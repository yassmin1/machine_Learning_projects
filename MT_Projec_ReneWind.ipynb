{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3-QehJxbp0t"
      },
      "source": [
        "# ReneWind\n",
        "\n",
        "Renewable energy sources play an increasingly important role in the global energy mix, as the effort to reduce the environmental impact of energy production increases.\n",
        "\n",
        "Out of all the renewable energy alternatives, wind energy is one of the most developed technologies worldwide. The U.S Department of Energy has put together a guide to achieving operational efficiency using predictive maintenance practices.\n",
        "\n",
        "Predictive maintenance uses sensor information and analysis methods to measure and predict degradation and future component capability. The idea behind predictive maintenance is that failure patterns are predictable and if component failure can be predicted accurately and the component is replaced before it fails, the costs of operation and maintenance will be much lower.\n",
        "\n",
        "The sensors fitted across different machines involved in the process of energy generation collect data related to various environmental factors (temperature, humidity, wind speed, etc.) and additional features related to various parts of the wind turbine (gearbox, tower, blades, break, etc.). \n",
        "\n",
        "\n",
        "\n",
        "## Objective\n",
        "“ReneWind” is a company working on improving the machinery/processes involved in the production of wind energy using machine learning and has collected data of generator failure of wind turbines using sensors. They have shared a ciphered version of the data, as the data collected through sensors is confidential (the type of data collected varies with companies). Data has 40 predictors, 20000 observations in the training set and 5000 in the test set.\n",
        "\n",
        "The objective is to build various classification models, tune them, and find the best one that will help identify failures so that the generators could be repaired before failing/breaking to reduce the overall maintenance cost. \n",
        "The nature of predictions made by the classification model will translate as follows:\n",
        "\n",
        "- True positives (TP) are failures correctly predicted by the model. These will result in repairing costs.\n",
        "- False negatives (FN) are real failures where there is no detection by the model. These will result in replacement costs.\n",
        "- False positives (FP) are detections where there is no failure. These will result in inspection costs.\n",
        "\n",
        "It is given that the cost of repairing a generator is much less than the cost of replacing it, and the cost of inspection is less than the cost of repair.\n",
        "\n",
        "“1” in the target variables should be considered as “failure” and “0” represents “No failure”.\n",
        "\n",
        "## Data Description\n",
        "- The data provided is a transformed version of original data which was collected using sensors.\n",
        "- Train.csv - To be used for training and tuning of models. \n",
        "- Test.csv - To be used only for testing the performance of the final best model.\n",
        "- Both the datasets consist of 40 predictor variables and 1 target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbHOIdlwcrqR"
      },
      "source": [
        "### **Please read the instructions carefully before starting the project.** \n",
        "This is a commented Jupyter IPython Notebook file in which all the instructions and tasks to be performed are mentioned. \n",
        "* Blanks '_______' are provided in the notebook that \n",
        "needs to be filled with an appropriate code to get the correct result. With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space. \n",
        "* Identify the task to be performed correctly, and only then proceed to write the required code.\n",
        "* Fill the code wherever asked by the commented lines like \"# write your code here\" or \"# complete the code\". Running incomplete code may throw error.\n",
        "* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors.\n",
        "* Add the results/observations (wherever mentioned) derived from the analysis in the presentation and submit the same.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xypQC_9dbp0v"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dbiVVX6hbp0v"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"# This will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n\\n# Libraries to help with reading and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# Libaries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To tune model, get different metric scores, and split data\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n)\\nfrom sklearn import metrics\\n\\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To impute missing values\\nfrom sklearn.impute import SimpleImputer\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# To do hyperparameter tuning\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\npd.set_option(\\\"display.max_rows\\\", None)\\n\\n# To supress scientific notations for a dataframe\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To help with model building\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import (\\n    AdaBoostClassifier,\\n    GradientBoostingClassifier,\\n    RandomForestClassifier,\\n    BaggingClassifier,\\n)\\nfrom xgboost import XGBClassifier\\n\\n# To suppress scientific notations\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To suppress warnings\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\nsns.set_style(\\\"white\\\")\";\n                var nbb_formatted_code = \"# This will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n\\n# Libraries to help with reading and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# Libaries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To tune model, get different metric scores, and split data\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n)\\nfrom sklearn import metrics\\n\\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To impute missing values\\nfrom sklearn.impute import SimpleImputer\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# To do hyperparameter tuning\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\npd.set_option(\\\"display.max_rows\\\", None)\\n\\n# To supress scientific notations for a dataframe\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To help with model building\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import (\\n    AdaBoostClassifier,\\n    GradientBoostingClassifier,\\n    RandomForestClassifier,\\n    BaggingClassifier,\\n)\\nfrom xgboost import XGBClassifier\\n\\n# To suppress scientific notations\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To suppress warnings\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\nsns.set_style(\\\"white\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# This will help in making the Python code more structured automatically (good coding practice)\n",
        "%load_ext nb_black\n",
        "\n",
        "# Libraries to help with reading and manipulating data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# To tune model, get different metric scores, and split data\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    plot_confusion_matrix,\n",
        ")\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "\n",
        "# To be used for data scaling and one hot encoding\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# To impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# To oversample and undersample data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# To do hyperparameter tuning\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# To be used for creating pipelines and personalizing them\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# To define maximum number of columns to be displayed in a dataframe\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "\n",
        "# To supress scientific notations for a dataframe\n",
        "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
        "\n",
        "# To help with model building\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    AdaBoostClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    RandomForestClassifier,\n",
        "    BaggingClassifier,\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# To suppress scientific notations\n",
        "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
        "\n",
        "# To suppress warnings\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set_style(\"white\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfmaS2U7bp0x"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "39UgpBY3bp0y"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"df = pd.read_csv('Train.csv.csv') ##  Complete the code to read the data\\ndf_test = pd.read_csv('Test.csv.csv') ##  Complete the code to read the data\";\n                var nbb_formatted_code = \"df = pd.read_csv(\\\"Train.csv.csv\\\")  ##  Complete the code to read the data\\ndf_test = pd.read_csv(\\\"Test.csv.csv\\\")  ##  Complete the code to read the data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('Train.csv.csv') ##  Complete the code to read the data\n",
        "df_test = pd.read_csv('Test.csv.csv') ##  Complete the code to read the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7Y8epHpjbp0z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20000, 41)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# Checking the number of rows and columns in the training data\\ndf.shape ##  Complete the code to view dimensions of the train data\";\n                var nbb_formatted_code = \"# Checking the number of rows and columns in the training data\\ndf.shape  ##  Complete the code to view dimensions of the train data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Checking the number of rows and columns in the training data\n",
        "df.shape ##  Complete the code to view dimensions of the train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hA15qTjzbp01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5000, 41)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"# Checking the number of rows and columns in the test data\\ndf_test.shape ##  Complete the code to view dimensions of the test data\";\n                var nbb_formatted_code = \"# Checking the number of rows and columns in the test data\\ndf_test.shape  ##  Complete the code to view dimensions of the test data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Checking the number of rows and columns in the test data\n",
        "df_test.shape ##  Complete the code to view dimensions of the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cVx5kZHbp02"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QTsYJZBubp02"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"# let's create a copy of the training data\\ndata = df.copy()\";\n                var nbb_formatted_code = \"# let's create a copy of the training data\\ndata = df.copy()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's create a copy of the training data\n",
        "data = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "69ImWbLXbp03"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# let's create a copy of the training data\\ndata_test = df_test.copy()\";\n                var nbb_formatted_code = \"# let's create a copy of the training data\\ndata_test = df_test.copy()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's create a copy of the training data\n",
        "data_test = df_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l9RnN7Twbp03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4.465</td>\n",
              "      <td>-4.679</td>\n",
              "      <td>3.102</td>\n",
              "      <td>0.506</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-2.033</td>\n",
              "      <td>-2.911</td>\n",
              "      <td>0.051</td>\n",
              "      <td>-1.522</td>\n",
              "      <td>3.762</td>\n",
              "      <td>-5.715</td>\n",
              "      <td>0.736</td>\n",
              "      <td>0.981</td>\n",
              "      <td>1.418</td>\n",
              "      <td>-3.376</td>\n",
              "      <td>-3.047</td>\n",
              "      <td>0.306</td>\n",
              "      <td>2.914</td>\n",
              "      <td>2.270</td>\n",
              "      <td>4.395</td>\n",
              "      <td>-2.388</td>\n",
              "      <td>0.646</td>\n",
              "      <td>-1.191</td>\n",
              "      <td>3.133</td>\n",
              "      <td>0.665</td>\n",
              "      <td>-2.511</td>\n",
              "      <td>-0.037</td>\n",
              "      <td>0.726</td>\n",
              "      <td>-3.982</td>\n",
              "      <td>-1.073</td>\n",
              "      <td>1.667</td>\n",
              "      <td>3.060</td>\n",
              "      <td>-1.690</td>\n",
              "      <td>2.846</td>\n",
              "      <td>2.235</td>\n",
              "      <td>6.667</td>\n",
              "      <td>0.444</td>\n",
              "      <td>-2.369</td>\n",
              "      <td>2.951</td>\n",
              "      <td>-3.480</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.366</td>\n",
              "      <td>3.653</td>\n",
              "      <td>0.910</td>\n",
              "      <td>-1.368</td>\n",
              "      <td>0.332</td>\n",
              "      <td>2.359</td>\n",
              "      <td>0.733</td>\n",
              "      <td>-4.332</td>\n",
              "      <td>0.566</td>\n",
              "      <td>-0.101</td>\n",
              "      <td>1.914</td>\n",
              "      <td>-0.951</td>\n",
              "      <td>-1.255</td>\n",
              "      <td>-2.707</td>\n",
              "      <td>0.193</td>\n",
              "      <td>-4.769</td>\n",
              "      <td>-2.205</td>\n",
              "      <td>0.908</td>\n",
              "      <td>0.757</td>\n",
              "      <td>-5.834</td>\n",
              "      <td>-3.065</td>\n",
              "      <td>1.597</td>\n",
              "      <td>-1.757</td>\n",
              "      <td>1.766</td>\n",
              "      <td>-0.267</td>\n",
              "      <td>3.625</td>\n",
              "      <td>1.500</td>\n",
              "      <td>-0.586</td>\n",
              "      <td>0.783</td>\n",
              "      <td>-0.201</td>\n",
              "      <td>0.025</td>\n",
              "      <td>-1.795</td>\n",
              "      <td>3.033</td>\n",
              "      <td>-2.468</td>\n",
              "      <td>1.895</td>\n",
              "      <td>-2.298</td>\n",
              "      <td>-1.731</td>\n",
              "      <td>5.909</td>\n",
              "      <td>-0.386</td>\n",
              "      <td>0.616</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-3.832</td>\n",
              "      <td>-5.824</td>\n",
              "      <td>0.634</td>\n",
              "      <td>-2.419</td>\n",
              "      <td>-1.774</td>\n",
              "      <td>1.017</td>\n",
              "      <td>-2.099</td>\n",
              "      <td>-3.173</td>\n",
              "      <td>-2.082</td>\n",
              "      <td>5.393</td>\n",
              "      <td>-0.771</td>\n",
              "      <td>1.107</td>\n",
              "      <td>1.144</td>\n",
              "      <td>0.943</td>\n",
              "      <td>-3.164</td>\n",
              "      <td>-4.248</td>\n",
              "      <td>-4.039</td>\n",
              "      <td>3.689</td>\n",
              "      <td>3.311</td>\n",
              "      <td>1.059</td>\n",
              "      <td>-2.143</td>\n",
              "      <td>1.650</td>\n",
              "      <td>-1.661</td>\n",
              "      <td>1.680</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>-4.551</td>\n",
              "      <td>3.739</td>\n",
              "      <td>1.134</td>\n",
              "      <td>-2.034</td>\n",
              "      <td>0.841</td>\n",
              "      <td>-1.600</td>\n",
              "      <td>-0.257</td>\n",
              "      <td>0.804</td>\n",
              "      <td>4.086</td>\n",
              "      <td>2.292</td>\n",
              "      <td>5.361</td>\n",
              "      <td>0.352</td>\n",
              "      <td>2.940</td>\n",
              "      <td>3.839</td>\n",
              "      <td>-4.309</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.618</td>\n",
              "      <td>1.888</td>\n",
              "      <td>7.046</td>\n",
              "      <td>-1.147</td>\n",
              "      <td>0.083</td>\n",
              "      <td>-1.530</td>\n",
              "      <td>0.207</td>\n",
              "      <td>-2.494</td>\n",
              "      <td>0.345</td>\n",
              "      <td>2.119</td>\n",
              "      <td>-3.053</td>\n",
              "      <td>0.460</td>\n",
              "      <td>2.705</td>\n",
              "      <td>-0.636</td>\n",
              "      <td>-0.454</td>\n",
              "      <td>-3.174</td>\n",
              "      <td>-3.404</td>\n",
              "      <td>-1.282</td>\n",
              "      <td>1.582</td>\n",
              "      <td>-1.952</td>\n",
              "      <td>-3.517</td>\n",
              "      <td>-1.206</td>\n",
              "      <td>-5.628</td>\n",
              "      <td>-1.818</td>\n",
              "      <td>2.124</td>\n",
              "      <td>5.295</td>\n",
              "      <td>4.748</td>\n",
              "      <td>-2.309</td>\n",
              "      <td>-3.963</td>\n",
              "      <td>-6.029</td>\n",
              "      <td>4.949</td>\n",
              "      <td>-3.584</td>\n",
              "      <td>-2.577</td>\n",
              "      <td>1.364</td>\n",
              "      <td>0.623</td>\n",
              "      <td>5.550</td>\n",
              "      <td>-1.527</td>\n",
              "      <td>0.139</td>\n",
              "      <td>3.101</td>\n",
              "      <td>-1.277</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.111</td>\n",
              "      <td>3.872</td>\n",
              "      <td>-3.758</td>\n",
              "      <td>-2.983</td>\n",
              "      <td>3.793</td>\n",
              "      <td>0.545</td>\n",
              "      <td>0.205</td>\n",
              "      <td>4.849</td>\n",
              "      <td>-1.855</td>\n",
              "      <td>-6.220</td>\n",
              "      <td>1.998</td>\n",
              "      <td>4.724</td>\n",
              "      <td>0.709</td>\n",
              "      <td>-1.989</td>\n",
              "      <td>-2.633</td>\n",
              "      <td>4.184</td>\n",
              "      <td>2.245</td>\n",
              "      <td>3.734</td>\n",
              "      <td>-6.313</td>\n",
              "      <td>-5.380</td>\n",
              "      <td>-0.887</td>\n",
              "      <td>2.062</td>\n",
              "      <td>9.446</td>\n",
              "      <td>4.490</td>\n",
              "      <td>-3.945</td>\n",
              "      <td>4.582</td>\n",
              "      <td>-8.780</td>\n",
              "      <td>-3.383</td>\n",
              "      <td>5.107</td>\n",
              "      <td>6.788</td>\n",
              "      <td>2.044</td>\n",
              "      <td>8.266</td>\n",
              "      <td>6.629</td>\n",
              "      <td>-10.069</td>\n",
              "      <td>1.223</td>\n",
              "      <td>-3.230</td>\n",
              "      <td>1.687</td>\n",
              "      <td>-2.164</td>\n",
              "      <td>-3.645</td>\n",
              "      <td>6.510</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      V1     V2     V3     V4     V5     V6     V7     V8     V9    V10  \\\n",
              "0 -4.465 -4.679  3.102  0.506 -0.221 -2.033 -2.911  0.051 -1.522  3.762   \n",
              "1  3.366  3.653  0.910 -1.368  0.332  2.359  0.733 -4.332  0.566 -0.101   \n",
              "2 -3.832 -5.824  0.634 -2.419 -1.774  1.017 -2.099 -3.173 -2.082  5.393   \n",
              "3  1.618  1.888  7.046 -1.147  0.083 -1.530  0.207 -2.494  0.345  2.119   \n",
              "4 -0.111  3.872 -3.758 -2.983  3.793  0.545  0.205  4.849 -1.855 -6.220   \n",
              "\n",
              "     V11    V12    V13    V14    V15    V16    V17    V18    V19    V20  \\\n",
              "0 -5.715  0.736  0.981  1.418 -3.376 -3.047  0.306  2.914  2.270  4.395   \n",
              "1  1.914 -0.951 -1.255 -2.707  0.193 -4.769 -2.205  0.908  0.757 -5.834   \n",
              "2 -0.771  1.107  1.144  0.943 -3.164 -4.248 -4.039  3.689  3.311  1.059   \n",
              "3 -3.053  0.460  2.705 -0.636 -0.454 -3.174 -3.404 -1.282  1.582 -1.952   \n",
              "4  1.998  4.724  0.709 -1.989 -2.633  4.184  2.245  3.734 -6.313 -5.380   \n",
              "\n",
              "     V21    V22    V23    V24    V25    V26    V27    V28    V29    V30  \\\n",
              "0 -2.388  0.646 -1.191  3.133  0.665 -2.511 -0.037  0.726 -3.982 -1.073   \n",
              "1 -3.065  1.597 -1.757  1.766 -0.267  3.625  1.500 -0.586  0.783 -0.201   \n",
              "2 -2.143  1.650 -1.661  1.680 -0.451 -4.551  3.739  1.134 -2.034  0.841   \n",
              "3 -3.517 -1.206 -5.628 -1.818  2.124  5.295  4.748 -2.309 -3.963 -6.029   \n",
              "4 -0.887  2.062  9.446  4.490 -3.945  4.582 -8.780 -3.383  5.107  6.788   \n",
              "\n",
              "     V31    V32    V33     V34   V35    V36    V37    V38    V39    V40  \\\n",
              "0  1.667  3.060 -1.690   2.846 2.235  6.667  0.444 -2.369  2.951 -3.480   \n",
              "1  0.025 -1.795  3.033  -2.468 1.895 -2.298 -1.731  5.909 -0.386  0.616   \n",
              "2 -1.600 -0.257  0.804   4.086 2.292  5.361  0.352  2.940  3.839 -4.309   \n",
              "3  4.949 -3.584 -2.577   1.364 0.623  5.550 -1.527  0.139  3.101 -1.277   \n",
              "4  2.044  8.266  6.629 -10.069 1.223 -3.230  1.687 -2.164 -3.645  6.510   \n",
              "\n",
              "   Target  \n",
              "0       0  \n",
              "1       0  \n",
              "2       0  \n",
              "3       0  \n",
              "4       0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# let's view the first 5 rows of the data\\ndata.head() ##  Complete the code to view top 5 rows of the data\";\n                var nbb_formatted_code = \"# let's view the first 5 rows of the data\\ndata.head()  ##  Complete the code to view top 5 rows of the data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's view the first 5 rows of the data\n",
        "data.head() ##  Complete the code to view top 5 rows of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N9Ir8YPgbp04"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>-2.071</td>\n",
              "      <td>-1.088</td>\n",
              "      <td>-0.796</td>\n",
              "      <td>-3.012</td>\n",
              "      <td>-2.288</td>\n",
              "      <td>2.807</td>\n",
              "      <td>0.481</td>\n",
              "      <td>0.105</td>\n",
              "      <td>-0.587</td>\n",
              "      <td>-2.899</td>\n",
              "      <td>8.868</td>\n",
              "      <td>1.717</td>\n",
              "      <td>1.358</td>\n",
              "      <td>-1.777</td>\n",
              "      <td>0.710</td>\n",
              "      <td>4.945</td>\n",
              "      <td>-3.100</td>\n",
              "      <td>-1.199</td>\n",
              "      <td>-1.085</td>\n",
              "      <td>-0.365</td>\n",
              "      <td>3.131</td>\n",
              "      <td>-3.948</td>\n",
              "      <td>-3.578</td>\n",
              "      <td>-8.139</td>\n",
              "      <td>-1.937</td>\n",
              "      <td>-1.328</td>\n",
              "      <td>-0.403</td>\n",
              "      <td>-1.735</td>\n",
              "      <td>9.996</td>\n",
              "      <td>6.955</td>\n",
              "      <td>-3.938</td>\n",
              "      <td>-8.274</td>\n",
              "      <td>5.745</td>\n",
              "      <td>0.589</td>\n",
              "      <td>-0.650</td>\n",
              "      <td>-3.043</td>\n",
              "      <td>2.216</td>\n",
              "      <td>0.609</td>\n",
              "      <td>0.178</td>\n",
              "      <td>2.928</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>2.890</td>\n",
              "      <td>2.483</td>\n",
              "      <td>5.644</td>\n",
              "      <td>0.937</td>\n",
              "      <td>-1.381</td>\n",
              "      <td>0.412</td>\n",
              "      <td>-1.593</td>\n",
              "      <td>-5.762</td>\n",
              "      <td>2.150</td>\n",
              "      <td>0.272</td>\n",
              "      <td>-2.095</td>\n",
              "      <td>-1.526</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-3.540</td>\n",
              "      <td>-2.762</td>\n",
              "      <td>-10.632</td>\n",
              "      <td>-0.495</td>\n",
              "      <td>1.720</td>\n",
              "      <td>3.872</td>\n",
              "      <td>-1.210</td>\n",
              "      <td>-8.222</td>\n",
              "      <td>2.121</td>\n",
              "      <td>-5.492</td>\n",
              "      <td>1.452</td>\n",
              "      <td>1.450</td>\n",
              "      <td>3.685</td>\n",
              "      <td>1.077</td>\n",
              "      <td>-0.384</td>\n",
              "      <td>-0.839</td>\n",
              "      <td>-0.748</td>\n",
              "      <td>-1.089</td>\n",
              "      <td>-4.159</td>\n",
              "      <td>1.181</td>\n",
              "      <td>-0.742</td>\n",
              "      <td>5.369</td>\n",
              "      <td>-0.693</td>\n",
              "      <td>-1.669</td>\n",
              "      <td>3.660</td>\n",
              "      <td>0.820</td>\n",
              "      <td>-1.987</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>-3.897</td>\n",
              "      <td>-3.942</td>\n",
              "      <td>-0.351</td>\n",
              "      <td>-2.417</td>\n",
              "      <td>1.108</td>\n",
              "      <td>-1.528</td>\n",
              "      <td>-3.520</td>\n",
              "      <td>2.055</td>\n",
              "      <td>-0.234</td>\n",
              "      <td>-0.358</td>\n",
              "      <td>-3.782</td>\n",
              "      <td>2.180</td>\n",
              "      <td>6.112</td>\n",
              "      <td>1.985</td>\n",
              "      <td>-8.330</td>\n",
              "      <td>-1.639</td>\n",
              "      <td>-0.915</td>\n",
              "      <td>5.672</td>\n",
              "      <td>-3.924</td>\n",
              "      <td>2.133</td>\n",
              "      <td>-4.502</td>\n",
              "      <td>2.777</td>\n",
              "      <td>5.728</td>\n",
              "      <td>1.620</td>\n",
              "      <td>-1.700</td>\n",
              "      <td>-0.042</td>\n",
              "      <td>-2.923</td>\n",
              "      <td>-2.760</td>\n",
              "      <td>-2.254</td>\n",
              "      <td>2.552</td>\n",
              "      <td>0.982</td>\n",
              "      <td>7.112</td>\n",
              "      <td>1.476</td>\n",
              "      <td>-3.954</td>\n",
              "      <td>1.856</td>\n",
              "      <td>5.029</td>\n",
              "      <td>2.083</td>\n",
              "      <td>-6.409</td>\n",
              "      <td>1.477</td>\n",
              "      <td>-0.874</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>-3.187</td>\n",
              "      <td>-10.052</td>\n",
              "      <td>5.696</td>\n",
              "      <td>-4.370</td>\n",
              "      <td>-5.355</td>\n",
              "      <td>-1.873</td>\n",
              "      <td>-3.947</td>\n",
              "      <td>0.679</td>\n",
              "      <td>-2.389</td>\n",
              "      <td>5.457</td>\n",
              "      <td>1.583</td>\n",
              "      <td>3.571</td>\n",
              "      <td>9.227</td>\n",
              "      <td>2.554</td>\n",
              "      <td>-7.039</td>\n",
              "      <td>-0.994</td>\n",
              "      <td>-9.665</td>\n",
              "      <td>1.155</td>\n",
              "      <td>3.877</td>\n",
              "      <td>3.524</td>\n",
              "      <td>-7.015</td>\n",
              "      <td>-0.132</td>\n",
              "      <td>-3.446</td>\n",
              "      <td>-4.801</td>\n",
              "      <td>-0.876</td>\n",
              "      <td>-3.812</td>\n",
              "      <td>5.422</td>\n",
              "      <td>-3.732</td>\n",
              "      <td>0.609</td>\n",
              "      <td>5.256</td>\n",
              "      <td>1.915</td>\n",
              "      <td>0.403</td>\n",
              "      <td>3.164</td>\n",
              "      <td>3.752</td>\n",
              "      <td>8.530</td>\n",
              "      <td>8.451</td>\n",
              "      <td>0.204</td>\n",
              "      <td>-7.130</td>\n",
              "      <td>4.249</td>\n",
              "      <td>-6.112</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>-2.687</td>\n",
              "      <td>1.961</td>\n",
              "      <td>6.137</td>\n",
              "      <td>2.600</td>\n",
              "      <td>2.657</td>\n",
              "      <td>-4.291</td>\n",
              "      <td>-2.344</td>\n",
              "      <td>0.974</td>\n",
              "      <td>-1.027</td>\n",
              "      <td>0.497</td>\n",
              "      <td>-9.589</td>\n",
              "      <td>3.177</td>\n",
              "      <td>1.055</td>\n",
              "      <td>-1.416</td>\n",
              "      <td>-4.669</td>\n",
              "      <td>-5.405</td>\n",
              "      <td>3.720</td>\n",
              "      <td>2.893</td>\n",
              "      <td>2.329</td>\n",
              "      <td>1.458</td>\n",
              "      <td>-6.429</td>\n",
              "      <td>1.818</td>\n",
              "      <td>0.806</td>\n",
              "      <td>7.786</td>\n",
              "      <td>0.331</td>\n",
              "      <td>5.257</td>\n",
              "      <td>-4.867</td>\n",
              "      <td>-0.819</td>\n",
              "      <td>-5.667</td>\n",
              "      <td>-2.861</td>\n",
              "      <td>4.674</td>\n",
              "      <td>6.621</td>\n",
              "      <td>-1.989</td>\n",
              "      <td>-1.349</td>\n",
              "      <td>3.952</td>\n",
              "      <td>5.450</td>\n",
              "      <td>-0.455</td>\n",
              "      <td>-2.202</td>\n",
              "      <td>1.678</td>\n",
              "      <td>-1.974</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          V1      V2     V3     V4     V5     V6     V7     V8     V9    V10  \\\n",
              "19995 -2.071  -1.088 -0.796 -3.012 -2.288  2.807  0.481  0.105 -0.587 -2.899   \n",
              "19996  2.890   2.483  5.644  0.937 -1.381  0.412 -1.593 -5.762  2.150  0.272   \n",
              "19997 -3.897  -3.942 -0.351 -2.417  1.108 -1.528 -3.520  2.055 -0.234 -0.358   \n",
              "19998 -3.187 -10.052  5.696 -4.370 -5.355 -1.873 -3.947  0.679 -2.389  5.457   \n",
              "19999 -2.687   1.961  6.137  2.600  2.657 -4.291 -2.344  0.974 -1.027  0.497   \n",
              "\n",
              "         V11    V12   V13    V14    V15     V16    V17    V18    V19    V20  \\\n",
              "19995  8.868  1.717 1.358 -1.777  0.710   4.945 -3.100 -1.199 -1.085 -0.365   \n",
              "19996 -2.095 -1.526 0.072 -3.540 -2.762 -10.632 -0.495  1.720  3.872 -1.210   \n",
              "19997 -3.782  2.180 6.112  1.985 -8.330  -1.639 -0.915  5.672 -3.924  2.133   \n",
              "19998  1.583  3.571 9.227  2.554 -7.039  -0.994 -9.665  1.155  3.877  3.524   \n",
              "19999 -9.589  3.177 1.055 -1.416 -4.669  -5.405  3.720  2.893  2.329  1.458   \n",
              "\n",
              "         V21    V22    V23    V24    V25    V26    V27    V28    V29    V30  \\\n",
              "19995  3.131 -3.948 -3.578 -8.139 -1.937 -1.328 -0.403 -1.735  9.996  6.955   \n",
              "19996 -8.222  2.121 -5.492  1.452  1.450  3.685  1.077 -0.384 -0.839 -0.748   \n",
              "19997 -4.502  2.777  5.728  1.620 -1.700 -0.042 -2.923 -2.760 -2.254  2.552   \n",
              "19998 -7.015 -0.132 -3.446 -4.801 -0.876 -3.812  5.422 -3.732  0.609  5.256   \n",
              "19999 -6.429  1.818  0.806  7.786  0.331  5.257 -4.867 -0.819 -5.667 -2.861   \n",
              "\n",
              "         V31    V32    V33    V34    V35    V36    V37    V38   V39    V40  \\\n",
              "19995 -3.938 -8.274  5.745  0.589 -0.650 -3.043  2.216  0.609 0.178  2.928   \n",
              "19996 -1.089 -4.159  1.181 -0.742  5.369 -0.693 -1.669  3.660 0.820 -1.987   \n",
              "19997  0.982  7.112  1.476 -3.954  1.856  5.029  2.083 -6.409 1.477 -0.874   \n",
              "19998  1.915  0.403  3.164  3.752  8.530  8.451  0.204 -7.130 4.249 -6.112   \n",
              "19999  4.674  6.621 -1.989 -1.349  3.952  5.450 -0.455 -2.202 1.678 -1.974   \n",
              "\n",
              "       Target  \n",
              "19995       1  \n",
              "19996       0  \n",
              "19997       0  \n",
              "19998       0  \n",
              "19999       0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"# let's view the last 5 rows of the data\\ndata.tail()##  Complete the code to view last 5 rows of the data  \";\n                var nbb_formatted_code = \"# let's view the last 5 rows of the data\\ndata.tail()  ##  Complete the code to view last 5 rows of the data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's view the last 5 rows of the data\n",
        "data.tail()##  Complete the code to view last 5 rows of the data  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EXBYJoKkbp04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 41 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   V1      19982 non-null  float64\n",
            " 1   V2      19982 non-null  float64\n",
            " 2   V3      20000 non-null  float64\n",
            " 3   V4      20000 non-null  float64\n",
            " 4   V5      20000 non-null  float64\n",
            " 5   V6      20000 non-null  float64\n",
            " 6   V7      20000 non-null  float64\n",
            " 7   V8      20000 non-null  float64\n",
            " 8   V9      20000 non-null  float64\n",
            " 9   V10     20000 non-null  float64\n",
            " 10  V11     20000 non-null  float64\n",
            " 11  V12     20000 non-null  float64\n",
            " 12  V13     20000 non-null  float64\n",
            " 13  V14     20000 non-null  float64\n",
            " 14  V15     20000 non-null  float64\n",
            " 15  V16     20000 non-null  float64\n",
            " 16  V17     20000 non-null  float64\n",
            " 17  V18     20000 non-null  float64\n",
            " 18  V19     20000 non-null  float64\n",
            " 19  V20     20000 non-null  float64\n",
            " 20  V21     20000 non-null  float64\n",
            " 21  V22     20000 non-null  float64\n",
            " 22  V23     20000 non-null  float64\n",
            " 23  V24     20000 non-null  float64\n",
            " 24  V25     20000 non-null  float64\n",
            " 25  V26     20000 non-null  float64\n",
            " 26  V27     20000 non-null  float64\n",
            " 27  V28     20000 non-null  float64\n",
            " 28  V29     20000 non-null  float64\n",
            " 29  V30     20000 non-null  float64\n",
            " 30  V31     20000 non-null  float64\n",
            " 31  V32     20000 non-null  float64\n",
            " 32  V33     20000 non-null  float64\n",
            " 33  V34     20000 non-null  float64\n",
            " 34  V35     20000 non-null  float64\n",
            " 35  V36     20000 non-null  float64\n",
            " 36  V37     20000 non-null  float64\n",
            " 37  V38     20000 non-null  float64\n",
            " 38  V39     20000 non-null  float64\n",
            " 39  V40     20000 non-null  float64\n",
            " 40  Target  20000 non-null  int64  \n",
            "dtypes: float64(40), int64(1)\n",
            "memory usage: 6.3 MB\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"# let's check the data types of the columns in the dataset\\ndata.info()\";\n                var nbb_formatted_code = \"# let's check the data types of the columns in the dataset\\ndata.info()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's check the data types of the columns in the dataset\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V0EmBHNmbp04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# let's check for duplicate values in the data\\ndata.duplicated().any() ##  Complete the code to check duplicate entries in the data\";\n                var nbb_formatted_code = \"# let's check for duplicate values in the data\\ndata.duplicated().any()  ##  Complete the code to check duplicate entries in the data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's check for duplicate values in the data\n",
        "data.duplicated().any() ##  Complete the code to check duplicate entries in the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SlwFZm-Jbp05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "V1        18\n",
              "V2        18\n",
              "V3         0\n",
              "V4         0\n",
              "V5         0\n",
              "V6         0\n",
              "V7         0\n",
              "V8         0\n",
              "V9         0\n",
              "V10        0\n",
              "V11        0\n",
              "V12        0\n",
              "V13        0\n",
              "V14        0\n",
              "V15        0\n",
              "V16        0\n",
              "V17        0\n",
              "V18        0\n",
              "V19        0\n",
              "V20        0\n",
              "V21        0\n",
              "V22        0\n",
              "V23        0\n",
              "V24        0\n",
              "V25        0\n",
              "V26        0\n",
              "V27        0\n",
              "V28        0\n",
              "V29        0\n",
              "V30        0\n",
              "V31        0\n",
              "V32        0\n",
              "V33        0\n",
              "V34        0\n",
              "V35        0\n",
              "V36        0\n",
              "V37        0\n",
              "V38        0\n",
              "V39        0\n",
              "V40        0\n",
              "Target     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"# let's check for missing values in the data\\ndata.isna().sum() ##  Complete the code to check missing entries in the train data\";\n                var nbb_formatted_code = \"# let's check for missing values in the data\\ndata.isna().sum()  ##  Complete the code to check missing entries in the train data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's check for missing values in the data\n",
        "data.isna().sum() ##  Complete the code to check missing entries in the train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "33bar6robp06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "V1        5\n",
              "V2        6\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "V29       0\n",
              "V30       0\n",
              "V31       0\n",
              "V32       0\n",
              "V33       0\n",
              "V34       0\n",
              "V35       0\n",
              "V36       0\n",
              "V37       0\n",
              "V38       0\n",
              "V39       0\n",
              "V40       0\n",
              "Target    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"# let's check for missing values in the data\\ndata_test.isna().sum() ##  Complete the code to check missing entries in the test data\";\n                var nbb_formatted_code = \"# let's check for missing values in the data\\ndata_test.isna().sum()  ##  Complete the code to check missing entries in the test data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's check for missing values in the data\n",
        "data_test.isna().sum() ##  Complete the code to check missing entries in the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J6lzvHKCbp06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>V1</th>\n",
              "      <td>19982.000</td>\n",
              "      <td>-0.272</td>\n",
              "      <td>3.442</td>\n",
              "      <td>-11.876</td>\n",
              "      <td>-2.737</td>\n",
              "      <td>-0.748</td>\n",
              "      <td>1.840</td>\n",
              "      <td>15.493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V2</th>\n",
              "      <td>19982.000</td>\n",
              "      <td>0.440</td>\n",
              "      <td>3.151</td>\n",
              "      <td>-12.320</td>\n",
              "      <td>-1.641</td>\n",
              "      <td>0.472</td>\n",
              "      <td>2.544</td>\n",
              "      <td>13.089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V3</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>2.485</td>\n",
              "      <td>3.389</td>\n",
              "      <td>-10.708</td>\n",
              "      <td>0.207</td>\n",
              "      <td>2.256</td>\n",
              "      <td>4.566</td>\n",
              "      <td>17.091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V4</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.083</td>\n",
              "      <td>3.432</td>\n",
              "      <td>-15.082</td>\n",
              "      <td>-2.348</td>\n",
              "      <td>-0.135</td>\n",
              "      <td>2.131</td>\n",
              "      <td>13.236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V5</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.054</td>\n",
              "      <td>2.105</td>\n",
              "      <td>-8.603</td>\n",
              "      <td>-1.536</td>\n",
              "      <td>-0.102</td>\n",
              "      <td>1.340</td>\n",
              "      <td>8.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V6</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.995</td>\n",
              "      <td>2.041</td>\n",
              "      <td>-10.227</td>\n",
              "      <td>-2.347</td>\n",
              "      <td>-1.001</td>\n",
              "      <td>0.380</td>\n",
              "      <td>6.976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V7</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.879</td>\n",
              "      <td>1.762</td>\n",
              "      <td>-7.950</td>\n",
              "      <td>-2.031</td>\n",
              "      <td>-0.917</td>\n",
              "      <td>0.224</td>\n",
              "      <td>8.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V8</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.548</td>\n",
              "      <td>3.296</td>\n",
              "      <td>-15.658</td>\n",
              "      <td>-2.643</td>\n",
              "      <td>-0.389</td>\n",
              "      <td>1.723</td>\n",
              "      <td>11.679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V9</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>2.161</td>\n",
              "      <td>-8.596</td>\n",
              "      <td>-1.495</td>\n",
              "      <td>-0.068</td>\n",
              "      <td>1.409</td>\n",
              "      <td>8.138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V10</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>2.193</td>\n",
              "      <td>-9.854</td>\n",
              "      <td>-1.411</td>\n",
              "      <td>0.101</td>\n",
              "      <td>1.477</td>\n",
              "      <td>8.108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V11</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-1.895</td>\n",
              "      <td>3.124</td>\n",
              "      <td>-14.832</td>\n",
              "      <td>-3.922</td>\n",
              "      <td>-1.921</td>\n",
              "      <td>0.119</td>\n",
              "      <td>11.826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V12</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>1.605</td>\n",
              "      <td>2.930</td>\n",
              "      <td>-12.948</td>\n",
              "      <td>-0.397</td>\n",
              "      <td>1.508</td>\n",
              "      <td>3.571</td>\n",
              "      <td>15.081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V13</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>1.580</td>\n",
              "      <td>2.875</td>\n",
              "      <td>-13.228</td>\n",
              "      <td>-0.224</td>\n",
              "      <td>1.637</td>\n",
              "      <td>3.460</td>\n",
              "      <td>15.420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V14</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.951</td>\n",
              "      <td>1.790</td>\n",
              "      <td>-7.739</td>\n",
              "      <td>-2.171</td>\n",
              "      <td>-0.957</td>\n",
              "      <td>0.271</td>\n",
              "      <td>5.671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V15</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-2.415</td>\n",
              "      <td>3.355</td>\n",
              "      <td>-16.417</td>\n",
              "      <td>-4.415</td>\n",
              "      <td>-2.383</td>\n",
              "      <td>-0.359</td>\n",
              "      <td>12.246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V16</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-2.925</td>\n",
              "      <td>4.222</td>\n",
              "      <td>-20.374</td>\n",
              "      <td>-5.634</td>\n",
              "      <td>-2.683</td>\n",
              "      <td>-0.095</td>\n",
              "      <td>13.583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V17</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.134</td>\n",
              "      <td>3.345</td>\n",
              "      <td>-14.091</td>\n",
              "      <td>-2.216</td>\n",
              "      <td>-0.015</td>\n",
              "      <td>2.069</td>\n",
              "      <td>16.756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V18</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>1.189</td>\n",
              "      <td>2.592</td>\n",
              "      <td>-11.644</td>\n",
              "      <td>-0.404</td>\n",
              "      <td>0.883</td>\n",
              "      <td>2.572</td>\n",
              "      <td>13.180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V19</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>1.182</td>\n",
              "      <td>3.397</td>\n",
              "      <td>-13.492</td>\n",
              "      <td>-1.050</td>\n",
              "      <td>1.279</td>\n",
              "      <td>3.493</td>\n",
              "      <td>13.238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V20</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>0.024</td>\n",
              "      <td>3.669</td>\n",
              "      <td>-13.923</td>\n",
              "      <td>-2.433</td>\n",
              "      <td>0.033</td>\n",
              "      <td>2.512</td>\n",
              "      <td>16.052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V21</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-3.611</td>\n",
              "      <td>3.568</td>\n",
              "      <td>-17.956</td>\n",
              "      <td>-5.930</td>\n",
              "      <td>-3.533</td>\n",
              "      <td>-1.266</td>\n",
              "      <td>13.840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V22</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>0.952</td>\n",
              "      <td>1.652</td>\n",
              "      <td>-10.122</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>0.975</td>\n",
              "      <td>2.026</td>\n",
              "      <td>7.410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V23</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>4.032</td>\n",
              "      <td>-14.866</td>\n",
              "      <td>-3.099</td>\n",
              "      <td>-0.262</td>\n",
              "      <td>2.452</td>\n",
              "      <td>14.459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V24</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>1.134</td>\n",
              "      <td>3.912</td>\n",
              "      <td>-16.387</td>\n",
              "      <td>-1.468</td>\n",
              "      <td>0.969</td>\n",
              "      <td>3.546</td>\n",
              "      <td>17.163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V25</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.002</td>\n",
              "      <td>2.017</td>\n",
              "      <td>-8.228</td>\n",
              "      <td>-1.365</td>\n",
              "      <td>0.025</td>\n",
              "      <td>1.397</td>\n",
              "      <td>8.223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V26</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>1.874</td>\n",
              "      <td>3.435</td>\n",
              "      <td>-11.834</td>\n",
              "      <td>-0.338</td>\n",
              "      <td>1.951</td>\n",
              "      <td>4.130</td>\n",
              "      <td>16.836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V27</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.612</td>\n",
              "      <td>4.369</td>\n",
              "      <td>-14.905</td>\n",
              "      <td>-3.652</td>\n",
              "      <td>-0.885</td>\n",
              "      <td>2.189</td>\n",
              "      <td>17.560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V28</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.883</td>\n",
              "      <td>1.918</td>\n",
              "      <td>-9.269</td>\n",
              "      <td>-2.171</td>\n",
              "      <td>-0.891</td>\n",
              "      <td>0.376</td>\n",
              "      <td>6.528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V29</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.986</td>\n",
              "      <td>2.684</td>\n",
              "      <td>-12.579</td>\n",
              "      <td>-2.787</td>\n",
              "      <td>-1.176</td>\n",
              "      <td>0.630</td>\n",
              "      <td>10.722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V30</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>3.005</td>\n",
              "      <td>-14.796</td>\n",
              "      <td>-1.867</td>\n",
              "      <td>0.184</td>\n",
              "      <td>2.036</td>\n",
              "      <td>12.506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V31</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>0.487</td>\n",
              "      <td>3.461</td>\n",
              "      <td>-13.723</td>\n",
              "      <td>-1.818</td>\n",
              "      <td>0.490</td>\n",
              "      <td>2.731</td>\n",
              "      <td>17.255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V32</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>0.304</td>\n",
              "      <td>5.500</td>\n",
              "      <td>-19.877</td>\n",
              "      <td>-3.420</td>\n",
              "      <td>0.052</td>\n",
              "      <td>3.762</td>\n",
              "      <td>23.633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V33</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>0.050</td>\n",
              "      <td>3.575</td>\n",
              "      <td>-16.898</td>\n",
              "      <td>-2.243</td>\n",
              "      <td>-0.066</td>\n",
              "      <td>2.255</td>\n",
              "      <td>16.692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V34</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.463</td>\n",
              "      <td>3.184</td>\n",
              "      <td>-17.985</td>\n",
              "      <td>-2.137</td>\n",
              "      <td>-0.255</td>\n",
              "      <td>1.437</td>\n",
              "      <td>14.358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V35</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>2.230</td>\n",
              "      <td>2.937</td>\n",
              "      <td>-15.350</td>\n",
              "      <td>0.336</td>\n",
              "      <td>2.099</td>\n",
              "      <td>4.064</td>\n",
              "      <td>15.291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V36</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>1.515</td>\n",
              "      <td>3.801</td>\n",
              "      <td>-14.833</td>\n",
              "      <td>-0.944</td>\n",
              "      <td>1.567</td>\n",
              "      <td>3.984</td>\n",
              "      <td>19.330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V37</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>0.011</td>\n",
              "      <td>1.788</td>\n",
              "      <td>-5.478</td>\n",
              "      <td>-1.256</td>\n",
              "      <td>-0.128</td>\n",
              "      <td>1.176</td>\n",
              "      <td>7.467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V38</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.344</td>\n",
              "      <td>3.948</td>\n",
              "      <td>-17.375</td>\n",
              "      <td>-2.988</td>\n",
              "      <td>-0.317</td>\n",
              "      <td>2.279</td>\n",
              "      <td>15.290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V39</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>0.891</td>\n",
              "      <td>1.753</td>\n",
              "      <td>-6.439</td>\n",
              "      <td>-0.272</td>\n",
              "      <td>0.919</td>\n",
              "      <td>2.058</td>\n",
              "      <td>7.760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V40</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>-0.876</td>\n",
              "      <td>3.012</td>\n",
              "      <td>-11.024</td>\n",
              "      <td>-2.940</td>\n",
              "      <td>-0.921</td>\n",
              "      <td>1.120</td>\n",
              "      <td>10.654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <td>20000.000</td>\n",
              "      <td>0.056</td>\n",
              "      <td>0.229</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count   mean   std     min    25%    50%    75%    max\n",
              "V1     19982.000 -0.272 3.442 -11.876 -2.737 -0.748  1.840 15.493\n",
              "V2     19982.000  0.440 3.151 -12.320 -1.641  0.472  2.544 13.089\n",
              "V3     20000.000  2.485 3.389 -10.708  0.207  2.256  4.566 17.091\n",
              "V4     20000.000 -0.083 3.432 -15.082 -2.348 -0.135  2.131 13.236\n",
              "V5     20000.000 -0.054 2.105  -8.603 -1.536 -0.102  1.340  8.134\n",
              "V6     20000.000 -0.995 2.041 -10.227 -2.347 -1.001  0.380  6.976\n",
              "V7     20000.000 -0.879 1.762  -7.950 -2.031 -0.917  0.224  8.006\n",
              "V8     20000.000 -0.548 3.296 -15.658 -2.643 -0.389  1.723 11.679\n",
              "V9     20000.000 -0.017 2.161  -8.596 -1.495 -0.068  1.409  8.138\n",
              "V10    20000.000 -0.013 2.193  -9.854 -1.411  0.101  1.477  8.108\n",
              "V11    20000.000 -1.895 3.124 -14.832 -3.922 -1.921  0.119 11.826\n",
              "V12    20000.000  1.605 2.930 -12.948 -0.397  1.508  3.571 15.081\n",
              "V13    20000.000  1.580 2.875 -13.228 -0.224  1.637  3.460 15.420\n",
              "V14    20000.000 -0.951 1.790  -7.739 -2.171 -0.957  0.271  5.671\n",
              "V15    20000.000 -2.415 3.355 -16.417 -4.415 -2.383 -0.359 12.246\n",
              "V16    20000.000 -2.925 4.222 -20.374 -5.634 -2.683 -0.095 13.583\n",
              "V17    20000.000 -0.134 3.345 -14.091 -2.216 -0.015  2.069 16.756\n",
              "V18    20000.000  1.189 2.592 -11.644 -0.404  0.883  2.572 13.180\n",
              "V19    20000.000  1.182 3.397 -13.492 -1.050  1.279  3.493 13.238\n",
              "V20    20000.000  0.024 3.669 -13.923 -2.433  0.033  2.512 16.052\n",
              "V21    20000.000 -3.611 3.568 -17.956 -5.930 -3.533 -1.266 13.840\n",
              "V22    20000.000  0.952 1.652 -10.122 -0.118  0.975  2.026  7.410\n",
              "V23    20000.000 -0.366 4.032 -14.866 -3.099 -0.262  2.452 14.459\n",
              "V24    20000.000  1.134 3.912 -16.387 -1.468  0.969  3.546 17.163\n",
              "V25    20000.000 -0.002 2.017  -8.228 -1.365  0.025  1.397  8.223\n",
              "V26    20000.000  1.874 3.435 -11.834 -0.338  1.951  4.130 16.836\n",
              "V27    20000.000 -0.612 4.369 -14.905 -3.652 -0.885  2.189 17.560\n",
              "V28    20000.000 -0.883 1.918  -9.269 -2.171 -0.891  0.376  6.528\n",
              "V29    20000.000 -0.986 2.684 -12.579 -2.787 -1.176  0.630 10.722\n",
              "V30    20000.000 -0.016 3.005 -14.796 -1.867  0.184  2.036 12.506\n",
              "V31    20000.000  0.487 3.461 -13.723 -1.818  0.490  2.731 17.255\n",
              "V32    20000.000  0.304 5.500 -19.877 -3.420  0.052  3.762 23.633\n",
              "V33    20000.000  0.050 3.575 -16.898 -2.243 -0.066  2.255 16.692\n",
              "V34    20000.000 -0.463 3.184 -17.985 -2.137 -0.255  1.437 14.358\n",
              "V35    20000.000  2.230 2.937 -15.350  0.336  2.099  4.064 15.291\n",
              "V36    20000.000  1.515 3.801 -14.833 -0.944  1.567  3.984 19.330\n",
              "V37    20000.000  0.011 1.788  -5.478 -1.256 -0.128  1.176  7.467\n",
              "V38    20000.000 -0.344 3.948 -17.375 -2.988 -0.317  2.279 15.290\n",
              "V39    20000.000  0.891 1.753  -6.439 -0.272  0.919  2.058  7.760\n",
              "V40    20000.000 -0.876 3.012 -11.024 -2.940 -0.921  1.120 10.654\n",
              "Target 20000.000  0.056 0.229   0.000  0.000  0.000  0.000  1.000"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"# let's view the statistical summary of the numerical columns in the data\\ndata.describe().T ##  Complete the code to print the statitical summary of the train data\";\n                var nbb_formatted_code = \"# let's view the statistical summary of the numerical columns in the data\\ndata.describe().T  ##  Complete the code to print the statitical summary of the train data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's view the statistical summary of the numerical columns in the data\n",
        "data.describe().T ##  Complete the code to print the statitical summary of the train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG84hrxfbp06"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv7Bs8aUbp07"
      },
      "source": [
        "### Univariate analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QIP4bI3Zbp07",
        "outputId": "f5372b09-92ef-4fbc-9398-e267e9116aa9"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"# function to plot a boxplot and a histogram along the same scale.\\n\\n\\ndef histogram_boxplot(data, feature, figsize=(12, 7), kde=True, bins=None):\\n    \\\"\\\"\\\"\\n    Boxplot and histogram combined\\n\\n    data: dataframe\\n    feature: dataframe column\\n    figsize: size of figure (default (12,7))\\n    kde: whether to the show density curve (default False)\\n    bins: number of bins for histogram (default None)\\n    \\\"\\\"\\\"\\n    f2, (ax_box2, ax_hist2) = plt.subplots(\\n        nrows=2,  # Number of rows of the subplot grid= 2\\n        sharex=True,  # x-axis will be shared among all subplots\\n        gridspec_kw={\\\"height_ratios\\\": (0.25, 0.75)},\\n        figsize=figsize,\\n    )  # creating the 2 subplots\\n    sns.boxplot(\\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\\\"violet\\\"\\n    )  # boxplot will be created and a star will indicate the mean value of the column\\n    sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\\\"winter\\\"\\n    ) if bins else sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2\\n    )  # For histogram\\n    ax_hist2.axvline(\\n        data[feature].mean(), color=\\\"green\\\", linestyle=\\\"--\\\"\\n    )  # Add mean to the histogram\\n    ax_hist2.axvline(\\n        data[feature].median(), color=\\\"black\\\", linestyle=\\\"-\\\"\\n    )  # Add median to the histogram\\n    f2.savefig(f'{feature}.png',dpi=200)\";\n                var nbb_formatted_code = \"# function to plot a boxplot and a histogram along the same scale.\\n\\n\\ndef histogram_boxplot(data, feature, figsize=(12, 7), kde=True, bins=None):\\n    \\\"\\\"\\\"\\n    Boxplot and histogram combined\\n\\n    data: dataframe\\n    feature: dataframe column\\n    figsize: size of figure (default (12,7))\\n    kde: whether to the show density curve (default False)\\n    bins: number of bins for histogram (default None)\\n    \\\"\\\"\\\"\\n    f2, (ax_box2, ax_hist2) = plt.subplots(\\n        nrows=2,  # Number of rows of the subplot grid= 2\\n        sharex=True,  # x-axis will be shared among all subplots\\n        gridspec_kw={\\\"height_ratios\\\": (0.25, 0.75)},\\n        figsize=figsize,\\n    )  # creating the 2 subplots\\n    sns.boxplot(\\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\\\"violet\\\"\\n    )  # boxplot will be created and a star will indicate the mean value of the column\\n    sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\\\"winter\\\"\\n    ) if bins else sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2\\n    )  # For histogram\\n    ax_hist2.axvline(\\n        data[feature].mean(), color=\\\"green\\\", linestyle=\\\"--\\\"\\n    )  # Add mean to the histogram\\n    ax_hist2.axvline(\\n        data[feature].median(), color=\\\"black\\\", linestyle=\\\"-\\\"\\n    )  # Add median to the histogram\\n    f2.savefig(f\\\"{feature}.png\\\", dpi=200)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# function to plot a boxplot and a histogram along the same scale.\n",
        "\n",
        "\n",
        "def histogram_boxplot(data, feature, figsize=(12, 7), kde=True, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram\n",
        "    f2.savefig(f'{feature}.png',dpi=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBkL6zw0bp07"
      },
      "source": [
        "### Plotting histograms and boxplots for all the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0ip-InCbp07",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "for feature in df.columns:\n",
        "    histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0   0.945\n",
              "1   0.056\n",
              "Name: Target, dtype: float64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"data.Target.value_counts(normalize=True)\";\n                var nbb_formatted_code = \"data.Target.value_counts(normalize=True)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.Target.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"sns.countplot(data=data,x=\\\"Target\\\")\\nplt.savefig('targetcounts.png')\";\n                var nbb_formatted_code = \"sns.countplot(data=data, x=\\\"Target\\\")\\nplt.savefig(\\\"targetcounts.png\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(data=data,x=\"Target\")\n",
        "plt.savefig('targetcounts.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"f1=sns.violinplot(data=data.iloc[:,:10])\\nplt.savefig('violin1.png')\";\n                var nbb_formatted_code = \"f1 = sns.violinplot(data=data.iloc[:, :10])\\nplt.savefig(\\\"violin1.png\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "f1=sns.violinplot(data=data.iloc[:,:10])\n",
        "plt.savefig('violin1.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 270;\n                var nbb_unformatted_code = \"f2=sns.violinplot(data=data.iloc[:,10:20])\\nplt.savefig('violin2.png')\";\n                var nbb_formatted_code = \"f2 = sns.violinplot(data=data.iloc[:, 10:20])\\nplt.savefig(\\\"violin2.png\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "f2=sns.violinplot(data=data.iloc[:,10:20])\n",
        "plt.savefig('violin2.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEECAYAAAAlEzNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2hElEQVR4nO3dZ2BUVd7H8e+0TGZSSUJC6P1EqogIiiiPuoqyKssCouiuiq4oiggWqqKg6ArSiwIKggqKIgqrqCAoipUi9dI7ElpInT7PiwQFRQTMzJ2Z+/+8MXMzyfx2Q+aXe+6555iCwSBCCCGMy6x3ACGEEPqSIhBCCIOTIhBCCIOTIhBCCIOTIhBCCIOz6h3gXLVs2TJYpUoVvWMIIURUWb9+/WFN0yqe7nNRVwRVqlThvffe0zuGEEJEFaXUrj/6nAwNCSGEwUkRCCGEwUkRCCGEwUkRCCGEwUkRCCGEwUkRCCGEwUkRCCGEwUkRCCEikiyRHz5SBEKIiPSvO+5g9uzZescwBCkCIURE2rN3L5MnT9Y7hiFIEQghIo4MC4VX2NcaUkq1BF7QNK2tUqoZsADYUvbpSZqmzQl3JiFEZPH7/XpHMJSwFoFS6nHgDqCo7FBz4CVN00aGM4cQIrL5fD69IxhKuIeGtgEdT3rcHGivlPpCKTVNKZUU5jxCiAgkRRBeYS0CTdPeBbwnHfoOeEzTtCuA7cBT4cwjhIhMXq/3z58kyo3eF4vnaZr244mPgWZ6hhFCRAaPx6N3BEPRuwgWKaUuKfv4auDHMz1ZCGEMUgThpfcOZfcD45RSXuBn4D865xFCRAC32613BEMJexFomrYTaFX28UqgdbgzCCEimxRBeOk9NCSEEL/jcrn0jmAoUgRCiIhTXFysdwRDkSIQQkSckpISvSMYihSBECLiFBUV/fKx3FwWelIEQoiIU1BQ8MvHhYWFOiYxBikCIUTEyc/P/+Xj48eP65jEGKQIhBARJy8v75ePpQhCT4pACBFx8vLysJmDv3wsQkuKQAgRcY4ePkT1xNKLxEeOHNE5TeyTIhBCRJxDhw9TPdGPxSRFEA5SBEKIiOJyuSgoLCI9PkBqPOTm5uodKeZJEQghIsrBgwcBSI/3k273cfDgzzonin1SBEKIiPLzz6Vv/BnxATLsfg7s36dzotgnRSCEiCj79pW+8Wc5/GQ5/Rw6fFRWIw0xKQIhRETZuXMnTpuJlLgg2U4/wWCQ3bt36x0rpkkRCCEiyratW0m2+fjq5ziqJfpLj23bpnOq2CZFIISIGG63m82bNTx++OJAPNlOPw4bbNiwQe9oMU2KQAgRMTZs2IDX58dhLb2r2GyCekkeVq2U7cxDSYrA4ILBoN4RhPjFihUrsJohwfrrv8umGV727N3Hnj17dEwW26QIDOz777/npptu4tChQ3pHEQK/38+SxZ/RsIIHs+nX4xdleDABixcv1i1brAt7ESilWiqllpZ9XFcptVwp9aVSapJSSoopjN59910KCgrYsmWL3lGE4LvvvuPwkaNckX3qVNH0+AAN07z8b+EC2aQmRML6xquUehyYCsSXHXoJGKRpWhvABNwczjxCiMgxZ/ZsKsRDswzP7z53dZUScg8dZtmyZToki33h/gt8G9DxpMfNgRM/2Y+Aa8KcRwAmk+nPnyRECK1bt47Va9bQrmoR1tO8KzXL8FI5Icgbs2YSCATCHzDGhbUINE17F/CedMikadqJq0IFQEo484hScsFY6CkYDPLKKy+TYoerqrhO+xyzCW6uUcj2HTtZsmRJmBPGPr3H5E+u9iQgT6ccQgidrFixgp9+WsvNNQqxW/74eS2zPNRICjB1yiuy5EQ507sIViml2pZ9fD3wpY5ZhBBh5vP5mDRxAtkJQdpWPvObu9kEt9Qp5OeDucybNy9MCY1B7yLoCzytlFoBxAFzdc4jhAijDz74gD1793FL7YLTXhv4rUZpXpqme3h9xgzZwrIcWcP9gpqm7QRalX28Gbgy3BmEEPorKChg+muvckEFH80yvH/+BWW61i1m4HdxTJ8+nd69e4cuoIHofUYghDCot956i/yCQm6tW8i5TFyrkuCnbWUXH374AXv37g1dQAORIhBChN2hQ4eY+847XJblpmaS/5y/vkPNYqymAFOmTAlBOuORIhByH4EIu5kzZ+L3e/ln7eLz+vpUe5DrqhazbNkyuTO+HEgRCLmPQITVvn37WLhwAVdmu6joOP+bw26o7iIxDqZOeaUc0xmTFIEQIqymTZuGhQAdap7f2cAJTmuQ9tWK+Pa771m9enX5hDMoKQIhRNisX7+eJUuWcF3VYlLtf/1M9G9VXaQ7YML48bL0xF8gRSCECAufz8fYsWNIjYcba5SUy/eMs0CXWgVs2bqVBQsWlMv3NCIpAiFEWMydOxdN28xtdQqIL8c7mFpleWhQwcfkSRPJzc0tv29sIFIEQoiQ27x5M9OmTaV5hoeWmb9fZvqvMJng7pwC/B4Xzw4bJnsWnAcpAiFESOXn5/Pk4EEkW33cnXNuN4+drUxHgDvrF7Dmp5+YNm1a+b9AjJMiEEKEjNvtZuCA/hw+lEvPBsdJigvdVOXW2R6uquLirbfeYuHChSF7nVgkRSBktoUICZ/Px3PPPcvadev5zwUF1E0J/ZDN7fWKaJzmZeTIkXz99dchf71YIUUgZExVlDu/388LL7zAsmVfcFvdIlplle91gT9iNcODjfKpkejlqScH8/3334fldaOdFIHA4wnPL6kwBr/fz3//+18+/fRTOtUupl310+86FioOKzzW9DjZDi8DBwyQMjgLUgQClyu8v6gidpUOBz3HokWL6FirmJtqls/9Aucq0Rbk8aZ5ZMW7GTCgPytWrNAlR7SQIjCwE2sMFRQU6JxExAKPx8PTQ4awePFiOtcuokMtfUrghOS4IP0uzKOKw8PgQYNYtmyZrnkimRSBgRUUFgJw9OhRnZOIaOdyuRg0cCBfLl9Ot3pF3FgzMs4yk2xBnmiaR63E0pL65JNP9I4UkaQIDOzAgQOn/FeI81FcXMwTjz/O999/z905hVxXLTJK4IQEW5DHmuaRk+pl+PDnmD9/vt6RIo4UgUEVFxdzrOxMYOeuXTqnEdEqPz+fPo/0Zt3an7i/YcGfbkCvl3gr9GlynKbpHkaNGsXs2bP1jhRRpAgMaufOnQD4HRX4+cAB3O7I/AUWkevo0aP07tWLrVs281Cj/LBNET1fcRbo1aiAlpluJk+ezKuvvip7cZSRIjCo7du3AxCITyEQCLB7926dE4locvDgQXo99CD79uykT5N8Lqp49pvP68lqhvsbFnJFtovXX3+dCRMmSBkA5bgG4PlTSq0E8sse7tA07S498xjBtm3bABNmd+Evj+vVq6dvKBEV9u7dyyO9H6bo+BEea3qc+qnRdUOi2QR35xQRbwkyd+5cioqKePTRR7FYLHpH043uRaCUigdMmqa11TuLkWzevIWgxUrQbMFksbJlyxbatWundywR4bZu3cqjffsQcOXT78K889p4PhKYTdCtXjFOa5D3P/qI4uJiBg0ahM1m0zuaLnQvAqAp4FRKfUJpngGapn2jc6aY5vP52LJlC0GzDUwmfM50Nm7apHcsEeHWrl1LvyceJz5YQv8Lj5GdEN1rVJlM0LF2CQ5rkLeWLaO4uIhnnhmKw+HQO1rYRcI1gmJgBHAd0AN4QykVCQUVs7Zs2YLH4yZoKf3rx59QEU3T5A5j8Ye+/fZbHu3bhyRTMQObRX8JnOz66i665xTyww8/8Gjfvoa8wTISimAzMEvTtKCmaZuBI0C2zpli2i9rr1jsAPiSsvH7fKxZs0bHVCJSLV68mAED+lPJ7mZQs2NkxMdOCZxwZWU3DzYsQNu0gYcfeogjR47oHSmsIqEI7gZGAiilKgPJgNzhFEJLlnxOIDGToLn0x+9PzsZkjWPp0qX6BhMRZ968eQwbNpS6SR76N8sjOYT7CeitRaaHvk2Os3/vLh584H727t2rd6SwiYQimAakKqWWA3OAuzVNi65pCFFk/fr17Ny5A096nV8Pmq14UmuwZMnnhjwtFr8XDAaZPn06Y8aM4cJ0D481PY7TGrslcELDNB/9LjxGwbFcHnqwJ1u3btU7UljoXgSapnk0TbtN07TLNU1ro2ma7CYRQm+++RYmqx1vet1TjnuyGuB2u3j//ff1CSYiRiAQYOzYsUyfPp3LK7no1aiAOAPNrKyd7GdQs2OYXMfp9dBD/PTTT3pHCjndi0CEz5o1a/jqq+W4MhuA5dRpcgFnOr7U6rzx5puGGx8VvzqxjPS8efNoV62Eey4owmLAd4nKCQEGX3SMVHMxj/btG/PLWBvwR2xMbrebkS+9BPZEPJUan/Y5rmotcLndjB8vd1sakdvtZvCgQXz22Wd0rl3ErXWLMYdgo/lokR4fYECzY1RxuBg0aCCLFy/WO1LISBEYxKRJk9i9axfFNS4Dy+ln5wbjU3BnX8jnny9h0aJFYU4o9FRcXEy/Jx7nm2++4d/1C7mxpguTgUvghNI9DY5TL8nDsGFDWbBggd6RQkKKwAAWLlzI+++/jyerIf6Uqmd8rie7Cf7kbEaOHMn69evDlFDoqbCwkEcf7cuaNWv4T4MCrq6q7wKEwSAcc5vZX2RhyT47ep+cOqxB+jY9TuM0LyNGjGDu3Ln6BgoBKYIY9+233zJy5Ej8KVVwV23x519gMlNSuy1ei4N+/fuzZ8+e0IcUuikoKKBvn0fQNm2kZ8MCWlfSfwXRJfvsHCyxkO81M11LZMk+u96RsFugd+N8mlf0MH78+JhbxlqKIIZ9//33DBw4CL+jAsV1/g/MZ/fjDtocFNb7G4UuL70efthQ86mN5EQJbNu6hV6N8mmRqX8JAKw6EnfGx3qxmqFnw1+XsY6lMpAiiFErVqxgwIABeO3JFNa/Dizn9ssUjE+hsF478gqKeajXw7/sXyBiw4nhoO3btvJwo3yaZUTOMtIev+mMj/VkNUOPBoW/lMHbb7+td6RyIUUQgz799FMGDhyEOy6FonrXgTX+vL5PwFmBwvrtyCss4cGHHmLjxo3lnFTo4cTWkic2lGkaQSUQDSxlZXBJppuJEyfGxNaXUgQxJBgMMnv2bJ599lm8iZkUqXYEbedXAicEnGkUqBso9Jp4+OHeMT+fOta53W4GDRrIho0buL9BQUSdCUSTE2VwYUbp1pfRPstOiiBG+Hw+Ro8ezeTJk/FWqEVxvb+d83DQHwnGJ1OYcwNuWxIDBgyQu4+jlM/nY9jQoaxcuYp7cgq5JEKuCUQrqxkebFhAgzQfL7zwAl999ZXekc6bFEEMyMvLo0+fvsyfPx9Ppca46rQFc/mu5B20OSlU1+NNqcro0aN58cUX8XjkjSRaBINBRo0axZfLl9OtXhFtsmWP6vIQZ4GHGx2nZqKXIUOeitrlKKQIotyqVavofs+9rF23npJaV+Cu1oKQ3QlksVFS92rc2U1YuHAhDz3US6aXRonp06ezcOFCbqxRzHXVZN+J8uSwQt+mx8mI8zKgfz927Nihd6RzJkUQpdzu0gtVj/Tpw5EiN4U5N+DLqPvnX/hXmcx4ql5MSZ2r2LxtB92738P7779PIBB7a9THio8++ogZM2bQJttFp9oleseJSUm2II82ycPqL+aJxx+LuvW6pAiiTDAYZMmSJdx+xx28/fbbeDIUBRfcTCAhI6w5fGk1KWjYgRJHBqNHj+b++x9g3bp1Yc0g/tzq1asZMeJFGqZ5uUsVybIRIVTREeCRRnkcP3qYgQP643ZHz/CbFEGUCAaDrF69mp49H+SZZ54ht9BHsboed83LfreSaNgyxSVQXO9aSmq1Qdu5hwcffJAhQ4awa9cuXfKIU+Xm5jLkycFkxft5sGEBVvltD7layX56NMhnk7aZUaNGRc3ijbI3cIQLBAJ88803zJw1i40bNmCKc+KqeTnejLpgioDfbJMJX0Y9CirUJO7ntSz7cjlLly3j8taXc/vt3cjJydE7oSH5fD6eenIw7uJC+jXPI8EWHW9IsaB5RS8dahbz/scf06hRI/7+97/rHelPSRFEKLfbzWeffcbb77zDrp07IT4JV41L8WbUK/cZQeXCYsNT5SK8mRdgO7iBr775juXLv+TCZs3o0rkzrVq1wnyWS1yIv27GjBls3KTRs2EBlWNoo/lo0aFWCVvzbYwbO4bGjRtTo0YNvSOdUQS+oxjb4cOHmT9/Pu/Pn09Bfj5BZxquWlfgS6t91msF6Sloc+Cp2hxPdmNsuRqrN2xg9YABZFeuTOdOnWjXrh1Op1PvmDFt06ZNvDFrFm0quWiZJVN89WA2wb0XFDDwexvDhz/HhAkTsVgid5s3KYIIsW3bNubMmcPixYvx+/34UqvjUa3xJ1UK3XTQULLE4c1ujDerIdZjO9mXu4GxY8cyZepUbr7pJjp27EhmZqbeKWOOz+djxIv/JcUe5Pb6xXrHMbQK9iC31y1g8gaN+fPn07FjR70j/SEpAh0Fg0F++OEH3po9m5U//ojJYsOdrvBkNSAYn6x3vPJhNuNLr40vvTbmwly8P69n9pw5vP3OO1x91VXccsst1K0bhmmvBrFw4UK2btvOQ40KcBhgs/lId2mWh+U/e3l12lSuueYakpMj8/da9yJQSpmBiUBTwA3co2naVn1ThZbf7+eLL75g1qw32LZtK6Y4J+6qzfFUzAGr/muvh0ogMRNX3Uzc7gLiDq7nsyVL+fTTT7mkZUtu79aNxo0bY4rGs58IUVxczGuvTkOl+ri4ogwJRQKTCW6rW8TA723MnDmTnj176h3ptHQvAqADEK9p2qVKqVbASOBmfSOFhsvlYtGiRcyePYcDB/aDI4WSmpfjS68D5sgdPyxvQXsS7uqtcFduRlzuRr5f9RPfffstFzRowK1du9K6deuIHk+NVAsXLiTveD4PNZf7BSJJ1UQ/rbNcfDD/fbp160ZqaqrekX4nEq4+Xg58DKBp2jfAxfrGKX9Hjhxh6tSp/LNTZ0aNGsW+fC8lda6ioOE/8FWsb6gSOIXVjqfyheQ37oyrxqVs3L6HJ598ktu6deO9996juFjGuM+W3+/n7TmzyUn1US/Fp3ecv6TEZyI+Pp5OnToRHx9PiS/6W619DRduj5cPPvhA7yinFQlnBMnA8ZMe+5VSVk3TovtfM7Bhwwbee+89Pv/8c/x+P97UGnhz2uBPzIrOC8ChYrbizbwAb0WF9dhuDhxc98uF5b+3b0+HDh2oUqWK3ikj2po1azh0+AhdGkb/EhLFPhN///vfefDBBwkGg3yxMPo3f6mS4KdBBR+LPv6IO+64I+KGQCOhCPKBpJMem6O5BLxeL59//jlz332XzZqGyRoXexeAQ8VkxpdWE19azdILywfX887cd3ln7lxatmzJPzt2pEWLFhH3SxQJvvrqK+wWExdmRP+1Aac1yIIFCwgGgyxcuJCsGLno3TLTxWvaAXbt2kXNmjX1jnOKSCiCr4AbgbfLrhGs1TnPecnLy+PDDz/k3ffeI+/YMXCk4qreqvQGMJ2WgIhmgcRMXImZuD3F2A5t4tuVa/j2m2+oVr0Gt3TpzN/+9jfs9ti9sH6utmzZTLVEL/YYGGV0WIO4Cl28++67pY9TY6MI6pYN2W3bti16ikAp9Ye7mmiaVp5/dswD/qaU+howAXeV4/cOuQMHDvDWW2/x0Ucf4fV68adUwV2/Bf7kKjL8Uw6CcU48VS7Ck90U69Ht7M7dwIgRI3j5lVfo9M9/0rFjR5KSkv78G8W4Y0ePUCnOr3cMcQYV7KV3eB89elTnJL93pjOCtUAWcJTSN+jgSf+tXV4BNE0LAD3K6/uFy/79+5k1axYff7yIAOBJq4O3UkMCjgp6R4tNZgu+jHoUptfFUvAzvoPreO2115g9ew6dO3eiU6dOETtHOxySU1Ip3BcJcz/EHynwlP5hmJKSonOS3ztTEVwOLAKu1jTtWJjyRLzc3FxmzJjBRx99RBAT7gyFJ7sxwbgEvaMZg8mEPzmbkuRszMVH8O5fw+uvv87b77xD11tuoUuXLoZcwiIn5wLmb9xAgcdEUlxsDKXEmlVHSgdZ6tevr3OS3/vDPyE0TTsE9AMuCl+cyJWXl8fEiRO57bZuLPzoY1wZORQ07oy7RqvoLIFgEJOnGHNJHrbcTRAly+WeLOBMx1X3KooadqAgPpPp06dzyy1defvtt6NqLfjy0L59e3wB+GiPQ+8o4jRKfCY+3eekUcOGEXd9AP7kYrGmaZ+EK0ikKigo4O233+btd97B7XbjTa+Lu3IzgvZEvaP9JbZDm7C48wGI3/U1EMSbeYG+oc5TwJmGq+7VeAoP4d/3IxMnTmT2nDn8+1//4oYbbsBmi/2L9bVr16Zdu3Ys/PhjGlTw0ijNq3ckUSYYhFc3JXDMbWFIj8gcBf/DMwKlVEWl1Ail1DClVPpJx58KTzR9FRcXM2vWLG7p2pWZM2dS6KhEUcN/4KrVJupLAMCat+eMj6NRILEixaodxep6DnssjBo1im7dbufjjz/G74/9C6kPP/ww1atXY9z6ZDbnRcKEQBEIwqwtTr7NtdO9e3caN26sd6TTOtPVpdeBzcB+4Aul1IkFta8MeSodud1u3nnnHbreehtTp04l35ZGUcObcdW9ioAjVe945SfgO/PjKOZPzqZItae43t84WOTn+eef59933snSpUtjem9lh8PBiyNGkp5ZmRfXpPDTkdg/E4pkvkDpmcCnex106dKF2267Te9If+hMfzbEa5r2CoBSajUwXynVltKZQzEnGAyyfPlyRo8Zy5HDh/AnZ+O64HICibJUclQymfCnVqMwpSrWY7vYs38lQ4YMoV79+vTt0ydmd07LzMxk7LjxPPZoX0b+tIMutYu4obpLZjKHWZ7bxPiyM7N///vf3HnnnRF9I+SZzggsSqnGAJqmfQ0MBz4AIm/u01904MAB+vfvz+DBgzlc7P9leEFKIAaYTPjSalLYsAMltdqwdedeetx/P2PGjKGwsFDvdCGRlpbGuPETuPLKtszZlsD4dYkUx8B6PdFCy7Py1I9p7Cp2MHjwYO66666ILgE4cxHMB6YqpbIANE2bA7wCRPaea+do9erVdL/nHr79/kdc1S6hsMFN+JMr6x1LlDeTGV9GPfIbdsRT8QLmzZvHfT16cODAAb2ThYTT6eSpp56iR48e/HjEweAfKrA9PwZuO45ggSB8sNPBc6tScKZlM2HiJK6++mq9Y52VMxVBNSADeEop1RRA07RZQMVwBAuHL774gr6PPkpxwEZBg5vxVmoUGRvCi9CxxuGu0YrinBvYf/AQPe6/n61bY3P7C5PJRNeuXRk3bhymhIoMXZnKx7vjo3GmcMTLc5t4cU0yc7c7ueqqq5kydVpUbbh0pvsIegM5wBLgOaXUV0qp7kB8mLKF1M6dOxk6bBje+DQKctrLgnAG40+qRKFqz/ESLwMGDqKoqEjvSCHTsGFDpk57lUsvbc2bWxMYtTaJAm9kD1VEk3VHbQz6IY2thU4ee+wxBg0aFHU3NZ7xz19N07yaps3VNK090BmoB+wOS7IQ8vv9PDN0KL6gmeI6V8X0rmDijwUcqRTXaktu7kHGjRund5yQSk5OZuiwYfTq1Yv1eQ6e/CEtYoeK4izBMz6OFIEgzN/h4MXVyaRVqs7kl1+hffv2EX894HT+dBxEKRWvlLoVmEbpshOPhzxViC1dupTt27ZRXK0Vwbjoam5RvvxJWXiyGrJo0SJ27476v3HOyGQy0bFjR8aNn4AlMYNhK1P5fF/k/RHULN1zxseRoMhrYtRPyby7w8k1f7uGSZNfplatWnrHOm9nuqGsrVLqNWAT0BJ4TNO0yzVNezVs6UJk9pw5BB2p+NKi9wcnyo+nUmMwW5g7d67eUcIiJyeHKVOnceFFzXlNS+T1zU58EXR7xVVV3GQ5/CTbAtypCrmqSmQtF3KgyMzTKyuwLs9O7969GTBgIA5HdC/tcaYzgiHAp4DSNK23pmnrwhMptA4dOsSWzZvxpNeVZaIFAEGbA09yVb5cvpygQa6kpqSk8PzzL9ClSxc+2+tgxE8pFEXIdQOTqXTJ5soJfq6q4o6oX9P1R608vbICJZZkXnppFB06dIjKoaDf+sMbyjRNaxvGHGFzYoaIPzFL5yQikvgTszi2ZyfHjh0jLS1N7zhhYbVaeeCBB6hVqxYjR4xg6MoK9G2SR0VHBJ0eRJBl++1M1xKpXqMGzw1/nuzsbL0jlRvDzZWMjy+b9BSM/bVnzsjvOWWDcPyRNw4bTqayfw+//PswkOuvv54XR4wgnwSeXin3G/xWMAhztzmYtimRZs2bM278hJgqATBgEdSoUQNbXFzp0ssGZvJ5ftkgvH379ph8Bi6CgB/7kS1UqVo16sd6z1ezZs2YMHESztRMhq9KZdVhWacIStcLenlDIh/sctK+fXuef/4FEhOjf9HJ3zJcEaSlpXF7t27Yju3EdkjTO45ugtY4FixYwLhx41i4cCFB6x/uTBrbgkHse76FkuM89OCDMTHee75q1KjBxEmTqVmnHqPXJvPZ3sibURRORV4TL65J4euDdu6++24effRRrNbYXNXVcEUA0LVrV1q0uIT4nV8Rd+CnqNyU5S+zxOFylW4Q7nK5wGLAIgj4id/xBXG5m+jSpQutWrXSO5Hu0tLSGD1mLJdeehmvb07kjS1OAgb89cgtMTN0VQW25NsZMGAA//rXv2L6jwRDFoHdbue5556lbdu22Pf+QPz2pYYfIzcak7uABO1/2I5s45577uH+++/XO1LEcDgcDB06lI4dO7Joj4NRPyVTYqBF6zYdszLkxwoUkMiLI0Zw7bXX6h0p5HQ9z1FKmYC9wJayQys0Tesfjte22Ww8+eST1KtXj2nTpmHbcISiWlfIiqMGYD26HeeuFcTHWej39NNceWVMb7FxXiwWC7169aJGjRqMGTOGZ1ZaeLjRcSo5Y3tG0ef77Ly+JZHKlasw/PkXqFq1qt6RwkLvAa86wEpN027U48XNZjPdunWjSZMmDHn6Gdi0EHelJngqXwhmmTkRc3wu4netwHZ0B/Vzchjy1FMxN/ujvN18881Uq1aNIU89yZAfzdzfIJ+m6bG3DaY3ADM3J7B0fzyXtGjB4CefJCkpSe9YYaP30FBzoIpS6nOl1P+UUkqPEI0bN2bG9Ndod9112A+sIXHjh5gLD+kRRYRCMIj16A6S1r+P/fhuunfvzoTx46UEztJFF13Ey69MoXL12ry0Jpl5Oxwxdd3gsMvMsytTWbo/nm7dujH8+ecNVQIQxjOCspVLH/nN4Z7AcE3T3lFKXQ7MAlqEK9PJEhMT6devH23atGHEyJcwbVqAJ/MC3FWag0Wm0kUrk7uQ+N3fYM3bTZ26den3xBPUq1dP71hRJzs7m/ETJvLSSy8x75NP2HrcRo8GBSTFRXcjrD1iY9LGZAKWeJ55ZgBXXHGF3pF0EbYi0DRtGqUL1/1CKeUEfGWfX66UqqyUMmmaptu/rtatW9O0aVOmTJnC/A8+IC5vFyVVW+KrUEOWpIgmwQC2gxtw7F+F1WKie48edOrUKWan/4VDfHw8/fv3p3HjxowdM5onf7TRs8Fx6qZE337XgSC8v8PB/J1OatWsydNDh1KtWjW9Y+lG76Ghp4DeAGWb3+zRswROSExM5JFHHmHC+PHUrJyFY9sSHFs+xeQu0DuaOAvmwlwSN3xA/J7vaHHxRcyYPp2uXbtKCZQDk8nEjTfeyPgJE4lLzuTZlSl8sie6NrvJ95RuIvP+TifXtWvHxMmTDV0CoP/F4ueBWUqp9pSeGdypb5xTNWzYkKlTXmHevHlMnTYN2/p5uLKb4slqJBeTI5HPjX3vD8Qd0khPz+Dhfs/Qpk2bmJ7/rRelFK9Mncbw4cOZ9fXXbMu3cndOIfYI/7XYlm9l/PoU8n1WHnvsEdq3b693pIigaxFomnYMiOifhNVqpXPnzlx55ZWMGzeOL7/8krij2ymp1lL2No4UwSDWw1tw7v8Rk89Npy5duPPOO6Nul6hok5SUxLBhw3jzzTeZNm0qe4ttPNLoOBkRumjdVwfimKYlkZ5RkQnDnqV+/fp6R4oYeg8NRY3MzEyGDh3Kc889R6VkO07tYxxbl8hwkc7MhbkkbFqAY+dycurW4uWXX+aBBx6QEggTs9nM7bffzgsv/Jej/gSGrKzAluN6DzScKhCEOVudvLwxicZNL+SVKVOlBH5DiuAcXXbZZbw+Ywbdu3fHWXSAxHXvYd/1DSZvid7Rzo3ZeubHEc5ccoz4rYtJ2LiANJufAQMGMHHCBJkRpJNLLrmEiZMmk5SezfOrU1h5KDJm2vkCMHlDIgt3O7jpppt48cURpKSk6B0r4kgRnAe73c4dd9zBrFkzaX99O+IPbyJp7Vzi9vyAyevSO95Z8aVWO+PjSGVyHSd++zIS1s0jyZXLv//9b958YxbXXnutXAvQWY0aNZgwcRJ16tZn7Lpklh/Qd/0qjx9Gr03mm4N27rvvPvr06SMTBv6AFMFfkJmZyWOPPcbrr7/OVW2vwH5wLUlr38G+5ztM3mK9452Rt2IOfnsyAWs8rhqX4a2Yo3ekMzKXHCN+21IS172HM383Xbt2ZfZbb3HXXXfJMFAESU1N5aVRo2nW7CKmbEziq5/1KYMTJbD2qI3HHnuMW2+9VZcc0ULqsRxUrVqVwYMHc8cdd/DGG2/w2WefYc/dhLuiwpPdhKAtAte4N5kIxjkJ4sSbGbklYC7JI27fKmzHdmC3x/OPW26hc+fOpKen6x1N/AGn08lzw4fTr98TvLJ6NXZLARdXDN+ijv4ATFifxLqjNp544gmuv/76sL12tJIzgnJUs2ZNBg4cyMyZM7nu2muw524oHTLatxKMvPHLeTC5C7Hv+JKE9fNILDnA7bffzpw5s+nRo4eUQBQoXeF3OBfk5DBpQ1LYLiAHgzBzSwKrDsfx8MMPSwmcJSmCEKhatSr9+vVjxowZXHH5Zdj3ryZ5/btYj+4w5t4H5yIYIO7ATyStew9n3k46d+rEnNmzueeee0hNTdU7nTgHDoeD54Y/T2ZWNqPXpnC4JPRvN4v2xrNkXzy33nor//jHP0L+erFCiiCEqlevztNPP83kyZOpU6Mqjm2f49i2JPpmGIWJufgYCRsXYN/7A5dd2pI33phFz549pQCiWGpqKs+/8F8CVgej16XgDuFW4euO2nhrawJtLr+ce++9N3QvFIOkCMIgJyeHyZMmcd999xFfsJ/EjR9gLszVO1ZEsR7eSuKmD0m1+hgyZAjDhg0jKytL71iiHFSrVo0nnxrCnkIzr25KDMlJ8aESMxM3JFOjenX6DxiA2SxvbedC/t8KE6vVyq233srkyZPIqpBUujvWwQ0yVBTwY9+1AseOL2jcsCHTX3uVtm3bylTQGNOyZUvuvrs7Kw7a+XRvfLl+b48fxq1PIWh1MOzZ52QW2XmQIgizunXrMnXKFFq2uIT43d+UbZMZext9nA2Tu5AE7X/E5W6kS5cuvPTSSNLS0vSOJUKkW7duXHbZZby1NYHNeeVz8TgYhBmbE9iZb2bgoMGG2VGsvEkR6CApKYnhw5/j3nvvJe7YTpI2zMdS8LPescKnbG2gpA3zSfAXMXToUB544AG52SfGmc1m+vfvT6XsbMZvSCHP/dfP+pbut/PlgXjuuOMOLrvssnJIaUxSBDo5sU3mmDFjyEp14tz0P+y7VsT82YHJXYhjy6c4dnxJg5x6TJ06hTZt2ugdS4RJUlISQ4c9S0nAxoT1yfj+wvp02/MtzNySyMUXN+fOO+8st4xGJEWgsyZNmjD9tdf45z//SdyhTSSvfw/rkW2xd+0g4CfuwBqS1r+Hs+QQvXr1YtzYsVSpUkXvZCLMateuTd9HH0PLszJ3+/mN5xd6TYxfn0paegaDBg3GYonw9a8jnBRBBHA4HDz00ENMnDCBujWq4Ni+DKf2Eebio3pHKxeW43tJ2vA+9r0/0vrSVsyYMZ2OHTvKzA4Du/baa7npppv4324Hqw6f2wJ1wSBM2ZhInsfC088MlenF5UB+EyNIgwYNmDxpEn379iU5WETChvnYd30DPrfe0c6LyV2AY+tnODd/QnaFRP773/8ybNgw2TReANCzZ0/q1qnN1E3JHPec/fWCJfvsrDocx309enDBBReEMKFxSBFEGIvFwo033sibb8ziphtvJO7QxrLhou3RM1wUCJQOA62bh7PoIPfeey8zpr/GJZdconcyEUHsdjuDBj+JO2g76/sLDhabeWtbIi1aXEynTp1CH9IgpAgiVEpKCn369OGVl18uvSt5+1IcWxdj8kT2qqbm4iMkbvoQ+94fubz1pcyaNZNu3boRF6fvksQiMtWsWZN77r2XVYfj+PHwmf+NBIPw+uZErHHxPP74E3KvSTmSIohw9evXZ/KkSfTo0QNH0QGSNryPJW+33rF+LxjE9vM6EjZ+SKrNz9NPP83QoUPJzMzUO5mIcB07dqR2rZq8uTUJ7xlmEa0+YmPtURt3d7+HihUrhi+gAUgRRAGr1UrXrl2ZNm0atapXwbnlM+y7v4VAhOwN63Pj2LqY+D3fcdmllzLz9de58sor9U4looTVaqXH/Q9wuASWH7Cf9jnBIMzbmUjl7Ep06NAhvAENQIogilSvXp1JEyfSoUMH4g6ux7llke47oplLjpG0aQH2gn306tWLZ4cNIzk5WddMIvq0aNGCnBzFR3sTTnutYGOelZ35Zm6/419y42EIhL0IlFL/UEq9edLjVkqpb5VSXymlngp3nmhjt9vp3bs3/fv3x158mMRNH2IuPqZLFkveHhI3LiDFbmL06NF07NhRxm3FeTGZTNx8cwd+LjKxNf/3b/RfHrDjdMRz9dVX65Au9oW1CJRSY4Dhv3ndycBtwOVAS6VUs3BmilbXXXcd48ePI9VhI1FbiOX43vC9eDCI7ef1OLd+Rp1aNZnyyis0btw4fK8vYtKVV16JzWrhh0OnXjT2B2DVkXiubPt/2O2nHzoSf024zwi+Bu4/8UAplQzYNU3bpmlaEFgEXBPmTFErJyeHV16eTM3qVXFu+RRb7qbQv2gwgH33N8Tv+ZbLW7dm3LixckFYlAun00nDho3YcOzUN/udBVaKvaXDRyI0QjLYppTqDjzym8N3aZo2RynV9qRjyUD+SY8LgNqhyBSrMjMzmTB+PEOefprvvv0ak7sAT9WLIRRDNH4vju1Lsebt4ZZbbuG+++6Tu4NFuWrcpAlv/LSGusl+zGX/hLcXlL5NNWrUSMdksS0kRaBp2jRg2lk8NR9IOulxEpAXikyxzOl08tyzzzJ27Fg++OADzJ4iXLXagLn81l8xeUtwbvkUS/ERHu7dW2ZuiJCoW7cugSB4/CbiraVXjfcUWkhOSpQpoyGk659zmqblAx6lVB2llAm4DvhSz0zRymq18sgjj3DvvfdiO7od55ZPym0lU5O7gMRNC7F78xk2bJiUgAiZatWqAeA5aWZ0bomFatWqy0SEEIqE8/oewBvAd8AqTdO+1TlP1DKZTHTr1o0BAwZgKzxIwuZFf3mdIpPrOIna/0iwBBg9ahStW7cup7RC/F6lSpUA8AZ+fdM/5LZRSdanCqmwT8jVNG0psPSkx98ArcKdI5Zde+21OBwOhgwZQsKWTylS7cB87j9qk6eIJO0jkhxxjHppJHXq1AlBWiF+5XQ6SUxw4vUWABAIwjEXMiEhxCLhjECEQJs2bRg8eDDmwlzid3597gvW+X04ty4mzhxg9KiXpARE2GRkZJBqD3BFtotCrwlfALk+EGJSBDGsbdu23HXXXdiObMV6bOc5fW3c/lWYiw7z1JNPUru2TOQS4ZNRMROzyczl2R6OukvfojIyMnROFdukCGJct27dqFmrNo6930PAd1ZfY3LlY89dz3XXXSf7wIqwy8zM5KindCjzqMv8yzEROlIEMc5qtfLQgz3BXYjt8Naz+pq4Az9hs1j4z3/+E+J0QvxeVlYWea4g3gAccZdOgZahodCSIjCAiy66iPpKEZ+77k+vFZi8xcQd3cYNN9xAenp6mBIK8asTM4cOu8wcKjFjj7ORlpamc6rYJkVgACaTia633AIl+X+6JpEtV4OAn86dO4cpnRCnOrGV6aESC4dKLFSqVEnuIQgxKQKDuOKKK0hLT8eeu+GPnxTwYz+scckll1C1atXwhRPiJFWqVAHgYImFgy4rVapW0zlR7JMiMAir1crNN92E5fg+TK780z8nbxd4iunYsWOY0wnxq7S0NOz2OA4Wm8ktMVO5cmW9I8U8KQIDad++PWazGdsh7bSfjzu0mYqZmbLKo9CVyWSiSnY2W47b8Ph/PUMQoSNFYCAZGRm0atWK+KPbIHjqNpcmdwGW/P3c+Pe/Y7GU32J1QpyP7CpV2VG26mi2LC8RclIEBnP99dcT9BRjOb7vlOO2I9uA0g1vhNDbiZlDv/1YhIZs/mkwrVq1IiExCe/R7Xgz6pUeDAaxH91OkyZNycrK0jegEJx634DcTBZ6ckZgMDabjSuvaEPc8b340mrjy6iH2ZUHJXlcffVVescTAjh1SQmn06ljEmOQIjCg1q1bE/S5sRTmAvxyb4EsJyEiRWpqqt4RDEWKwICaNGmCyWTCUngQAEvBQbIrV5Hb+EXESElJ0TuCoUgRGFBSUhLZlStjLj4CQJzrGA0bXKBzKiF+lZiYqHcEQ5EiMKhaNWtic+eD30fQVUD16tX1jiTELxwOh94RDEWKwKCysrIweYoweYsAmaInIktcXJzeEQxFisCg0tPTCfo8mN2lWwLK6o4ikkgRhJfcR2BQJ2ZlmEvyTnksRCSwWCxc3Lw5V119td5RDCHsRaCU+gfQWdO02056PALYU/aUpzRNWxbuXEYjRSAimclkYsTIkXrHMIywFoFSagxwHbD6pMPNgcc1TXs3nFmM7sQbv6WsCGS6nhDGFe5rBF8D9//mWHPgbqXUl0qpkUopGa4KgxNv/GZXHg6nE5vNpnMiIYReQvKmq5TqDjzym8N3aZo2RynV9jfHPwXeB3YAk4EewPhQ5BK/OnFGYPJ7SEnJOPOThRAxLSRFoGnaNGDaWT79VU3T8gCUUvOBf4YikzhVQkICFosFv99PWoVUveMIIXSk6/RRpZQJ+EkpdWJfxKuBH3WMZBgmk4mk5NLhIbk+IISx6VoEmqYFgXuA95RSywAnMEXPTEaSlFR6G39ycrLOSYQQegr7hVlN05YCS096/AnwSbhziNI1h0DWdRHC6OTOYgNLTEgAZL13IYxOisDAzObSH39CWSEIIYxJikAQHx+vdwQhhI6kCIQUgRAGJ0UgpAiEMDgpAiHLSwhhcFIEApPJpHcEIYSOpAiEEMLgpAiEEMLgpAiEEMLgpAiEEMLgpAiEEMLgpAiEEMLgpAiEEMLgpAiEEMLgpAiEEMLgpAiEEMLgpAgM7P/+7/8AqF69us5JhBB6CvtWlSJyXHvttVx66aWyZ7EQBidnBAZmMpmkBIQQ4TsjUEqlALOAZCAO6KNp2gqlVCtgDOADPtE07elwZRJCCBHeM4I+wGJN064E7gQmlB2fDNwGXA60VEo1C2MmIYQwvHBeIxgFuE96XZdSKhmwa5q2DUAptQi4BlgVxlxCCGFoISkCpVR34JHfHL5L07TvlVKVKB0i6k3pMFH+Sc8pAGqHIpMQQojTC0kRaJo2DZj22+NKqcbAbOBRTdOWlZ0RJJ30lCQgLxSZhBBCnF7YrhEopRoA7wC3aZr2EYCmafmARylVRyllAq4DvgxXJiGEEOG9RjAciAfGKKUAjmuadjPQA3gDsFA6a+jbMGYSQgjDMwWDQb0znBOl1CFgl945hBAiytTQNK3i6T4RdUUghBCifMmdxUIIYXBSBEIIYXBSBEIIYXBSBEIIYXBSBEIIYXBSBEIIYXCyMY1BKaXMwESgKaWLAd6jadpWfVMJ8SulVEvgBU3T2uqdJdbJGYFxdQDiNU27FOgHjNQ3jhC/Uko9DkyldDUCEWJSBMZ1OfAxgKZp3wAX6xtHiFNsAzrqHcIopAiMKxk4ftJjv1JKhgpFRNA07V3Aq3cOo5AiMK58Tl0C3Kxpmk+vMEII/UgRGNdXwA0AZftGr9U3jhBCLzIUYFzzgL8ppb4GTMBdOucRQuhEVh8VQgiDk6EhIYQwOCkCIYQwOCkCIYQwOCkCIYQwOCkCIYQwOJk+KsRpKKVGAs2BSoAT2A4c0jStczm+xoOapo0vr+8nxPmS6aNCnIFS6k4gR9O0fiH43j9rmlapvL+vEOdKzgiEOAtKqWRKV8NMBSoDEzRNm6SUWgrkAmnAzcD0ss/vAa7QNK2yUqoxMJbSG/eOAHcDDwJpSqmJmqY9EN7/NUKcSq4RCHF26gKzNU27FrgW6HPS597SNO0a4B5gh6ZprYEhQFbZ56cAPcvW1f8f8Limac8CR6UERCSQMwIhzs5BoLdSqiOlC/bZTvqcVvbfC/h1ae9NSqlDJx2fqJSi7Ou2hCWxEGdJzgiEODt9gRWapt0OvEPpMM8JgbL/rgMuBVBK1QEyyo5rwL/KzggeBxaUHT/5ewihGzkjEOLsfAiMU0p1BfIAn1LK/pvnTAOmK6W+AHYBrrLj9wOvl+33EAS6lx3foJSaVVYuQuhGZg0JUU6UUpcBiZqmfaKUqgd8rGlaHb1zCfFn5IxAiPKzHXhLKfUUpdcCeuqcR4izImcEQghhcHKxWAghDE6KQAghDE6KQAghDE6KQAghDE6KQAghDO7/AZ2RFVzQSCfHAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 51;\n                var nbb_unformatted_code = \"sns.violinplot(data=data,y=data.columns.tolist()[20],x=\\\"Target\\\")\\nplt.savefig('violin3.png')\";\n                var nbb_formatted_code = \"sns.violinplot(data=data, y=data.columns.tolist()[20], x=\\\"Target\\\")\\nplt.savefig(\\\"violin3.png\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.violinplot(data=data,y=data.columns.tolist()[20],x=\"Target\")\n",
        "plt.savefig('violin3.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.violinplot(data=data.iloc[:,30:40])\n",
        "plt.savefig('violin4.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    sns.displot(data=data,x=col,hue='Target',kind='ecdf')\n",
        "    plt.title('Empirical cumulative distribution')\n",
        "    plt.savefig(f'ecdf_{col}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>level_1</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>V18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>V18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>V18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>V18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>V18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>V18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>V18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>V18</td>\n",
              "      <td>-0.921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>V18</td>\n",
              "      <td>-0.978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>V18</td>\n",
              "      <td>-0.343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   level_0 level_1  Target\n",
              "0        0     V18     NaN\n",
              "1        1     V18     NaN\n",
              "2        2     V18     NaN\n",
              "3        3     V18     NaN\n",
              "4        4     V18     NaN\n",
              "5        5     V18     NaN\n",
              "6        6     V18     NaN\n",
              "7        7     V18  -0.921\n",
              "8        8     V18  -0.978\n",
              "9        9     V18  -0.343"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 80;\n                var nbb_unformatted_code = \"data[['V18','Target']].rolling(min_periods = 1, window = 3).corr().iloc[0::2,-1].reset_index()[:10]\";\n                var nbb_formatted_code = \"data[[\\\"V18\\\", \\\"Target\\\"]].rolling(min_periods=1, window=3).corr().iloc[\\n    0::2, -1\\n].reset_index()[:10]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data[['V18','Target']].rolling(min_periods = 1, window = 3).corr().iloc[0::2,-1].reset_index()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>level_1</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>V22</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>V22</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>V22</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>V22</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>V22</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>V22</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>V22</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>V22</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>V22</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>V22</td>\n",
              "      <td>-0.760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>V22</td>\n",
              "      <td>-0.621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>V22</td>\n",
              "      <td>-0.967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>45</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>48</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>50</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>51</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>52</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>53</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>54</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>55</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>56</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>58</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>59</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>61</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>62</td>\n",
              "      <td>V22</td>\n",
              "      <td>-0.655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>V22</td>\n",
              "      <td>-0.704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>64</td>\n",
              "      <td>V22</td>\n",
              "      <td>-0.761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>68</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>69</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>70</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>71</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>72</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>73</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>74</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>76</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>77</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>78</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>79</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>80</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>81</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>82</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>83</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>84</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>85</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>86</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>87</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>88</td>\n",
              "      <td>V22</td>\n",
              "      <td>-0.525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>89</td>\n",
              "      <td>V22</td>\n",
              "      <td>-0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>90</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>91</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>93</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>V22</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    level_0 level_1  Target\n",
              "0         0     V22     NaN\n",
              "1         1     V22     NaN\n",
              "2         2     V22     NaN\n",
              "3         3     V22     NaN\n",
              "4         4     V22     NaN\n",
              "5         5     V22     NaN\n",
              "6         6     V22     NaN\n",
              "7         7     V22   0.965\n",
              "8         8     V22   0.992\n",
              "9         9     V22   0.920\n",
              "10       10     V22   0.000\n",
              "11       11     V22   0.000\n",
              "12       12     V22   0.000\n",
              "13       13     V22   0.000\n",
              "14       14     V22   0.955\n",
              "15       15     V22   0.884\n",
              "16       16     V22   0.429\n",
              "17       17     V22   0.069\n",
              "18       18     V22   0.520\n",
              "19       19     V22     NaN\n",
              "20       20     V22     NaN\n",
              "21       21     V22   0.677\n",
              "22       22     V22   0.970\n",
              "23       23     V22   0.963\n",
              "24       24     V22   0.000\n",
              "25       25     V22   0.000\n",
              "26       26     V22   0.000\n",
              "27       27     V22   0.000\n",
              "28       28     V22   0.000\n",
              "29       29     V22   0.000\n",
              "30       30     V22   0.000\n",
              "31       31     V22   0.000\n",
              "32       32     V22   0.000\n",
              "33       33     V22  -0.760\n",
              "34       34     V22  -0.621\n",
              "35       35     V22  -0.967\n",
              "36       36     V22   0.000\n",
              "37       37     V22   0.000\n",
              "38       38     V22   0.000\n",
              "39       39     V22   0.000\n",
              "40       40     V22   0.000\n",
              "41       41     V22   0.000\n",
              "42       42     V22   0.000\n",
              "43       43     V22   0.000\n",
              "44       44     V22   0.000\n",
              "45       45     V22   0.000\n",
              "46       46     V22   0.000\n",
              "47       47     V22   0.000\n",
              "48       48     V22   0.000\n",
              "49       49     V22   0.000\n",
              "50       50     V22   0.000\n",
              "51       51     V22   0.000\n",
              "52       52     V22   0.000\n",
              "53       53     V22   0.000\n",
              "54       54     V22   0.000\n",
              "55       55     V22   0.000\n",
              "56       56     V22   0.000\n",
              "57       57     V22   0.000\n",
              "58       58     V22   0.000\n",
              "59       59     V22   0.000\n",
              "60       60     V22   0.000\n",
              "61       61     V22   0.000\n",
              "62       62     V22  -0.655\n",
              "63       63     V22  -0.704\n",
              "64       64     V22  -0.761\n",
              "65       65     V22   0.000\n",
              "66       66     V22   0.000\n",
              "67       67     V22   0.000\n",
              "68       68     V22   0.000\n",
              "69       69     V22   0.000\n",
              "70       70     V22   0.000\n",
              "71       71     V22   0.000\n",
              "72       72     V22   0.000\n",
              "73       73     V22   0.000\n",
              "74       74     V22   0.000\n",
              "75       75     V22   0.000\n",
              "76       76     V22   0.000\n",
              "77       77     V22   0.000\n",
              "78       78     V22   0.000\n",
              "79       79     V22   0.000\n",
              "80       80     V22   0.000\n",
              "81       81     V22   0.000\n",
              "82       82     V22   0.000\n",
              "83       83     V22   0.000\n",
              "84       84     V22   0.000\n",
              "85       85     V22   0.000\n",
              "86       86     V22   0.000\n",
              "87       87     V22   0.397\n",
              "88       88     V22  -0.525\n",
              "89       89     V22  -0.808\n",
              "90       90     V22   0.000\n",
              "91       91     V22   0.000\n",
              "92       92     V22   0.000\n",
              "93       93     V22   0.000\n",
              "94       94     V22   0.000\n",
              "95       95     V22   0.000\n",
              "96       96     V22   0.000\n",
              "97       97     V22   0.000\n",
              "98       98     V22   0.000\n",
              "99       99     V22   0.000"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 74;\n                var nbb_unformatted_code = \"data[['V22','Target']].rolling(min_periods = 1, window = 3).corr().iloc[0::2,-1].reset_index()[:100]\";\n                var nbb_formatted_code = \"data[[\\\"V22\\\", \\\"Target\\\"]].rolling(min_periods=1, window=3).corr().iloc[\\n    0::2, -1\\n].reset_index()[:100]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data[['V22','Target']].rolling(min_periods = 1, window = 3).corr().iloc[0::2,-1].reset_index()[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CjaGOdvbp08"
      },
      "source": [
        "### Let's look at the values in target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jchAb6Ikbp08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0   0.945\n",
              "1   0.056\n",
              "Name: Target, dtype: float64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 27;\n                var nbb_unformatted_code = \"data[\\\"Target\\\"].value_counts(normalize=True)##  Complete the code to check the class distribution in target variable for train data\";\n                var nbb_formatted_code = \"data[\\\"Target\\\"].value_counts(\\n    normalize=True\\n)  ##  Complete the code to check the class distribution in target variable for train data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data[\"Target\"].value_counts(normalize=True)##  Complete the code to check the class distribution in target variable for train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp8vC9MZbp09"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IktO9G2Lbp09"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 28;\n                var nbb_unformatted_code = \"# Dividing data into X and y\\nX = data.drop([\\\"Target\\\"], axis=1)\\ny = data[\\\"Target\\\"]\\n\\nX_test = data_test.drop(['Target'],axis=1) ##  Complete the code to drop target variable from test data\\ny_test = data_test['Target'] ##  Complete the code to store target variable in y_test\";\n                var nbb_formatted_code = \"# Dividing data into X and y\\nX = data.drop([\\\"Target\\\"], axis=1)\\ny = data[\\\"Target\\\"]\\n\\nX_test = data_test.drop(\\n    [\\\"Target\\\"], axis=1\\n)  ##  Complete the code to drop target variable from test data\\ny_test = data_test[\\\"Target\\\"]  ##  Complete the code to store target variable in y_test\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Dividing data into X and y\n",
        "X = data.drop([\"Target\"], axis=1)\n",
        "y = data[\"Target\"]\n",
        "\n",
        "X_test = data_test.drop(['Target'],axis=1) ##  Complete the code to drop target variable from test data\n",
        "y_test = data_test['Target'] ##  Complete the code to store target variable in y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "j-8vqBMXbp09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15000, 40) (5000, 40) (5000, 40)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 29;\n                var nbb_unformatted_code = \"# Splitting data into training and validation set:\\n\\nX_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.25) ## Complete the code to split the data into train test in the ratio 75:25\\n\\nprint(X_train.shape, X_val.shape, X_test.shape)\";\n                var nbb_formatted_code = \"# Splitting data into training and validation set:\\n\\nX_train, X_val, y_train, y_val = train_test_split(\\n    X, y, test_size=0.25\\n)  ## Complete the code to split the data into train test in the ratio 75:25\\n\\nprint(X_train.shape, X_val.shape, X_test.shape)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Splitting data into training and validation set:\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.25) ## Complete the code to split the data into train test in the ratio 75:25\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "28L1vgAwbp09"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 30;\n                var nbb_unformatted_code = \"# creating an instace of the imputer to be used\\nimputer = SimpleImputer(strategy=\\\"median\\\")\";\n                var nbb_formatted_code = \"# creating an instace of the imputer to be used\\nimputer = SimpleImputer(strategy=\\\"median\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# creating an instace of the imputer to be used\n",
        "imputer = SimpleImputer(strategy=\"median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FNfbw4rJbp09"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"# Fit and transform the train data\\nX_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\\n\\n# Transform the validation data\\nX_val =  pd.DataFrame(imputer.fit_transform(X_val),columns=X_val.columns) ## Complete the code to impute missing values in X_val\\n\\n# Transform the test data\\nX_test =  pd.DataFrame(imputer.fit_transform(X_test),columns=X_test.columns)  ## Complete the code to impute missing values in X_test\";\n                var nbb_formatted_code = \"# Fit and transform the train data\\nX_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\\n\\n# Transform the validation data\\nX_val = pd.DataFrame(\\n    imputer.fit_transform(X_val), columns=X_val.columns\\n)  ## Complete the code to impute missing values in X_val\\n\\n# Transform the test data\\nX_test = pd.DataFrame(\\n    imputer.fit_transform(X_test), columns=X_test.columns\\n)  ## Complete the code to impute missing values in X_test\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Fit and transform the train data\n",
        "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "\n",
        "# Transform the validation data\n",
        "X_val =  pd.DataFrame(imputer.fit_transform(X_val),columns=X_val.columns) ## Complete the code to impute missing values in X_val\n",
        "\n",
        "# Transform the test data\n",
        "X_test =  pd.DataFrame(imputer.fit_transform(X_test),columns=X_test.columns)  ## Complete the code to impute missing values in X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3jdLvwTAbp09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V1     0\n",
            "V2     0\n",
            "V3     0\n",
            "V4     0\n",
            "V5     0\n",
            "V6     0\n",
            "V7     0\n",
            "V8     0\n",
            "V9     0\n",
            "V10    0\n",
            "V11    0\n",
            "V12    0\n",
            "V13    0\n",
            "V14    0\n",
            "V15    0\n",
            "V16    0\n",
            "V17    0\n",
            "V18    0\n",
            "V19    0\n",
            "V20    0\n",
            "V21    0\n",
            "V22    0\n",
            "V23    0\n",
            "V24    0\n",
            "V25    0\n",
            "V26    0\n",
            "V27    0\n",
            "V28    0\n",
            "V29    0\n",
            "V30    0\n",
            "V31    0\n",
            "V32    0\n",
            "V33    0\n",
            "V34    0\n",
            "V35    0\n",
            "V36    0\n",
            "V37    0\n",
            "V38    0\n",
            "V39    0\n",
            "V40    0\n",
            "dtype: int64\n",
            "------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "V1     0\n",
              "V2     0\n",
              "V3     0\n",
              "V4     0\n",
              "V5     0\n",
              "V6     0\n",
              "V7     0\n",
              "V8     0\n",
              "V9     0\n",
              "V10    0\n",
              "V11    0\n",
              "V12    0\n",
              "V13    0\n",
              "V14    0\n",
              "V15    0\n",
              "V16    0\n",
              "V17    0\n",
              "V18    0\n",
              "V19    0\n",
              "V20    0\n",
              "V21    0\n",
              "V22    0\n",
              "V23    0\n",
              "V24    0\n",
              "V25    0\n",
              "V26    0\n",
              "V27    0\n",
              "V28    0\n",
              "V29    0\n",
              "V30    0\n",
              "V31    0\n",
              "V32    0\n",
              "V33    0\n",
              "V34    0\n",
              "V35    0\n",
              "V36    0\n",
              "V37    0\n",
              "V38    0\n",
              "V39    0\n",
              "V40    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 32;\n                var nbb_unformatted_code = \"# Checking that no column has missing values in train or test sets\\nprint(X_train.isna().sum())\\nprint(\\\"-\\\" * 30)\\n\\nX_val.isna().sum() ## Complete the code to check the count of missing values in validation set\\nX_test.isna().sum() ## Complete the code to check the count of missing values in test set\";\n                var nbb_formatted_code = \"# Checking that no column has missing values in train or test sets\\nprint(X_train.isna().sum())\\nprint(\\\"-\\\" * 30)\\n\\nX_val.isna().sum()  ## Complete the code to check the count of missing values in validation set\\nX_test.isna().sum()  ## Complete the code to check the count of missing values in test set\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Checking that no column has missing values in train or test sets\n",
        "print(X_train.isna().sum())\n",
        "print(\"-\" * 30)\n",
        "\n",
        "X_val.isna().sum() ## Complete the code to check the count of missing values in validation set\n",
        "X_test.isna().sum() ## Complete the code to check the count of missing values in test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzOa9FGA6WtG"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZqmoqz7bp0-"
      },
      "source": [
        "### Model evaluation criterion\n",
        "\n",
        "The nature of predictions made by the classification model will translate as follows:\n",
        "\n",
        "- True positives (TP) are failures correctly predicted by the model.\n",
        "- False negatives (FN) are real failures in a generator where there is no detection by model. \n",
        "- False positives (FP) are failure detections in a generator where there is no failure.\n",
        "\n",
        "### Which metric to optimize?\n",
        "\n",
        "* We need to choose the metric which will ensure that the maximum number of generator failures are predicted correctly by the model.\n",
        "* We would want Recall to be maximized as greater the Recall, the higher the chances of minimizing false negatives.\n",
        "* We want to minimize false negatives because if a model predicts that a machine will have no failure when there will be a failure, it will increase the maintenance cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUs837UXbp0-"
      },
      "source": [
        "**Let's define a function to output different metrics (including recall) on the train and test set and a function to show confusion matrix so that we do not have to use the same code repetitively while evaluating models.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Nt33nwx_bp0-"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 33;\n                var nbb_unformatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using sklearn\\ndef model_performance_classification_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\n            \\\"Accuracy\\\": acc,\\n            \\\"Recall\\\": recall,\\n            \\\"Precision\\\": precision,\\n            \\\"F1\\\": f1\\n        },\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n                var nbb_formatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using sklearn\\ndef model_performance_classification_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\\"Accuracy\\\": acc, \\\"Recall\\\": recall, \\\"Precision\\\": precision, \\\"F1\\\": f1},\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
        "def model_performance_classification_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check classification model performance\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred)  # to compute Recall\n",
        "    precision = precision_score(target, pred)  # to compute Precision\n",
        "    f1 = f1_score(target, pred)  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"Accuracy\": acc,\n",
        "            \"Recall\": recall,\n",
        "            \"Precision\": precision,\n",
        "            \"F1\": f1\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XGLGc5ZFbp0-"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 34;\n                var nbb_unformatted_code = \"def confusion_matrix_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors)\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n                var nbb_formatted_code = \"def confusion_matrix_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors)\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def confusion_matrix_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    To plot the confusion_matrix with percentages\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(predictors)\n",
        "    cm = confusion_matrix(target, y_pred)\n",
        "    labels = np.asarray(\n",
        "        [\n",
        "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
        "            for item in cm.flatten()\n",
        "        ]\n",
        "    ).reshape(2, 2)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.xlabel(\"Predicted label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hOzddAXbp0_"
      },
      "source": [
        "### Defining scorer to be used for cross-validation and hyperparameter tuning\n",
        "\n",
        "- We want to reduce false negatives and will try to maximize \"Recall\".\n",
        "- To maximize Recall, we can use Recall as a **scorer** in cross-validation and hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ayLcyOLsbp0_"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 35;\n                var nbb_unformatted_code = \"# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(metrics.recall_score)\";\n                var nbb_formatted_code = \"# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(metrics.recall_score)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.recall_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNwROa3X3OV7"
      },
      "source": [
        "**We are now done with pre-processing and evaluation criterion, so let's start building the model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Je_G2zN3VCF"
      },
      "source": [
        "### Model Building on original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "-OTOG3o1bp0_",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-Validation Cost:\n",
            "\n",
            "Logistic regression: 0.4916666666666667\n",
            "Bagging: 0.7071428571428571\n",
            "RandomForest: 0.7285714285714286\n",
            "AdaBoost: 0.6142857142857143\n",
            "GradientBoost: 0.7178571428571427\n",
            "XGB: 0.8047619047619048\n",
            "\n",
            "Validation Performance:\n",
            "\n",
            "Logistic regression: 0.4888888888888889\n",
            "Bagging: 0.662962962962963\n",
            "RandomForest: 0.7222222222222222\n",
            "AdaBoost: 0.6037037037037037\n",
            "GradientBoost: 0.7222222222222222\n",
            "XGB: 0.7925925925925926\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 66;\n                var nbb_unformatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\nmodels.append((\\\"Logistic regression\\\", LogisticRegression(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"RandomForest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"AdaBoost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"GradientBoost\\\", GradientBoostingClassifier(random_state=1))) \\nmodels.append((\\\"XGB\\\", XGBClassifier(random_state=1))) \\n\\n## Complete the code to append remaining 4 models in the list models\\n\\nresults1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n\\n\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Cost:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean())) \\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\nscores=[]\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    recall_scores = recall_score(y_val, model.predict(X_val))\\n    scores.append(recall_scores)\\n    print(\\\"{}: {}\\\".format(name, recall_scores))\";\n                var nbb_formatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\nmodels.append((\\\"Logistic regression\\\", LogisticRegression(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"RandomForest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"AdaBoost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"GradientBoost\\\", GradientBoostingClassifier(random_state=1)))\\nmodels.append((\\\"XGB\\\", XGBClassifier(random_state=1)))\\n\\n## Complete the code to append remaining 4 models in the list models\\n\\nresults1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n\\n\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Cost:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\nscores = []\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    recall_scores = recall_score(y_val, model.predict(X_val))\\n    scores.append(recall_scores)\\n    print(\\\"{}: {}\\\".format(name, recall_scores))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "models = []  # Empty list to store all the models\n",
        "\n",
        "# Appending models into the list\n",
        "models.append((\"Logistic regression\", LogisticRegression(random_state=1)))\n",
        "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
        "models.append((\"RandomForest\", RandomForestClassifier(random_state=1)))\n",
        "models.append((\"AdaBoost\", AdaBoostClassifier(random_state=1)))\n",
        "models.append((\"GradientBoost\", GradientBoostingClassifier(random_state=1))) \n",
        "models.append((\"XGB\", XGBClassifier(random_state=1))) \n",
        "\n",
        "## Complete the code to append remaining 4 models in the list models\n",
        "\n",
        "results1 = []  # Empty list to store all model's CV scores\n",
        "names = []  # Empty list to store name of the models\n",
        "\n",
        "\n",
        "# loop through all models to get the mean cross validated score\n",
        "print(\"\\n\" \"Cross-Validation Cost:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=5, shuffle=True, random_state=1\n",
        "    )  # Setting number of splits equal to 5\n",
        "    cv_result = cross_val_score(\n",
        "        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\n",
        "    )\n",
        "    results1.append(cv_result)\n",
        "    names.append(name)\n",
        "    print(\"{}: {}\".format(name, cv_result.mean())) \n",
        "\n",
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "scores=[]\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    recall_scores = recall_score(y_val, model.predict(X_val))\n",
        "    scores.append(recall_scores)\n",
        "    print(\"{}: {}\".format(name, recall_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic regression</th>\n",
              "      <th>Bagging</th>\n",
              "      <th>randomforest</th>\n",
              "      <th>adaboost</th>\n",
              "      <th>gradientboost</th>\n",
              "      <th>XGB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>training</th>\n",
              "      <td>0.490</td>\n",
              "      <td>0.698</td>\n",
              "      <td>0.728</td>\n",
              "      <td>0.631</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>validation</th>\n",
              "      <td>0.491</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.726</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.712</td>\n",
              "      <td>0.772</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Logistic regression  Bagging  randomforest  adaboost  \\\n",
              "training                  0.490    0.698         0.728     0.631   \n",
              "validation                0.491    0.680         0.726     0.577   \n",
              "\n",
              "            gradientboost   XGB  \n",
              "training            0.720 0.795  \n",
              "validation          0.712 0.772  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"ff=pd.DataFrame([dict(zip(names,[results1[i].mean() for i in range(6)]))],index=['training'])\\nff2=pd.DataFrame([dict(zip(names,scores))],index=['validation'])\\npd.concat([ff,ff2])\";\n                var nbb_formatted_code = \"ff = pd.DataFrame(\\n    [dict(zip(names, [results1[i].mean() for i in range(6)]))], index=[\\\"training\\\"]\\n)\\nff2 = pd.DataFrame([dict(zip(names, scores))], index=[\\\"validation\\\"])\\npd.concat([ff, ff2])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ff=pd.DataFrame([dict(zip(names,[results1[i].mean() for i in range(6)]))],index=['training'])\n",
        "ff2=pd.DataFrame([dict(zip(names,scores))],index=['validation'])\n",
        "pd.concat([ff,ff2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Cm61fR_mbp0_",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 34;\n                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results1)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C91_6Swtbp1A"
      },
      "source": [
        "### Model Building with oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "o2dEk01hbp1A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before OverSampling, counts of label '1': 833\n",
            "Before OverSampling, counts of label '0': 14167 \n",
            "\n",
            "After OverSampling, counts of label '1': 14167\n",
            "After OverSampling, counts of label '0': 14167 \n",
            "\n",
            "After OverSampling, the shape of train_X: (28334, 40)\n",
            "After OverSampling, the shape of train_y: (28334,) \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 36;\n                var nbb_unformatted_code = \"print(\\\"Before OverSampling, counts of label '1': {}\\\".format(sum(y_train == 1)))\\nprint(\\\"Before OverSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train == 0)))\\n\\n# Synthetic Minority Over Sampling Technique\\nsm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\\nX_train_over, y_train_over = sm.fit_resample(X_train, y_train)\\n\\n\\nprint(\\\"After OverSampling, counts of label '1': {}\\\".format(sum(y_train_over == 1)))\\nprint(\\\"After OverSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train_over == 0)))\\n\\n\\nprint(\\\"After OverSampling, the shape of train_X: {}\\\".format(X_train_over.shape))\\nprint(\\\"After OverSampling, the shape of train_y: {} \\\\n\\\".format(y_train_over.shape))\";\n                var nbb_formatted_code = \"print(\\\"Before OverSampling, counts of label '1': {}\\\".format(sum(y_train == 1)))\\nprint(\\\"Before OverSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train == 0)))\\n\\n# Synthetic Minority Over Sampling Technique\\nsm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\\nX_train_over, y_train_over = sm.fit_resample(X_train, y_train)\\n\\n\\nprint(\\\"After OverSampling, counts of label '1': {}\\\".format(sum(y_train_over == 1)))\\nprint(\\\"After OverSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train_over == 0)))\\n\\n\\nprint(\\\"After OverSampling, the shape of train_X: {}\\\".format(X_train_over.shape))\\nprint(\\\"After OverSampling, the shape of train_y: {} \\\\n\\\".format(y_train_over.shape))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "# Synthetic Minority Over Sampling Technique\n",
        "sm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\n",
        "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_over == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {} \\n\".format(sum(y_train_over == 0)))\n",
        "\n",
        "\n",
        "print(\"After OverSampling, the shape of train_X: {}\".format(X_train_over.shape))\n",
        "print(\"After OverSampling, the shape of train_y: {} \\n\".format(y_train_over.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZsOer36qbp1A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-Validation Cost:\n",
            "\n",
            "Logistic regression results is 0.8864848837333417\n",
            "Bagging results is 0.9745629248901775\n",
            "randomforest results is 0.9813975828966368\n",
            "adaboost results is 0.8947288857181794\n",
            "gradientboost results is 0.924675707656941\n",
            "XGB results is 0.9886555206959542\n",
            "\n",
            "Validation Performance:\n",
            "\n",
            "Logistic regression: 0.8245033112582781\n",
            "Bagging: 0.8443708609271523\n",
            "randomforest: 0.8509933774834437\n",
            "adaboost: 0.8278145695364238\n",
            "gradientboost: 0.8708609271523179\n",
            "XGB: 0.8609271523178808\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 37;\n                var nbb_unformatted_code = \"results1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Cost:\\\" \\\"\\\\n\\\")\\nfor name,model in models:## Complete the code to build models on oversampled data \\n    k_folds=StratifiedKFold(random_state=1,shuffle=True,n_splits=5)\\n    results=cross_val_score(model,X_train_over,y_train_over,cv=k_folds,scoring=scorer)    \\n## Note - Take reference from the original models built above\\n    results1.append(results)\\n    names.append(name)\\n    print('{} results is {}'.format(name,results.mean()))\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\nall_scores=[]\\nfor name, model in models:\\n    model.fit(X_train_over, y_train_over)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    all_scores.append(scores)\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n                var nbb_formatted_code = \"results1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Cost:\\\" \\\"\\\\n\\\")\\nfor name, model in models:  ## Complete the code to build models on oversampled data\\n    k_folds = StratifiedKFold(random_state=1, shuffle=True, n_splits=5)\\n    results = cross_val_score(\\n        model, X_train_over, y_train_over, cv=k_folds, scoring=scorer\\n    )\\n    ## Note - Take reference from the original models built above\\n    results1.append(results)\\n    names.append(name)\\n    print(\\\"{} results is {}\\\".format(name, results.mean()))\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\nall_scores = []\\nfor name, model in models:\\n    model.fit(X_train_over, y_train_over)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    all_scores.append(scores)\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results1 = []  # Empty list to store all model's CV scores\n",
        "names = []  # Empty list to store name of the models\n",
        "# loop through all models to get the mean cross validated score\n",
        "print(\"\\n\" \"Cross-Validation Cost:\" \"\\n\")\n",
        "for name,model in models:## Complete the code to build models on oversampled data \n",
        "    k_folds=StratifiedKFold(random_state=1,shuffle=True,n_splits=5)\n",
        "    results=cross_val_score(model,X_train_over,y_train_over,cv=k_folds,scoring=scorer)    \n",
        "## Note - Take reference from the original models built above\n",
        "    results1.append(results)\n",
        "    names.append(name)\n",
        "    print('{} results is {}'.format(name,results.mean()))\n",
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "all_scores=[]\n",
        "for name, model in models:\n",
        "    model.fit(X_train_over, y_train_over)\n",
        "    scores = recall_score(y_val, model.predict(X_val))\n",
        "    all_scores.append(scores)\n",
        "    print(\"{}: {}\".format(name, scores))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic regression</th>\n",
              "      <th>Bagging</th>\n",
              "      <th>randomforest</th>\n",
              "      <th>adaboost</th>\n",
              "      <th>gradientboost</th>\n",
              "      <th>XGB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>training</th>\n",
              "      <td>0.886</td>\n",
              "      <td>0.975</td>\n",
              "      <td>0.981</td>\n",
              "      <td>0.895</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>validation</th>\n",
              "      <td>0.825</td>\n",
              "      <td>0.844</td>\n",
              "      <td>0.851</td>\n",
              "      <td>0.828</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.861</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Logistic regression  Bagging  randomforest  adaboost  \\\n",
              "training                  0.886    0.975         0.981     0.895   \n",
              "validation                0.825    0.844         0.851     0.828   \n",
              "\n",
              "            gradientboost   XGB  \n",
              "training            0.925 0.989  \n",
              "validation          0.871 0.861  "
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 38;\n                var nbb_unformatted_code = \"ff=pd.DataFrame([dict(zip(names,[results1[i].mean() for i in range(6)]))],index=['training'])\\nff2=pd.DataFrame([dict(zip(names,all_scores))],index=['validation'])\\npd.concat([ff,ff2])\";\n                var nbb_formatted_code = \"ff = pd.DataFrame(\\n    [dict(zip(names, [results1[i].mean() for i in range(6)]))], index=[\\\"training\\\"]\\n)\\nff2 = pd.DataFrame([dict(zip(names, all_scores))], index=[\\\"validation\\\"])\\npd.concat([ff, ff2])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ff=pd.DataFrame([dict(zip(names,[results1[i].mean() for i in range(6)]))],index=['training'])\n",
        "ff2=pd.DataFrame([dict(zip(names,all_scores))],index=['validation'])\n",
        "pd.concat([ff,ff2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kwUcBORjbp1A",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(1, 0, 'Logistic regression'),\n",
              " Text(2, 0, 'Bagging'),\n",
              " Text(3, 0, 'randomforest'),\n",
              " Text(4, 0, 'adaboost'),\n",
              " Text(5, 0, 'gradientboost'),\n",
              " Text(6, 0, 'XGB')]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAHNCAYAAADc7DUCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAn+0lEQVR4nO3de5hdVX3/8fdJiCIx4ASpF4qFavt1dAL6E+U2IEFAQG3RqiV4KTTKRcULlsLT0UKxYxXFS0HwloqXOqg/xUfURmkJwnATbzUJw1fS4qVSL5iR+EMDuczvj7VHDnFiJmFNzpnJ+/U888ycs8/e+3vW2bPns9da50xrbGwMSZIkPXizOl2AJEnSTGGwkiRJqsRgJUmSVInBSpIkqRKDlSRJUiUGK0mSpEp26nQBkqZORMwBfgB8NzOPae47HLg4M/sq7ePPgCMz87UR8RzggMz8+4g4CXhhZj63xn6afe0MDADPBVrAbOATwAWZ2TWfHRMRXwb+JjNv7XQtkrYvg5U0sz0f+C7wtIjozcyR2jvIzC8AX2huPh2YX3sfABHRAj4PfA84KDPXRsTuwJeAhwNvnor9bovMPK7TNUjqDIOVNLO9CrgcWAW8Hji1fWFE7AF8BHg88AvgJ8CKzDwvIg4F3gHsAtwHvCkzlzY9UYuBucDdwEeBFwJvAU4DZkfE3cDtwGMi4kvA44D1wImZORIR1wDfBI4A/gB4L/Ao4JnNdl+cmcs3eS6HAb3AczJzA0Bm/iIiXgbs3TyfPwQubW63gI9m5jsiYm/g6ubrIGAO8DdNezwR+AawqKnza8A1wH7NNl6TmddFxKOADzR1PprSE/jizPxZRHwfuBnYF/g74N1Nm9zWtO+fABub53xqZm6MiFOA1wIbgJ82+/leRFwGrAEWAHs12zghM/8fkrqec6ykGSoingQcCHyaEn5e1vTwtPtnYGVm9gIvAg5u1t0d+L/A6zJzX+CvgE9ExD7Nek8GDs/MheMbysybgfcDn8rMgebuP262sQC4lhJmxu2dmU8FXgC8HbgmM/cHlgJnTPCU9gduHg9Vbfu9PTOvam7+K7Cs2d8hwEsj4oRm2T7AFzLzycB/UMLcoua5HNq0FZRw9ZXMfApwDvCpZkj1BODGzDyoeV6/Bl7WVsqKzOzNzCva7ns+MK/Z1tPH2yQijgD+FliYmfsBnwQ+3/TKATwNOIYSJB9LeW0kTQMGK2nmOh34UmauzsxbgDvYpMcKOA74IEBm/i8lTAEcAKxqwhKZuRK4Hji8Wf7dzFwziRq+npmrmp+/Q+mdGve55vt/Nd+Xtt2eaDhxI7/nnBURcylh6n1NzXcDlwHHNg9ZB1zZto8bMnNNZq4F7mzb52hmfrLZxr9RepT2zcz3AjdExJnAJUAfZQhy3HUTlDUMPLnpoTsHeE/THsdQAujPm/1cBuxJ0/MGLM3MezNzHbB8M+0hqQsZrKQZqAkZLwf6I+L7zVDVY4BXU4bBxq2nDHeNG+8NmujcMKtt3ckOS61r+3lsk33d2/7AJkT8PjcBT4+I2e13RsTTI+LjTX2tTdZpr/m+TSa4b25/6yfYxoaIeDtwPvBzShj96ib7+502ycw7gCcA/wTsCvx7RLyQidu31Vbrb9ru37TdJHUxg5U0M70EuAt4bGbunZl7U4avHs4De42+RJkvNT7893zKH/Kbyl3xjGbZkylznK7Zwn7X88DgVk1m3kiZb/Su5t2BNPOeLgLuyMxfNXW/ulm2GyVcXjXxFjdrj4gYfwfl8ygBbDnwbEqP08eBnwFHUd6VuFkRcTpljtVXM/Ns4CuUnq6vAH/ZzHEjIk6mzHFbtbltSZoeDFbSzHQ68K72+UiZ+UvKnKrXtz3uDcATI2I58FnKhOxfZ+ZdlHk9FzXLPgmcnJnf28J+/wP4s4i4qNYT2cRfUHpvvhkR/9ns77PAuc3ylwDPamr+erPssq3cx1rKfLT/pHy0w/FNO54PvDMivkkZxhym9Eb9Ph+jhK9bI+IblF6r9zZzwt4NXB0RKylz2J6bmRu3slZJXaY1NtY1H/0iaTuLiFcB387MGyPioZR5Quc2c4t2OM27B1dk5sO39FhJmogftyDt2G6l9ErNBh4CfGZHDVWSVIM9VpIkSZU4x0qSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUmSVInBSpIkqRKDlSRJUiUGK0mSpEoMVpIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqmSnThcw7oADDhjbc889O12GJEnSFq1cufKuzNxj0/u7JljtueeefO5zn+t0GZIkSVsUET+Y6H6HAiVJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJElSNX19fbRarSn56uvr6/TT26KdOl2AJEnqXvPnz2d0dLTTZQCwcuVKWq3WpB7b09PD6tWrp7ii32WwkiRJmzU6OsrY2Finy9hqkw1gtTkUKEmSVInBSpIkqRKDlSRJUiXOsZIkSZu1/PS5cN5unS5jqy0/fW5H9muwkiRJm7Xg0num5eT1Ba0WY5ds//06FChJklSJPVaSJOn36tRHFzwYPT09HdmvwUqSJG3WVA4DtlqtaTnM+Ps4FChJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKykHVRfXx+tVmtKvvr6+jr99CR1yNacW4AZd27x4xakHdSKFSsm/diZ+JZoSVNja84tM5E9VpIkSZUYrCRJkioxWEmSJFVisJIkSarEyevSDDF//nxGR0enbPtT9U9Ye3p6WL169ZRsW5K2N4OVNEOMjo5Oy3fuTVVgk6ROcChQkiSpEnuspBli+elz4bzdOl3GVlt++txOlyBJ1RispBliwaX3TMuhwAWtFmOXdLoKSarDoUBJkqRKDFaSJEmVGKwkSZIq2eIcq4iYBVwC7AfcC7wiM1e1LT8bWASsAS7IzC9GxOOAjwMtYDVwYmb+egrqlyRJ6hqT6bE6Htg5Mw8CzgEuHF8QEQuAE4EDgaOB8yNiF+ANwKcy8zBgJbC4ct2SJEldZzLBqh9YCpCZNwH7ty3rBa7JzLWZuRa4HdgX+A7Q0zxmV2BdrYIlSZK61WSC1a7A3W23N0TE+BDicuCwiJgXEbsDBwNzgf8BXhMRK4Fjgc9UrFmSJKkrTSZYrQHmta+TmesBMnMEuJjSo3UxcDNwF/AO4KTMfDLwOuBjNYuWJEnqRpMJVtcDxwFExIGUXiqa23sA8zLzEOA0YC9gBTDK/b1cd3L/sKAkSdKMNZlPXr8COCoibqC8y+/kiDgTWAVcCfRGxC3AfcBZmbkhIs4ALo6I2c06r56a8iVJkrrHFoNVZm6k9Ea1u63t51MnWOdW4IgHV5okSdL04geESpIkVeI/YZZmkFar1ekStlpPj1MwJc0cBitphhgbG5uybbdarSndviTNFA4FSpIkVWKwUlfo6+uj1WpNyVdfX1+nn15X2po2B2xzSZoEhwLVFVasWDHpxzosVcfWtLkkaXLssZIkSarEYCVJklSJwUqSJKkS51hpSsyfP5/R0dEp2/5UfV5TT08Pq1evnpJtS5JmPoOVpsTo6Oi0nGA+HT9gU5LUPQxWmhLLT58L5+3W6TK22vLT53a6BEnSNGaw0pRYcOk907LHakGrxdglna5CkjRdOXldkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKvFdgZoy0/EzoXp6ejpdgiRpGjNYaUpMx49akCTpwXIoUJIkqRKDlSRJUiUGK0mSpEoMVpIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUmSVInBSpIkqRKDlSRJUiUGK0mSpEoMVpIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlO23pARExC7gE2A+4F3hFZq5qW342sAhYA1yQmV+MiLnApcA+wEOAMzLz61NQvyRJUteYTI/V8cDOmXkQcA5w4fiCiFgAnAgcCBwNnB8RuwBnASsy81DglUBUrluSJKnrTCZY9QNLATLzJmD/tmW9wDWZuTYz1wK3A/sCzwbui4ivAG8GvlK1akmSpC40mWC1K3B32+0NETE+hLgcOCwi5kXE7sDBwFzgkUBPZj4buBJ4Z8WaJUmSutJkgtUaYF77Opm5HiAzR4CLKT1aFwM3A3cBvwC+0Dz+Sh7YyyVJkjQjTSZYXQ8cBxARB1J6qWhu7wHMy8xDgNOAvYAVwPD4OsBhwMqKNUuSJHWlLb4rELgCOCoibgBawMkRcSawitIb1RsRtwD3AWdl5oaIeCvw4Yi4EVgHvHxqypckSeoeWwxWmbmR0hvV7ra2n0+dYJ3VwAseXGmSJEnTix8QKkmSVInBSpIkqRKDlSRJUiUGK0mSpEoMVpIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUmSVInBSpIkqRKDlSRJUiUGK0mSpEoMVpIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUmSVInBSpIkqRKDlSRJUiUGK0mSpEoMVpIkSZUYrCRJkirZaUsPiIhZwCXAfsC9wCsyc1Xb8rOBRcAa4ILM/GLbsmcCn8jMvWoXLkmS1G0m02N1PLBzZh4EnANcOL4gIhYAJwIHAkcD50fELs2yvYAzgTmVa5YkSepKkwlW/cBSgMy8Cdi/bVkvcE1mrs3MtcDtwL4RsTPwfuBVleuVJEnqWpMJVrsCd7fd3hAR40OIy4HDImJeROwOHAzMBS4G3pmZP65arSRJUhebTLBaA8xrXycz1wNk5gglRC1tvt8MrAcOBc6NiGuA+RFxec2iJUmSutEWJ68D1wPPAz4dEQdSeqkAiIg9gHmZeUhE7AZ8FRjOzGh7zE8y84TKdUuSJHWdyQSrK4CjIuIGoAWcHBFnAquAK4HeiLgFuA84KzM3TFm1kiRJXWyLwSozNwKnbXL3bW0/n7qF9R+9DXVJkiRNO35AqCRJUiUGK0mSpEoMVpIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUmSVInBSpI0Y/X19dFqtabkq6+vr9NPT11op04XIEnSVFmxYsWkH9tqtRgbG5vCarQjsMdKkiSpEoOVJElSJQYrSZKkSgxWkiRJlTh5XZI0bcyfP5/R0dEp236r1ZqS7fb09LB69eop2ba6i8FKkjRtjI6OTst37k1VYFP3cShQkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUmSVInBSpIkqRKDlSRJUiUGK0mSpEoMVpIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlO3W6AEmSJmv56XPhvN06XcZWW3763E6XoO3EYCVJmjYWXHoPY2NjnS5jqy1otRi7pNNVaHtwKFCSJKkSg5UkSVIlBitJkqRKtjjHKiJmAZcA+wH3Aq/IzFVty88GFgFrgAsy84sR8TjgX5rtt4BTMjOnoH5JkqSuMZkeq+OBnTPzIOAc4MLxBRGxADgROBA4Gjg/InYB3gJcnJmHA28F/qlu2ZKkHVWr1Zp2Xz09PZ1uNm0nk3lXYD+wFCAzb4qI/duW9QLXZOZagIi4HdgXeCNwd9s+1larWJK0w5rKdwS2Wq1p+Y5DdZfJ9Fjtyv0hCWBDRIwHsuXAYRExLyJ2Bw4G5mbmXZm5LiICeCfwD1WrliRpEvr6+ibdqwRb1xvW19fX4WenbjSZHqs1wLy227Mycz1AZo5ExMWUHq0fAjcDdwFExELK3KyXOb9KktQJK1as6HQJ2sFMpsfqeuA4gIg4kNJLRXN7D2BeZh4CnAbsBaxoQtV7gWMy8xvVq5YkSepCk+mxugI4KiJuoLzD7+SIOBNYBVwJ9EbELcB9wFmZuSEi3gM8BPhoGQ0kM/PUqXgCkiRJ3WKLwSozN1J6o9rd1vbz7wSmzNzvQdYlSZI07fgBoZIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUmSVInBSpIkqRKDlSRJUiUGK0mSpEoMVpIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUldZGhoiL6+PmbPnk1fXx9DQ0OdLknSVtip0wVIkoqhoSEGBgZYsmQJ/f39DA8Ps3jxYgAWLVrU4eokTYY9VpLUJQYHB1myZAkLFy5kzpw5LFy4kCVLljA4ONjp0iRNksFKkrrEyMgI/f39D7ivv7+fkZGRDlUkaWsZrCSpS/T29jI8PPyA+4aHh+nt7e1QRZK2lsFKkrrEwMAAixcvZtmyZaxbt45ly5axePFiBgYGOl2apEly8rokdYnxCepnnHEGIyMj9Pb2Mjg46MR1aRoxWElSF1m0aJFBSprGHAqUJEmqxGAlSZJUyRaHAiNiFnAJsB9wL/CKzFzVtvxsYBGwBrggM78YEY8EPgk8DLgTODkzfz0F9UuSJHWNyfRYHQ/snJkHAecAF44viIgFwInAgcDRwPkRsQvw98AnM/NQ4NvAqZXrliRJ6jqTCVb9wFKAzLwJ2L9tWS9wTWauzcy1wO3Avu3rAP8GHFmtYkmSpC41mWC1K3B32+0NETE+hLgcOCwi5kXE7sDBwNxN1vkVsFuleiVJkrrWZILVGmBe+zqZuR4gM0eAiym9UxcDNwN3bbLOPOCXleqVJEnqWpMJVtcDxwFExIGUXiqa23sA8zLzEOA0YC9gRfs6wLHAdRVrliRJ6kqT+YDQK4CjIuIGoAWcHBFnAquAK4HeiLgFuA84KzM3RMQ/Ah+NiFdSerBOnJryJUmSuscWg1VmbqT0RrW7re3n33nHX2b+FDjmwZUmSZI0vfgBoZIkSZUYrCRJkioxWEmSJFVisJIkSarEYCVJklSJwUqSJKkSg5UkSVIlBitJkqRKDFaSJEmVGKwkSZIqMVhJkiRVMpl/wixJmsD8+fMZHR3tdBlbraenh9WrV3e6DGlGMlhJ0jYaHR1lbGys02VstVar1ekSpBnLoUBJkqRK7LHaRkNDQwwODjIyMkJvby8DAwMsWrSo02VJ2o6Wnz4Xztut02VsteWnz+10CdKMZbDaBkNDQwwMDLBkyRL6+/sZHh5m8eLFAIYraQey4NJ7puVQ4IJWi7FLOl2FNDM5FLgNBgcHWbJkCQsXLmTOnDksXLiQJUuWMDg42OnSJG1nrVZr2n319PR0utmkGcseq20wMjJCf3//A+7r7+9nZGSkQxVJ6oTp2FslaWrZY7UNent7GR4efsB9w8PD9Pb2dqgiSZLUDQxW22BgYIDFixezbNky1q1bx7Jly1i8eDEDAwOdLk2SJHWQQ4HbYHyC+hlnnPHbdwUODg46cV2SpB2cwWobLVq0yCAlSZIewKFASZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUldZGhoiL6+PmbPnk1fXx9DQ0OdLknSVvDjFiSpS/gP3qXpzx4rSeoS/oN3afozWElSl/AfvEvT3w4RrObPn0+r1Zp2X/Pnz+9000najvwH79L0t0MEq9HRUcbGxqbd1+joaKebTtJ25D94l6Y/J69LUpfwH7xL05/BSpK6iP/gXZredoihQEmSpO1hh+ixWn76XDhvt06XsdWWnz630yVIkqStsEMEqwWX3sPY2Finy9hqC1otxi7pdBWSJGmyHAqUJEmqxGAlSZJUyQ4xFAjQarU6XcJW6+np6XQJkiRpK+wQwWo6zq+SJEnTj0OBkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUmSVInBSpIkqRKDlSRJUiUGK0mSpEoMVpIkSZUYrCRJkioxWEmSJFVisJIkSapki/+EOSJmAZcA+wH3Aq/IzFVty98InAhsBN6amVdExG7A5cDDm3Vempk/mYL6JUmSusZkeqyOB3bOzIOAc4ALxxdExCOA1wEHAUcD72kWnQQsz8xDgU8BZ9UqWJIkqVtNJlj1A0sBMvMmYP+2ZfcAPwDmNl8bm/uXA/Oan3cF1tUoVpIkqZtNJljtCtzddntDRLQPIf4IuBX4FvDPzX2/AI6OiFspvVVLKtTaVYaGhujr62P27Nn09fUxNDTU6ZIkSVKHTSZYreH+3ieAWZm5vvn5WOAxwD7A44DjI+IZwLnABZn5JMoQ4Wfrldx5Q0NDDAwMcNFFF7F27VouuugiBgYGDFeSJO3gJhOsrgeOA4iIAynDfONGgd8A92bmWuCXwCOa+8d7uX5G6fWaMQYHB1myZAkLFy5kzpw5LFy4kCVLljA4ONjp0iRJUgdt8V2BwBXAURFxA9ACTo6IM4FVmfmFiDgSuCkiNgLDwFXACuDDEfEqYA7wyqkpvzNGRkbo7+9/wH39/f2MjIx0qCJJktQNthisMnMjcNomd9/WtvxcytBfuztperlmot7eXoaHh1m4cOFv7xseHqa3t7eDVUmSpE7zA0K3wcDAAIsXL2bZsmWsW7eOZcuWsXjxYgYGBjpdmiRJ6qDJDAVqE4sWLQLgjDPOYGRkhN7eXgYHB397vyRJ2jEZrLbRokWLDFKSJOkBHAqUJEmqxGAlSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlRisJEmSKjFYSZIkVWKwkiRJqsRgJUmSVInBSpIkqRKDlSRJUiVd80+YV65ceVdE/KDTdUiSJE3CH010Z2tsbGx7FyJJkjQjORQoSZJUicFKkiSpEoOVJElSJQYrSZKkSgxWkiRJlXTNxy1sKiIOB07LzBMexDbOAa7OzK9vZvlrMvPiiDgGeFxmfnBb97U9RcR7gHdl5g87XcvWaF7TTwO3Ai3gocDpmfntCtu+HHh5Zt73YLe1I4iI04BHZ+Z5D2IbbweOBV6bmddUKo2IeBywX2ZeWWub3WBLbR4R5wE/ycz3V97vjGzPLRlvb+D9wN9n5qu2cv0FQE9mXhsR3weemJlrK9f4fODmzLyz5na7QUQcBVwIPCMz10bEnsBS4BjgUODVzUM3AN8B/jYz72va+ofAGDAX+HRmXrCdy39QZnSPVWa+bXOhqvGm5nFLp0uoAsjM10+3UNXm6sw8PDOfCfw98JYaG83MEwxV292LgENqhqrGEcAhlbe5I9uh2zMzf7K1oarxF8CTatezidcBu07xPjoiM6+iBKl3R8Qc4HLgTGA/4JXA8zLzUGAhJUT9VdvqRzd/Iw4GTo2IP9iuxT9IXdtjtTlNCv5HYC3wC+CvgbuB9wH7Az8B9gGeB5xHeTH/G/gIsJ4SJk8EXg7Mj4hLgK9TrkbOiYg3AcdT2ubSzPxA275PavY3CzgXmE85UDYAw836jwQ+SemNSeCIzHxCRKwAvgfcB5wKLAF2bzb92sxcHhEfAZ4APAx4b2Z+PCIGKQfeTsBnM/PtEXENcFrzXD9B+cXcCXhTZl4dEd8FvgbsSzlg/zwz734QzT5VeoCfRcQzKe05C3g4cGJmfi8i3gw8H/g5sAvwZmAFE7fv94EnUq5O7wX2Bh4DnJSZ34qIxcBrgNWU1+BTmXnZdnqeVW1yHH4G+HPKld1dlPY6ETiO0maPB96emZdFRD/wXmCU8rtwU7O9NwInNPddm5lnN70nTwAeSTlO30f5Q/OnlBPg0cBjgS9FxLMpv5P9TYmfzMz3RsRlzbq7A88B/pZypTqb0uP6mYh4VbO9jcAtwBuAc4BdIuKGzPxCzbabShGxK/Bh4BGUtnkfsJyJ2/yfKOer3YH/zMyTm808PyJeTHntXpuZX4+IlwCvpxzXtwOnNI/9CPDH3N+en5op7RkRDwM+RmnHHwGHUc6fP6Ocd/8C+BBtbZ2Zl050jEfE3sDlmXlgc64ZpJyz/4tyLn4Jm/y+AFcBJwH3RcS3mrI+0Gzrp5Q2Xs/Er8FTgYuafaylhIifUXrrd2v2MwDMAZ4CfCwi+mfoheEAcD3wBeDfM/OqiPg34KzM/CVAZo5FxJmZOdGHau4CrAN+vb0KrmFa9VhFRAv4IPCCJs1+jdLr9GfA7pn5DGAxsNcmqx5FCU9HUv6A75aZg8Dq9iuZ5hfiWOAA4BnAnzb7bDeamf3At4F/AJ7V3N6zCX0DwOeb+j7D/eH14cBbmqHNvwP+IzMXUk6Sl0bEPMrJ4wWUrtINzXovofyhPBT45Sa1vAm4KjMPo/QeLGnq3RUYamr4cfOcusUREXFNRNxIOSldDjwZeGlmHg58DnhRROxHqfvplKD7mGb9zbVvux9k5rMpJ7dTmrB7NuWq/WhKCJnuRinHyyOAIzPzAEpbPL1ZvltmPpfyu3FOc9+lwKLMPBK4A3473PFiypXhwcCfRMRzm8f/JjOPAT4LHJeZzwPeBpyQmedTgv3RwLMoFzMHUsLVic12ofRQHtws26f5XVkIDETEI4CTgddk5kHACGWI+G2UcDYtQkCbJ1D+gB9NaZczmbjNd6WcR46ihKsDm2ESgDsy8wjKeez9EbE75TxzRNN2v6SEgVOBnzdteyTwj81xPlPa8xRKWxxCuUB+VHP/UNOWj+d32xomaO9xzbnxQ9z/9+PHlPAEm/y+ZOaPgcsoYWl81OPSZr3vU8LS5l6DD1Feg2cClwDvaup9JOWCfxGwU2Z+iTIENmOnMGTmOsrf7CMp53so54pVABFxUNNRMNxM5xj31Yj4GuXi+Ubgnu1WdAXTKlhRDsw1zUEPcC3lj3IvpfHJzJ8Dt22y3hLKCWkppddi/Wa2H8DXM3NDZt6XmW+cIEVn8/0JwB7Al5sD40mUX55e4IbmMddtZt0FwF83630ImJ+Zv6JclX4Q+BSlRwZKsHob8BXKH9F2vU0b0LTJGmC8y3R83tKPgJ0383w7YXwo8CDgqZRg9WPgn5sejoWUK7le7n8tfgN8o1n/97XvuE2f+xOAWzPz15m5oW396SwzcyOl920oIpYAf0hpOygnbHjg6/+ozPxe8/P1zfcnAjdl5rrmWL+O8jsFMH6l/kvKvDgogW7T46kXuC4zx5oT6U3cP4TSfsw/rTnmlzZ17k0JAq9uTqJ/RAkC09VPgeMj4hOUi545TNzmvwH+ICKGgA9QLrrGX7fx3+eVlPlBfwysbM4P48vHz3njj/0V5fV5PDOnPX/7e56Zt1F6reH+42mitoaJ23vcHpQLtE83x+HR3P8vSb7TfN/c+fK+zLyp+fkGyt+Kzb0Gj83M8e1dCzy5eT0/AAxRwtZ0+9u7TZoevrMovdWfiIjZlDbeByAzb2wuqBdTjvdx40OBezVfL9mOZT9o0+3FvQvYNSLGey+eSekeXgEcBBARPZThinZ/TjnxP4vSy3F2c/+mJ53bgP8TEbMiYk5EXBURD93kMRub73dQDpCjmgPjIsoflN/WQrlKn2jd24B3N+u9mHLAPQZ4WmY+nzJsckGz7xdRrnAWAidFRPv/Jhqh9GTRXPH2UIZHoQwBdrufNt8/DJycmScBd1Jel5XA05vX4qGUEAa/v33HbfrcVwFPjIiHRcQsSm/kdLcxIvYFjs/MvwTOoPw+jx/TE73+P46I3ubn8Z6t24ADImKn5op+fMhlc9uYyAjNMGAzl+JgypAVPPCYX9Yc80dQhkX+i3Llf1pzEn1qs+5Gpt+5CeCNwI2Z+VLKeabFxG1+LLBXZi6i9F4/jPtft2fAb3sSf0g5zzwpIsZ7WcfPee2/+/MowfUOZk57tp/Tx3t74P7jaaK2honbe9xdwP9QpkYcThkSvLpZNtGx3t5uD4mIpzQ/H9rUt7nX4M7mdxOa16t5Pedl5nMow4gXTbCPGSUiHkLpJHhDZr6bcjyfS3nu74iI3doefjgTvAZNT95PgYdMecEVdfscq6Mj4httt0+knDg+FxEbKVfPJ1HCxLERcQNleOLXlHHZcd8APtrMn5pNmXcAcGtzxfPvAJn5nYhYSrnSmUXp+r13osIy8+cR8S7ga00K/z7lj8XbgI838yTu3KSOcYOUYbtTKMN25zV1P7p5DhuAd2bmvRGxmhLYfgN8lXJwjnsr8C8R8ULKyfmUzFwfERM2Zpc4orla3ADMo3Th7wtcFxH3UH6JHptlztmXKc/9Lko7rmNy7fsAmXlXlHewXUeZY/Wwyaw3DawC7omI8Svz/6XMN9mcUynzOdYAv6IMRy2PiE9z/zE/DHyeMsF0UjLzixFxeDO8+xDKu3i+tclxeCVweERcR+mhuSIzfxURyymv/a8oPZc3U3peByLiW5l5OdPHlcBFEXECpZdvPWUu5APanDIt4c0RcS3lj8l/c//rtk9EXE3psT61OXbPBZY157xVlKHdjcCHImKYcjz/Q2b+bAa15xLgsqaNfkCZq9Tud9q6uQD7nWN8fIXM3BgRr6PMC5xFaZeXA4/bTA3fpASAEcr8tjMi4k+aes6hhLmJXoNXAhc3FyrrKb0xdwLnNuetWZQ37kDp/fpYRBydmau3qaW614WUucdfbm6/itKmV1N67z7fnCN2pVxIn9K27lcjYgMlo/wI+NftVXQNM+KfMEfEE4GnZOblzZyElcAfbS4UTXEtx1HG3W+JiCOBv2vmTGgrRHkXyAsz85LmhLmS0tPRx1a2b0TsBJydmYPNye5aYCAzr53ipyFpG0TEwcDDM/OrTZhZmpmP73Rd0mR0e4/VZP0IeHtEvJ7SI3V2J0JV4w5KL9L6ppbXdqiO6e4uylDgLZSr+g9n5g+bIZGtat+mF29ulHf33Ee5it/c/CxJnffflLmD51LmT716C4+XusaM6LGSJEnqBjNy0pwkSVInGKwkSZIqMVhJkiRVYrCSJEmqxGAlSZJUicFKkiSpkv8P6ZSSOnvJs9kAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 39;\n                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names) ## Write the code to create boxplot to check model performance on oversampled data\";\n                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(\\n    names\\n)  ## Write the code to create boxplot to check model performance on oversampled data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results1)\n",
        "ax.set_xticklabels(names) ## Write the code to create boxplot to check model performance on oversampled data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYLfDmHvbp1B"
      },
      "source": [
        "### Model Building with undersampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "PHM-5g8Qbp1B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before UnderSampling, counts of label '1': 833\n",
            "Before UnderSampling, counts of label '0': 14167 \n",
            "\n",
            "After UnderSampling, counts of label '1': 833\n",
            "After UnderSampling, counts of label '0': 833 \n",
            "\n",
            "After UnderSampling, the shape of train_X: (1666, 40)\n",
            "After UnderSampling, the shape of train_y: (1666,) \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 37;\n                var nbb_unformatted_code = \"rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_train_un, y_train_un = rus.fit_resample(X_train, y_train)\\n\\n\\nprint(\\\"Before UnderSampling, counts of label '1': {}\\\".format(sum(y_train == 1)))\\nprint(\\\"Before UnderSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train == 0)))\\n\\n\\nprint(\\\"After UnderSampling, counts of label '1': {}\\\".format(sum(y_train_un == 1)))\\nprint(\\\"After UnderSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train_un == 0)))\\n\\n\\nprint(\\\"After UnderSampling, the shape of train_X: {}\\\".format(X_train_un.shape))\\nprint(\\\"After UnderSampling, the shape of train_y: {} \\\\n\\\".format(y_train_un.shape))\";\n                var nbb_formatted_code = \"rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_train_un, y_train_un = rus.fit_resample(X_train, y_train)\\n\\n\\nprint(\\\"Before UnderSampling, counts of label '1': {}\\\".format(sum(y_train == 1)))\\nprint(\\\"Before UnderSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train == 0)))\\n\\n\\nprint(\\\"After UnderSampling, counts of label '1': {}\\\".format(sum(y_train_un == 1)))\\nprint(\\\"After UnderSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train_un == 0)))\\n\\n\\nprint(\\\"After UnderSampling, the shape of train_X: {}\\\".format(X_train_un.shape))\\nprint(\\\"After UnderSampling, the shape of train_y: {} \\\\n\\\".format(y_train_un.shape))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\n",
        "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "\n",
        "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_un == 1)))\n",
        "print(\"After UnderSampling, counts of label '0': {} \\n\".format(sum(y_train_un == 0)))\n",
        "\n",
        "\n",
        "print(\"After UnderSampling, the shape of train_X: {}\".format(X_train_un.shape))\n",
        "print(\"After UnderSampling, the shape of train_y: {} \\n\".format(y_train_un.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Rc5ndPMubp1B",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-Validation Cost:\n",
            "\n",
            "Logistic regression: 0.8576719576719578\n",
            "Bagging: 0.841515221225366\n",
            "randomforest: 0.8786826163637759\n",
            "adaboost: 0.8601564297216472\n",
            "gradientboost: 0.8712752089563682\n",
            "XGB: 0.8886128364389234\n",
            "\n",
            "Validation Performance:\n",
            "\n",
            "Logistic regression: 0.8443708609271523\n",
            "Bagging: 0.8774834437086093\n",
            "randomforest: 0.9006622516556292\n",
            "adaboost: 0.8708609271523179\n",
            "gradientboost: 0.890728476821192\n",
            "XGB: 0.9072847682119205\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 41;\n                var nbb_unformatted_code = \"results1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Cost:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_un, y=y_train_un, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\nall_scores=[]\\nfor name, model in models:\\n    model.fit(X_train_un, y_train_un)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    all_scores.append(scores)\\n    print(\\\"{}: {}\\\".format(name, scores)) ## Complete the code to build models on undersampled data \\n## Note - Take reference from the original models built above\";\n                var nbb_formatted_code = \"results1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Cost:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_un, y=y_train_un, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\nall_scores = []\\nfor name, model in models:\\n    model.fit(X_train_un, y_train_un)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    all_scores.append(scores)\\n    print(\\n        \\\"{}: {}\\\".format(name, scores)\\n    )  ## Complete the code to build models on undersampled data\\n## Note - Take reference from the original models built above\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results1 = []  # Empty list to store all model's CV scores\n",
        "names = []  # Empty list to store name of the models\n",
        "# loop through all models to get the mean cross validated score\n",
        "print(\"\\n\" \"Cross-Validation Cost:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=5, shuffle=True, random_state=1\n",
        "    )  # Setting number of splits equal to 5\n",
        "    cv_result = cross_val_score(\n",
        "        estimator=model, X=X_train_un, y=y_train_un, scoring=scorer, cv=kfold\n",
        "    )\n",
        "    results1.append(cv_result)\n",
        "    names.append(name)\n",
        "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
        "\n",
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "all_scores=[]\n",
        "for name, model in models:\n",
        "    model.fit(X_train_un, y_train_un)\n",
        "    scores = recall_score(y_val, model.predict(X_val))\n",
        "    all_scores.append(scores)\n",
        "    print(\"{}: {}\".format(name, scores)) ## Complete the code to build models on undersampled data \n",
        "## Note - Take reference from the original models built above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic regression</th>\n",
              "      <th>Bagging</th>\n",
              "      <th>randomforest</th>\n",
              "      <th>adaboost</th>\n",
              "      <th>gradientboost</th>\n",
              "      <th>XGB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>training</th>\n",
              "      <td>0.858</td>\n",
              "      <td>0.842</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.860</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>validation</th>\n",
              "      <td>0.844</td>\n",
              "      <td>0.877</td>\n",
              "      <td>0.901</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.891</td>\n",
              "      <td>0.907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Logistic regression  Bagging  randomforest  adaboost  \\\n",
              "training                  0.858    0.842         0.879     0.860   \n",
              "validation                0.844    0.877         0.901     0.871   \n",
              "\n",
              "            gradientboost   XGB  \n",
              "training            0.871 0.889  \n",
              "validation          0.891 0.907  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 42;\n                var nbb_unformatted_code = \"ff=pd.DataFrame([dict(zip(names,[results1[i].mean() for i in range(6)]))],index=['training'])\\nff2=pd.DataFrame([dict(zip(names,all_scores))],index=['validation'])\\npd.concat([ff,ff2])\";\n                var nbb_formatted_code = \"ff = pd.DataFrame(\\n    [dict(zip(names, [results1[i].mean() for i in range(6)]))], index=[\\\"training\\\"]\\n)\\nff2 = pd.DataFrame([dict(zip(names, all_scores))], index=[\\\"validation\\\"])\\npd.concat([ff, ff2])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ff=pd.DataFrame([dict(zip(names,[results1[i].mean() for i in range(6)]))],index=['training'])\n",
        "ff2=pd.DataFrame([dict(zip(names,all_scores))],index=['validation'])\n",
        "pd.concat([ff,ff2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8HcDqaD2bp1B",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(1, 0, 'Logistic regression'),\n",
              " Text(2, 0, 'Bagging'),\n",
              " Text(3, 0, 'randomforest'),\n",
              " Text(4, 0, 'adaboost'),\n",
              " Text(5, 0, 'gradientboost'),\n",
              " Text(6, 0, 'XGB')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 43;\n                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\n# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names) ## Write the code to create boxplot to check model performance on undersampled data\";\n                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\n# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(\\n    names\\n)  ## Write the code to create boxplot to check model performance on undersampled data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "# Plotting boxplots for CV scores of all models defined above\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results1)\n",
        "ax.set_xticklabels(names) ## Write the code to create boxplot to check model performance on undersampled data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERm8IqLo34q8"
      },
      "source": [
        "**After looking at performance of all the models, let's decide which models can further improve with hyperparameter tuning.**\n",
        "\n",
        "**Note**: You can choose to tune some other model if XGBoost gives error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLZlKa99bp1C"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FtmPS7Ubp1D"
      },
      "source": [
        "### Tuning AdaBoost using oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "IPSlOlvkbp1D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters are {'n_estimators': 200, 'learning_rate': 0.2, 'base_estimator': DecisionTreeClassifier(max_depth=3, random_state=1)} with CV score=0.9631071424556618:\n",
            "CPU times: total: 1min 29s\n",
            "Wall time: 26min 12s\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 124;\n                var nbb_unformatted_code = \"%%time \\n\\n# defining model\\nModel = AdaBoostClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [100, 150, 200],\\n    \\\"learning_rate\\\": [0.2, 0.05],\\n    \\\"base_estimator\\\": [DecisionTreeClassifier(max_depth=1, random_state=1), DecisionTreeClassifier(max_depth=2, random_state=1), DecisionTreeClassifier(max_depth=3, random_state=1),\\n    ]\\n}\\n\\n\\n#Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\\n\\n#Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over,y_train_over) ## Complete the code to fit the model on over sampled data\\n\\nprint(\\\"Best parameters are {} with CV score={}:\\\" .format(randomized_cv.best_params_,randomized_cv.best_score_))\";\n                var nbb_formatted_code = \"%%time \\n\\n# defining model\\nModel = AdaBoostClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [100, 150, 200],\\n    \\\"learning_rate\\\": [0.2, 0.05],\\n    \\\"base_estimator\\\": [DecisionTreeClassifier(max_depth=1, random_state=1), DecisionTreeClassifier(max_depth=2, random_state=1), DecisionTreeClassifier(max_depth=3, random_state=1),\\n    ]\\n}\\n\\n\\n#Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\\n\\n#Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over,y_train_over) ## Complete the code to fit the model on over sampled data\\n\\nprint(\\\"Best parameters are {} with CV score={}:\\\" .format(randomized_cv.best_params_,randomized_cv.best_score_))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "# defining model\n",
        "Model = AdaBoostClassifier(random_state=1)\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 150, 200],\n",
        "    \"learning_rate\": [0.2, 0.05],\n",
        "    \"base_estimator\": [DecisionTreeClassifier(max_depth=1, random_state=1), DecisionTreeClassifier(max_depth=2, random_state=1), DecisionTreeClassifier(max_depth=3, random_state=1),\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train_over,y_train_over) ## Complete the code to fit the model on over sampled data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "UTQNwsr5bp1D"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
              "                                                         random_state=1),\n",
              "                   learning_rate=0.2, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
              "                                                         random_state=1),\n",
              "                   learning_rate=0.2, n_estimators=200)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
              "                                                         random_state=1),\n",
              "                   learning_rate=0.2, n_estimators=200)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 92;\n                var nbb_unformatted_code = \"# Creating new pipeline with best parameters\\ntuned_ada = AdaBoostClassifier(\\n    n_estimators= 200, learning_rate= 0.2, base_estimator= DecisionTreeClassifier(max_depth=3, random_state=1)\\n) ## Complete the code with the best parameters obtained from tuning\\n\\ntuned_ada.fit(X_train_over,y_train_over) ## Complete the code to fit the model on oversampled data\";\n                var nbb_formatted_code = \"# Creating new pipeline with best parameters\\ntuned_ada = AdaBoostClassifier(\\n    n_estimators=200,\\n    learning_rate=0.2,\\n    base_estimator=DecisionTreeClassifier(max_depth=3, random_state=1),\\n)  ## Complete the code with the best parameters obtained from tuning\\n\\ntuned_ada.fit(\\n    X_train_over, y_train_over\\n)  ## Complete the code to fit the model on oversampled data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_ada = AdaBoostClassifier(\n",
        "    n_estimators= 200, learning_rate= 0.2, base_estimator= DecisionTreeClassifier(max_depth=3, random_state=1)\n",
        ") ## Complete the code with the best parameters obtained from tuning\n",
        "\n",
        "tuned_ada.fit(X_train_over,y_train_over) ## Complete the code to fit the model on oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "MKzdHSSbbp1D",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.992</td>\n",
              "      <td>0.989</td>\n",
              "      <td>0.996</td>\n",
              "      <td>0.992</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.992   0.989      0.996 0.992"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 93;\n                var nbb_unformatted_code = \"ada_train_perf = model_performance_classification_sklearn(tuned_ada, X_train_over, y_train_over)\\nada_train_perf\";\n                var nbb_formatted_code = \"ada_train_perf = model_performance_classification_sklearn(\\n    tuned_ada, X_train_over, y_train_over\\n)\\nada_train_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ada_train_perf = model_performance_classification_sklearn(tuned_ada, X_train_over, y_train_over)\n",
        "ada_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "10_dV5m4bp1D"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.979</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.777</td>\n",
              "      <td>0.819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.979   0.866      0.777 0.819"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 94;\n                var nbb_unformatted_code = \"ada_val_perf = model_performance_classification_sklearn(tuned_ada, X_val, y_val) ## Complete the code to check the performance on validation set\\nada_val_perf\";\n                var nbb_formatted_code = \"ada_val_perf = model_performance_classification_sklearn(\\n    tuned_ada, X_val, y_val\\n)  ## Complete the code to check the performance on validation set\\nada_val_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ada_val_perf = model_performance_classification_sklearn(tuned_ada, X_val, y_val) ## Complete the code to check the performance on validation set\n",
        "ada_val_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqj6dc38bp1E"
      },
      "source": [
        "### Tuning Random forest using undersampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "9tLNoDYhbp1E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters are {'n_estimators': 200, 'min_samples_leaf': 2, 'max_samples': 0.6, 'max_features': 'sqrt'} with CV score=0.8942134363402257:\n",
            "CPU times: total: 1.59 s\n",
            "Wall time: 1min 7s\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 71;\n                var nbb_unformatted_code = \"%%time \\n\\n# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [200,250,300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1),'sqrt'],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1)}\\n\\n\\n#Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\\n\\n#Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un,y_train_un) ## Complete the code to fit the model on under sampled data\\n\\nprint(\\\"Best parameters are {} with CV score={}:\\\" .format(randomized_cv.best_params_,randomized_cv.best_score_))\";\n                var nbb_formatted_code = \"%%time \\n\\n# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [200,250,300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1),'sqrt'],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1)}\\n\\n\\n#Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\\n\\n#Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un,y_train_un) ## Complete the code to fit the model on under sampled data\\n\\nprint(\\\"Best parameters are {} with CV score={}:\\\" .format(randomized_cv.best_params_,randomized_cv.best_score_))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "# defining model\n",
        "Model = RandomForestClassifier(random_state=1)\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": [200,250,300],\n",
        "    \"min_samples_leaf\": np.arange(1, 4),\n",
        "    \"max_features\": [np.arange(0.3, 0.6, 0.1),'sqrt'],\n",
        "    \"max_samples\": np.arange(0.4, 0.7, 0.1)}\n",
        "\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train_un,y_train_un) ## Complete the code to fit the model on under sampled data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5kmoh9KMbp1E"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_samples=0.6, min_samples_leaf=2, n_estimators=200,\n",
              "                       random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_samples=0.6, min_samples_leaf=2, n_estimators=200,\n",
              "                       random_state=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_samples=0.6, min_samples_leaf=2, n_estimators=200,\n",
              "                       random_state=1)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 39;\n                var nbb_unformatted_code = \"# Creating new pipeline with best parameters\\ntuned_rf2 = RandomForestClassifier(\\n    max_features='sqrt',\\n    random_state=1,\\n    max_samples=0.6,\\n    n_estimators=200,\\n    min_samples_leaf=2,\\n)## Complete the code with the best parameters obtained from tuning\\n\\ntuned_rf2.fit(X_train_un,y_train_un) ## Complete the code to fit the model on under sampled data\";\n                var nbb_formatted_code = \"# Creating new pipeline with best parameters\\ntuned_rf2 = RandomForestClassifier(\\n    max_features=\\\"sqrt\\\",\\n    random_state=1,\\n    max_samples=0.6,\\n    n_estimators=200,\\n    min_samples_leaf=2,\\n)  ## Complete the code with the best parameters obtained from tuning\\n\\ntuned_rf2.fit(\\n    X_train_un, y_train_un\\n)  ## Complete the code to fit the model on under sampled data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_rf2 = RandomForestClassifier(\n",
        "    max_features='sqrt',\n",
        "    random_state=1,\n",
        "    max_samples=0.6,\n",
        "    n_estimators=200,\n",
        "    min_samples_leaf=2,\n",
        ")## Complete the code with the best parameters obtained from tuning\n",
        "\n",
        "tuned_rf2.fit(X_train_un,y_train_un) ## Complete the code to fit the model on under sampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "bAAD5mzybp1E"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.967</td>\n",
              "      <td>0.935</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.967   0.935      0.999 0.966"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 40;\n                var nbb_unformatted_code = \"rf2_train_perf =  model_performance_classification_sklearn(tuned_rf2, X_train_un,y_train_un) ## Complete the code to check the performance on undersampled train set\\nrf2_train_perf\";\n                var nbb_formatted_code = \"rf2_train_perf = model_performance_classification_sklearn(\\n    tuned_rf2, X_train_un, y_train_un\\n)  ## Complete the code to check the performance on undersampled train set\\nrf2_train_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rf2_train_perf =  model_performance_classification_sklearn(tuned_rf2, X_train_un,y_train_un) ## Complete the code to check the performance on undersampled train set\n",
        "rf2_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WTtYpzO-bp1E",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.942</td>\n",
              "      <td>0.899</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.942   0.899      0.488 0.633"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 41;\n                var nbb_unformatted_code = \"rf2_val_perf = model_performance_classification_sklearn(tuned_rf2, X_val,y_val) ## Complete the code to check the performance on validation set\\nrf2_val_perf\";\n                var nbb_formatted_code = \"rf2_val_perf = model_performance_classification_sklearn(\\n    tuned_rf2, X_val, y_val\\n)  ## Complete the code to check the performance on validation set\\nrf2_val_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rf2_val_perf = model_performance_classification_sklearn(tuned_rf2, X_val,y_val) ## Complete the code to check the performance on validation set\n",
        "rf2_val_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tuning Random forest using oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters are {'n_estimators': 250, 'min_samples_leaf': 1, 'max_samples': 0.6, 'max_features': 'sqrt'} with CV score=0.9809416741543673:\n",
            "CPU times: total: 25.7 s\n",
            "Wall time: 16min 57s\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 298;\n                var nbb_unformatted_code = \"%%time \\n\\n# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [200,250,300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1),'sqrt'],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1)}\\n\\n\\n#Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\\n\\n#Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over,y_train_over) ## Complete the code to fit the model on under sampled data\\n\\nprint(\\\"Best parameters are {} with CV score={}:\\\" .format(randomized_cv.best_params_,randomized_cv.best_score_))\";\n                var nbb_formatted_code = \"%%time \\n\\n# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [200,250,300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1),'sqrt'],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1)}\\n\\n\\n#Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\\n\\n#Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over,y_train_over) ## Complete the code to fit the model on under sampled data\\n\\nprint(\\\"Best parameters are {} with CV score={}:\\\" .format(randomized_cv.best_params_,randomized_cv.best_score_))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "# defining model\n",
        "Model = RandomForestClassifier(random_state=1)\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": [200,250,300],\n",
        "    \"min_samples_leaf\": np.arange(1, 4),\n",
        "    \"max_features\": [np.arange(0.3, 0.6, 0.1),'sqrt'],\n",
        "    \"max_samples\": np.arange(0.4, 0.7, 0.1)}\n",
        "\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train_over,y_train_over) ## Complete the code to fit the model on under sampled data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_samples=0.6, n_estimators=250, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_samples=0.6, n_estimators=250, random_state=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_samples=0.6, n_estimators=250, random_state=1)"
            ]
          },
          "execution_count": 300,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 300;\n                var nbb_unformatted_code = \"# Creating new pipeline with best parameters\\ntuned_rf3 = RandomForestClassifier(\\n    max_features='sqrt',\\n    random_state=1,\\n    max_samples=0.6,\\n    n_estimators=250,\\n    min_samples_leaf=1,\\n)## Complete the code with the best parameters obtained from tuning\\n\\ntuned_rf3.fit(X_train_over,y_train_over) ## Complete the code to fit the model on under sampled data\";\n                var nbb_formatted_code = \"# Creating new pipeline with best parameters\\ntuned_rf3 = RandomForestClassifier(\\n    max_features=\\\"sqrt\\\",\\n    random_state=1,\\n    max_samples=0.6,\\n    n_estimators=250,\\n    min_samples_leaf=1,\\n)  ## Complete the code with the best parameters obtained from tuning\\n\\ntuned_rf3.fit(\\n    X_train_over, y_train_over\\n)  ## Complete the code to fit the model on under sampled data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_rf3 = RandomForestClassifier(\n",
        "    max_features='sqrt',\n",
        "    random_state=1,\n",
        "    max_samples=0.6,\n",
        "    n_estimators=250,\n",
        "    min_samples_leaf=1,\n",
        ")## Complete the code with the best parameters obtained from tuning\n",
        "\n",
        "tuned_rf3.fit(X_train_over,y_train_over) ## Complete the code to fit the model on under sampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     1.000   1.000      1.000 1.000"
            ]
          },
          "execution_count": 301,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 301;\n                var nbb_unformatted_code = \"rf3_train_perf =  model_performance_classification_sklearn(tuned_rf3, X_train_over,y_train_over) ## Complete the code to check the performance on undersampled train set\\nrf3_train_perf\";\n                var nbb_formatted_code = \"rf3_train_perf = model_performance_classification_sklearn(\\n    tuned_rf3, X_train_over, y_train_over\\n)  ## Complete the code to check the performance on undersampled train set\\nrf3_train_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rf3_train_perf =  model_performance_classification_sklearn(tuned_rf3, X_train_over,y_train_over) ## Complete the code to check the performance on undersampled train set\n",
        "rf3_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.986</td>\n",
              "      <td>0.852</td>\n",
              "      <td>0.887</td>\n",
              "      <td>0.869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.986   0.852      0.887 0.869"
            ]
          },
          "execution_count": 302,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 302;\n                var nbb_unformatted_code = \"rf3_val_perf = model_performance_classification_sklearn(tuned_rf3, X_val,y_val) ## Complete the code to check the performance on validation set\\nrf3_val_perf\";\n                var nbb_formatted_code = \"rf3_val_perf = model_performance_classification_sklearn(\\n    tuned_rf3, X_val, y_val\\n)  ## Complete the code to check the performance on validation set\\nrf3_val_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rf3_val_perf = model_performance_classification_sklearn(tuned_rf3, X_val,y_val) ## Complete the code to check the performance on validation set\n",
        "rf3_val_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoLT8ewJ5V2d"
      },
      "source": [
        "### Tuning Gradient Boosting using oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkDY8_X25Kxe"
      },
      "outputs": [],
      "source": [
        "%%time \n",
        "\n",
        "# defining model\n",
        "Model = GradientBoostingClassifier(random_state=1)\n",
        "\n",
        "#Parameter grid to pass in RandomSearchCV\n",
        "param_grid={\"n_estimators\": np.arange(100,150,25), \"learning_rate\": [0.2, 0.05, 1], \"subsample\":[0.5,0.7], \"max_features\":[0.5,0.7]}\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, scoring=scorer, n_iter=50, n_jobs = -1, cv=5, random_state=1,v)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train_over, y_train_over)\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "j_61Omhq5KkB"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=1, max_features=0.5, n_estimators=125,\n",
              "                           random_state=1, subsample=0.7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=1, max_features=0.5, n_estimators=125,\n",
              "                           random_state=1, subsample=0.7)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GradientBoostingClassifier(learning_rate=1, max_features=0.5, n_estimators=125,\n",
              "                           random_state=1, subsample=0.7)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 87;\n                var nbb_unformatted_code = \"# Creating new pipeline with best parameters\\ntuned_gbm = GradientBoostingClassifier(\\n    max_features=0.5,\\n    random_state=1,\\n    learning_rate=1,\\n    n_estimators=125,\\n    subsample=0.7,\\n)## Complete the code with the best parameters obtained from tuning\\n\\ntuned_gbm.fit(X_train_over, y_train_over)\";\n                var nbb_formatted_code = \"# Creating new pipeline with best parameters\\ntuned_gbm = GradientBoostingClassifier(\\n    max_features=0.5,\\n    random_state=1,\\n    learning_rate=1,\\n    n_estimators=125,\\n    subsample=0.7,\\n)  ## Complete the code with the best parameters obtained from tuning\\n\\ntuned_gbm.fit(X_train_over, y_train_over)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_gbm = GradientBoostingClassifier(\n",
        "    max_features=0.5,\n",
        "    random_state=1,\n",
        "    learning_rate=1,\n",
        "    n_estimators=125,\n",
        "    subsample=0.7,\n",
        ")## Complete the code with the best parameters obtained from tuning\n",
        "\n",
        "tuned_gbm.fit(X_train_over, y_train_over)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "_wVH74h75KXh"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.981</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.983</td>\n",
              "      <td>0.981</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.981   0.978      0.983 0.981"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 88;\n                var nbb_unformatted_code = \"gbm_train_perf = model_performance_classification_sklearn(\\n    tuned_gbm, X_train_over, y_train_over\\n)\\ngbm_train_perf\";\n                var nbb_formatted_code = \"gbm_train_perf = model_performance_classification_sklearn(\\n    tuned_gbm, X_train_over, y_train_over\\n)\\ngbm_train_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gbm_train_perf = model_performance_classification_sklearn(\n",
        "    tuned_gbm, X_train_over, y_train_over\n",
        ")\n",
        "gbm_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "VSfX85W55KF-"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.957</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.578</td>\n",
              "      <td>0.690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.957   0.856      0.578 0.690"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 89;\n                var nbb_unformatted_code = \"gbm_val_perf = model_performance_classification_sklearn(\\n    tuned_gbm, X_val, y_val\\n)\\ngbm_val_perf\";\n                var nbb_formatted_code = \"gbm_val_perf = model_performance_classification_sklearn(tuned_gbm, X_val, y_val)\\ngbm_val_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gbm_val_perf = model_performance_classification_sklearn(\n",
        "    tuned_gbm, X_val, y_val\n",
        ")\n",
        "gbm_val_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbrQHwrKbp1C"
      },
      "source": [
        "### Tuning XGBoost using oversampled data\n",
        "\n",
        "**Note**: You can choose to skip this section if XGBoost gives error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ec8e6iVzbp1C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "Best parameters are {'subsample': 0.8, 'scale_pos_weight': 10, 'n_estimators': 250, 'learning_rate': 0.1, 'gamma': 5} with CV score=0.9963999352046328:\n",
            "CPU times: total: 2min 9s\n",
            "Wall time: 57min 13s\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 96;\n                var nbb_unformatted_code = \"%%time \\n\\n# defining model\\nModel = XGBClassifier(random_state=1,eval_metric='logloss')\\n\\n#Parameter grid to pass in RandomSearchCV#'scale_pos_weight':[5,10]\\nparam_grid={'n_estimators':[150,200,250],'scale_pos_weight':[5,10], 'learning_rate':[0.1,0.2], 'gamma':[0,3,5], 'subsample':[0.8,0.9]}\\n\\n#Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid,verbose=2, n_iter=50, n_jobs = -1, scoring=scorer, cv=3, random_state=1)\\n\\n#Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over) ## Complete the code to fit the model on over sampled data\\n\\nprint(\\\"Best parameters are {} with CV score={}:\\\" .format(randomized_cv.best_params_,randomized_cv.best_score_))\";\n                var nbb_formatted_code = \"%%time \\n\\n# defining model\\nModel = XGBClassifier(random_state=1,eval_metric='logloss')\\n\\n#Parameter grid to pass in RandomSearchCV#'scale_pos_weight':[5,10]\\nparam_grid={'n_estimators':[150,200,250],'scale_pos_weight':[5,10], 'learning_rate':[0.1,0.2], 'gamma':[0,3,5], 'subsample':[0.8,0.9]}\\n\\n#Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid,verbose=2, n_iter=50, n_jobs = -1, scoring=scorer, cv=3, random_state=1)\\n\\n#Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over) ## Complete the code to fit the model on over sampled data\\n\\nprint(\\\"Best parameters are {} with CV score={}:\\\" .format(randomized_cv.best_params_,randomized_cv.best_score_))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "# defining model\n",
        "Model = XGBClassifier(random_state=1,eval_metric='logloss')\n",
        "\n",
        "#Parameter grid to pass in RandomSearchCV#'scale_pos_weight':[5,10]\n",
        "param_grid={'n_estimators':[150,200,250],'scale_pos_weight':[5,10], 'learning_rate':[0.1,0.2], 'gamma':[0,3,5], 'subsample':[0.8,0.9]}\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid,verbose=2, n_iter=50, n_jobs = -1, scoring=scorer, cv=3, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train_over, y_train_over) ## Complete the code to fit the model on over sampled data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "NSio3khJbp1C",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;logloss&#x27;, gamma=5, gpu_id=-1,\n",
              "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
              "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
              "              max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
              "              n_estimators=250, n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
              "              random_state=1, reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;logloss&#x27;, gamma=5, gpu_id=-1,\n",
              "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
              "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
              "              max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
              "              n_estimators=250, n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
              "              random_state=1, reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric='logloss', gamma=5, gpu_id=-1,\n",
              "              grow_policy='depthwise', importance_type=None,\n",
              "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
              "              max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=250, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
              "              random_state=1, reg_alpha=0, reg_lambda=1, ...)"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 105;\n                var nbb_unformatted_code = \"xgb2 = XGBClassifier(\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n    subsample=0.8,\\n    scale_pos_weight=10,\\n    n_estimators=250,\\n    learning_rate=0.1,\\n    gamma=5,\\n)## Complete the code with the best parameters obtained from tuning\\n\\nxgb2.fit(X_train_over, y_train_over) ## Complete the code to fit the model on over sampled data\";\n                var nbb_formatted_code = \"xgb2 = XGBClassifier(\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n    subsample=0.8,\\n    scale_pos_weight=10,\\n    n_estimators=250,\\n    learning_rate=0.1,\\n    gamma=5,\\n)  ## Complete the code with the best parameters obtained from tuning\\n\\nxgb2.fit(\\n    X_train_over, y_train_over\\n)  ## Complete the code to fit the model on over sampled data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "xgb2 = XGBClassifier(\n",
        "    random_state=1,\n",
        "    eval_metric=\"logloss\",\n",
        "    subsample=0.8,\n",
        "    scale_pos_weight=10,\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.1,\n",
        "    gamma=5,\n",
        ")## Complete the code with the best parameters obtained from tuning\n",
        "\n",
        "xgb2.fit(X_train_over, y_train_over) ## Complete the code to fit the model on over sampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "hDzHR8Pwbp1D"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.998</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.996</td>\n",
              "      <td>0.998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.998   1.000      0.996 0.998"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 107;\n                var nbb_unformatted_code = \"xgb2_train_perf =  model_performance_classification_sklearn(\\n    xgb2,X_train_over, y_train_over) ## Complete the code to check the performance on oversampled train set\\nxgb2_train_perf\";\n                var nbb_formatted_code = \"xgb2_train_perf = model_performance_classification_sklearn(\\n    xgb2, X_train_over, y_train_over\\n)  ## Complete the code to check the performance on oversampled train set\\nxgb2_train_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "xgb2_train_perf =  model_performance_classification_sklearn(\n",
        "    xgb2,X_train_over, y_train_over) ## Complete the code to check the performance on oversampled train set\n",
        "xgb2_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "jiDRsOrMbp1D",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.974</td>\n",
              "      <td>0.899</td>\n",
              "      <td>0.709</td>\n",
              "      <td>0.793</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.974   0.899      0.709 0.793"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 110;\n                var nbb_unformatted_code = \"xgb2_val_perf = model_performance_classification_sklearn(\\n    xgb2,X_val, y_val)  ## Complete the code to check the performance on validation set\\nxgb2_val_perf\";\n                var nbb_formatted_code = \"xgb2_val_perf = model_performance_classification_sklearn(\\n    xgb2, X_val, y_val\\n)  ## Complete the code to check the performance on validation set\\nxgb2_val_perf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "xgb2_val_perf = model_performance_classification_sklearn(\n",
        "    xgb2,X_val, y_val)  ## Complete the code to check the performance on validation set\n",
        "xgb2_val_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJsiURQL4eBn"
      },
      "source": [
        "**We have now tuned all the models, let's compare the performance of all tuned models and see which one is the best.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Yra0TCbp1E"
      },
      "source": [
        "## Model Performance comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "TF1WfZZHbp1E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training performance comparison:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting tuned with oversampled data</th>\n",
              "      <td>0.981</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.983</td>\n",
              "      <td>0.981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost classifier tuned with oversampled data</th>\n",
              "      <td>0.992</td>\n",
              "      <td>0.989</td>\n",
              "      <td>0.996</td>\n",
              "      <td>0.992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest tuned with undersampled data</th>\n",
              "      <td>0.967</td>\n",
              "      <td>0.935</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost tuned with oversampled data</th>\n",
              "      <td>0.998</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.996</td>\n",
              "      <td>0.998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Accuracy  Recall  Precision  \\\n",
              "Gradient Boosting tuned with oversampled data       0.981   0.978      0.983   \n",
              "AdaBoost classifier tuned with oversampled data     0.992   0.989      0.996   \n",
              "Random forest tuned with undersampled data          0.967   0.935      0.999   \n",
              "XGBoost tuned with oversampled data                 0.998   1.000      0.996   \n",
              "\n",
              "                                                   F1  \n",
              "Gradient Boosting tuned with oversampled data   0.981  \n",
              "AdaBoost classifier tuned with oversampled data 0.992  \n",
              "Random forest tuned with undersampled data      0.966  \n",
              "XGBoost tuned with oversampled data             0.998  "
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 102;\n                var nbb_unformatted_code = \"# training performance comparison\\n\\nmodels_train_comp_df = pd.concat(\\n    [\\n        gbm_train_perf.T,\\n        ada_train_perf.T,\\n        rf2_train_perf.T,\\n       xgb2_train_perf.T,\\n    ],\\n    axis=1,\\n)\\nmodels_train_comp_df.columns = [\\n    \\\"Gradient Boosting tuned with oversampled data\\\",\\n    \\\"AdaBoost classifier tuned with oversampled data\\\",\\n    \\\"Random forest tuned with undersampled data\\\",\\n    \\\"XGBoost tuned with oversampled data\\\",\\n]\\nprint(\\\"Training performance comparison:\\\")\\nmodels_train_comp_df.T\";\n                var nbb_formatted_code = \"# training performance comparison\\n\\nmodels_train_comp_df = pd.concat(\\n    [\\n        gbm_train_perf.T,\\n        ada_train_perf.T,\\n        rf2_train_perf.T,\\n        xgb2_train_perf.T,\\n    ],\\n    axis=1,\\n)\\nmodels_train_comp_df.columns = [\\n    \\\"Gradient Boosting tuned with oversampled data\\\",\\n    \\\"AdaBoost classifier tuned with oversampled data\\\",\\n    \\\"Random forest tuned with undersampled data\\\",\\n    \\\"XGBoost tuned with oversampled data\\\",\\n]\\nprint(\\\"Training performance comparison:\\\")\\nmodels_train_comp_df.T\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training performance comparison\n",
        "\n",
        "models_train_comp_df = pd.concat(\n",
        "    [\n",
        "        gbm_train_perf.T,\n",
        "        ada_train_perf.T,\n",
        "        rf2_train_perf.T,\n",
        "       xgb2_train_perf.T,\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "models_train_comp_df.columns = [\n",
        "    \"Gradient Boosting tuned with oversampled data\",\n",
        "    \"AdaBoost classifier tuned with oversampled data\",\n",
        "    \"Random forest tuned with undersampled data\",\n",
        "    \"XGBoost tuned with oversampled data\",\n",
        "]\n",
        "print(\"Training performance comparison:\")\n",
        "models_train_comp_df.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "0FgTXpsXbp1F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training performance comparison:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting tuned with oversampled data</th>\n",
              "      <td>0.957</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.578</td>\n",
              "      <td>0.690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost classifier tuned with oversampled data</th>\n",
              "      <td>0.979</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.777</td>\n",
              "      <td>0.819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest tuned with undersampled data</th>\n",
              "      <td>0.942</td>\n",
              "      <td>0.899</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost tuned with oversampled data</th>\n",
              "      <td>0.974</td>\n",
              "      <td>0.899</td>\n",
              "      <td>0.709</td>\n",
              "      <td>0.793</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Accuracy  Recall  Precision  \\\n",
              "Gradient Boosting tuned with oversampled data       0.957   0.856      0.578   \n",
              "AdaBoost classifier tuned with oversampled data     0.979   0.866      0.777   \n",
              "Random forest tuned with undersampled data          0.942   0.899      0.488   \n",
              "XGBoost tuned with oversampled data                 0.974   0.899      0.709   \n",
              "\n",
              "                                                   F1  \n",
              "Gradient Boosting tuned with oversampled data   0.690  \n",
              "AdaBoost classifier tuned with oversampled data 0.819  \n",
              "Random forest tuned with undersampled data      0.633  \n",
              "XGBoost tuned with oversampled data             0.793  "
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 103;\n                var nbb_unformatted_code = \"# validation performance comparison\\n\\nmodels_val_comp_df = pd.concat(\\n    [\\n        gbm_val_perf.T,\\n        ada_val_perf.T,\\n        rf2_val_perf.T,\\n       xgb2_val_perf.T,\\n    ],\\n    axis=1,\\n)\\nmodels_val_comp_df.columns = [\\n    \\\"Gradient Boosting tuned with oversampled data\\\",\\n    \\\"AdaBoost classifier tuned with oversampled data\\\",\\n    \\\"Random forest tuned with undersampled data\\\",\\n    \\\"XGBoost tuned with oversampled data\\\",\\n]\\nprint(\\\"Training performance comparison:\\\")\\nmodels_val_comp_df.T\\n\\n## Write the code to compare the performance on validation set\";\n                var nbb_formatted_code = \"# validation performance comparison\\n\\nmodels_val_comp_df = pd.concat(\\n    [\\n        gbm_val_perf.T,\\n        ada_val_perf.T,\\n        rf2_val_perf.T,\\n        xgb2_val_perf.T,\\n    ],\\n    axis=1,\\n)\\nmodels_val_comp_df.columns = [\\n    \\\"Gradient Boosting tuned with oversampled data\\\",\\n    \\\"AdaBoost classifier tuned with oversampled data\\\",\\n    \\\"Random forest tuned with undersampled data\\\",\\n    \\\"XGBoost tuned with oversampled data\\\",\\n]\\nprint(\\\"Training performance comparison:\\\")\\nmodels_val_comp_df.T\\n\\n## Write the code to compare the performance on validation set\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# validation performance comparison\n",
        "\n",
        "models_val_comp_df = pd.concat(\n",
        "    [\n",
        "        gbm_val_perf.T,\n",
        "        ada_val_perf.T,\n",
        "        rf2_val_perf.T,\n",
        "       xgb2_val_perf.T,\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "models_val_comp_df.columns = [\n",
        "    \"Gradient Boosting tuned with oversampled data\",\n",
        "    \"AdaBoost classifier tuned with oversampled data\",\n",
        "    \"Random forest tuned with undersampled data\",\n",
        "    \"XGBoost tuned with oversampled data\",\n",
        "]\n",
        "print(\"Training performance comparison:\")\n",
        "models_val_comp_df.T\n",
        "\n",
        "## Write the code to compare the performance on validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYS5m_mcbp1F"
      },
      "source": [
        "**Now we have our final model, so let's find out how our final model is performing on unseen test data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "rqgvz7e7bp1F"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.943</td>\n",
              "      <td>0.869</td>\n",
              "      <td>0.498</td>\n",
              "      <td>0.633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.943   0.869      0.498 0.633"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 116;\n                var nbb_unformatted_code = \"# Let's check the performance on test set\\nbest_model = model_performance_classification_sklearn(\\n    tuned_rf2,X_test, y_test) \\nbest_model\\n## Write the code to check the performance of best model on test data\";\n                var nbb_formatted_code = \"# Let's check the performance on test set\\nbest_model = model_performance_classification_sklearn(tuned_rf2, X_test, y_test)\\nbest_model\\n## Write the code to check the performance of best model on test data\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Let's check the performance on test set\n",
        "best_model = model_performance_classification_sklearn(\n",
        "    tuned_rf2,X_test, y_test) \n",
        "best_model\n",
        "## Write the code to check the performance of best model on test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J49s-TEB41JQ"
      },
      "source": [
        "### Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "7Zk2dFRzbp1F"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 187;\n                var nbb_unformatted_code = \"feature_names = X_train.columns\\nimportances =  tuned_rf2.feature_importances_## Complete the code to check the feature importance of the best model\\nindices = np.argsort(importances)\\n\\nplt.figure(figsize=(8, 12))\\nplt.title(\\\"Feature Importances\\\")\\n\\n\\nplt.barh(range(len(indices)), importances[indices], color='red', align=\\\"center\\\")\\n\\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\\nplt.xlabel(\\\"Relative Importance\\\")\\nplt.tight_layout()\\nplt.savefig('features.png',ppi=200)\";\n                var nbb_formatted_code = \"feature_names = X_train.columns\\nimportances = (\\n    tuned_rf2.feature_importances_\\n)  ## Complete the code to check the feature importance of the best model\\nindices = np.argsort(importances)\\n\\nplt.figure(figsize=(8, 12))\\nplt.title(\\\"Feature Importances\\\")\\n\\n\\nplt.barh(range(len(indices)), importances[indices], color=\\\"red\\\", align=\\\"center\\\")\\n\\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\\nplt.xlabel(\\\"Relative Importance\\\")\\nplt.tight_layout()\\nplt.savefig(\\\"features.png\\\", ppi=200)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "feature_names = X_train.columns\n",
        "importances =  tuned_rf2.feature_importances_## Complete the code to check the feature importance of the best model\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(8, 12))\n",
        "plt.title(\"Feature Importances\")\n",
        "\n",
        "\n",
        "plt.barh(range(len(indices)), importances[indices], color='red', align=\"center\")\n",
        "\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('features.png',ppi=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 313;\n                var nbb_unformatted_code = \"blue=data[data['Target']==0].mean()#.plot.line(color='blue')\\nred=data[data['Target']==1].mean()#.plot.line(color='red')\\n#pd.DataFrame([blue,red],index=['blue','red'])\";\n                var nbb_formatted_code = \"blue = data[data[\\\"Target\\\"] == 0].mean()  # .plot.line(color='blue')\\nred = data[data[\\\"Target\\\"] == 1].mean()  # .plot.line(color='red')\\n# pd.DataFrame([blue,red],index=['blue','red'])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "blue=data[data['Target']==0].mean()#.plot.line(color='blue')\n",
        "red=data[data['Target']==1].mean()#.plot.line(color='red')\n",
        "#pd.DataFrame([blue,red],index=['blue','red'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[data['Target']==0].mean().plot.line(color='blue',figsize=(12,8))\n",
        "data[data['Target']==1].mean().plot.line(color='red',figsize=(12,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gohwGn0tbp1L"
      },
      "source": [
        "## Let's use Pipelines to build the final model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euQoHofA5JBx"
      },
      "source": [
        "- Since we have only one datatype in the data, we don't need to use column transformer here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "xTB5oErrbp1L"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 165;\n                var nbb_unformatted_code = \"Model = Pipeline([('imputer',SimpleImputer(strategy=\\\"median\\\")),('RadomForest',RandomForestClassifier(\\n    max_features='sqrt',\\n    random_state=1,\\n    max_samples=0.6,\\n    n_estimators=200,\\n    min_samples_leaf=2,\\n))] ) ## Complete the code to create pipeline for the best model\";\n                var nbb_formatted_code = \"Model = Pipeline(\\n    [\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\n            \\\"RadomForest\\\",\\n            RandomForestClassifier(\\n                max_features=\\\"sqrt\\\",\\n                random_state=1,\\n                max_samples=0.6,\\n                n_estimators=200,\\n                min_samples_leaf=2,\\n            ),\\n        ),\\n    ]\\n)  ## Complete the code to create pipeline for the best model\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Model = Pipeline([('imputer',SimpleImputer(strategy=\"median\")),\n",
        "                  ('RadomForest',RandomForestClassifier(\n",
        "    max_features='sqrt',\n",
        "    random_state=1,\n",
        "    max_samples=0.6,\n",
        "    n_estimators=200,\n",
        "    min_samples_leaf=2,\n",
        "))\n",
        "                  \n",
        "                  ] ) ## Complete the code to create pipeline for the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "KVhk_Ga4bp1L"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 166;\n                var nbb_unformatted_code = \"# Separating target variable and other variables\\nX1 = data.drop(columns=\\\"Target\\\")\\nY1 = data[\\\"Target\\\"]\\n\\n# Since we already have a separate test set, we don't need to divide data into train and test\\n\\nX_test1 = df_test.drop(columns=\\\"Target\\\")##  Complete the code to drop target variable from test data\\ny_test1 = df_test[\\\"Target\\\"] ##  Complete the code to store target variable in y_test1\";\n                var nbb_formatted_code = \"# Separating target variable and other variables\\nX1 = data.drop(columns=\\\"Target\\\")\\nY1 = data[\\\"Target\\\"]\\n\\n# Since we already have a separate test set, we don't need to divide data into train and test\\n\\nX_test1 = df_test.drop(\\n    columns=\\\"Target\\\"\\n)  ##  Complete the code to drop target variable from test data\\ny_test1 = df_test[\\\"Target\\\"]  ##  Complete the code to store target variable in y_test1\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Separating target variable and other variables\n",
        "X1 = data.drop(columns=\"Target\")\n",
        "Y1 = data[\"Target\"]\n",
        "\n",
        "# Since we already have a separate test set, we don't need to divide data into train and test\n",
        "\n",
        "X_test1 = df_test.drop(columns=\"Target\")##  Complete the code to drop target variable from test data\n",
        "y_test1 = df_test[\"Target\"] ##  Complete the code to store target variable in y_test1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "esCUwy3ibp1L"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 167;\n                var nbb_unformatted_code = \"# We can't oversample data without doing missing value treatment, so let's first treat the missing values in the train set\\nimputer = SimpleImputer(strategy=\\\"median\\\")\\nX1 = imputer.fit_transform(X1)\\n\\n\\n# We don't need to impute missing values in test set as it will be done inside pipeline\";\n                var nbb_formatted_code = \"# We can't oversample data without doing missing value treatment, so let's first treat the missing values in the train set\\nimputer = SimpleImputer(strategy=\\\"median\\\")\\nX1 = imputer.fit_transform(X1)\\n\\n\\n# We don't need to impute missing values in test set as it will be done inside pipeline\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We can't oversample data without doing missing value treatment, so let's first treat the missing values in the train set\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X1 = imputer.fit_transform(X1)\n",
        "\n",
        "\n",
        "# We don't need to impute missing values in test set as it will be done inside pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "wRhGqGEqbp1M"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 168;\n                var nbb_unformatted_code = \"# Synthetic Minority Over Sampling Technique\\nsm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\\nX_over1, y_over1 = sm.fit_resample(X1, Y1)\";\n                var nbb_formatted_code = \"# Synthetic Minority Over Sampling Technique\\nsm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\\nX_over1, y_over1 = sm.fit_resample(X1, Y1)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Synthetic Minority Over Sampling Technique\n",
        "sm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\n",
        "X_over1, y_over1 = sm.fit_resample(X1, Y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 171;\n                var nbb_unformatted_code = \"rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_un1, y_un1 = rus.fit_resample(X1, Y1)\";\n                var nbb_formatted_code = \"rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_un1, y_un1 = rus.fit_resample(X1, Y1)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\n",
        "X_un1, y_un1 = rus.fit_resample(X1, Y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "AWI12Lh5bp1M"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                (&#x27;RadomForest&#x27;,\n",
              "                 RandomForestClassifier(max_samples=0.6, min_samples_leaf=2,\n",
              "                                        n_estimators=200, random_state=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                (&#x27;RadomForest&#x27;,\n",
              "                 RandomForestClassifier(max_samples=0.6, min_samples_leaf=2,\n",
              "                                        n_estimators=200, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_samples=0.6, min_samples_leaf=2, n_estimators=200,\n",
              "                       random_state=1)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
              "                ('RadomForest',\n",
              "                 RandomForestClassifier(max_samples=0.6, min_samples_leaf=2,\n",
              "                                        n_estimators=200, random_state=1))])"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 177;\n                var nbb_unformatted_code = \"Model.fit(X_over1, y_over1) ##  Complete the code to fit the Model obtained from above step\";\n                var nbb_formatted_code = \"Model.fit(\\n    X_over1, y_over1\\n)  ##  Complete the code to fit the Model obtained from above step\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Model.fit(X_over1, y_over1) ##  Complete the code to fit the Model obtained from above step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.998</td>\n",
              "      <td>0.997</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.998   0.997      0.999 0.998"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 179;\n                var nbb_unformatted_code = \"Model_train = model_performance_classification_sklearn(Model,X_over1, y_over1)  \\nModel_train\";\n                var nbb_formatted_code = \"Model_train = model_performance_classification_sklearn(Model, X_over1, y_over1)\\nModel_train\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Model_train = model_performance_classification_sklearn(Model,X_over1, y_over1)  \n",
        "Model_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "AlKakNj7592p"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.988</td>\n",
              "      <td>0.858</td>\n",
              "      <td>0.931</td>\n",
              "      <td>0.893</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1\n",
              "0     0.988   0.858      0.931 0.893"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 180;\n                var nbb_unformatted_code = \"Model_test = model_performance_classification_sklearn(Model, X_test1, y_test1)  ## Complete the code to check the performance on test set\\nModel_test\";\n                var nbb_formatted_code = \"Model_test = model_performance_classification_sklearn(\\n    Model, X_test1, y_test1\\n)  ## Complete the code to check the performance on test set\\nModel_test\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Model_test = model_performance_classification_sklearn(Model, X_test1, y_test1)  ## Complete the code to check the performance on test set\n",
        "Model_test"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xypQC_9dbp0v",
        "zfmaS2U7bp0x",
        "4cVx5kZHbp02",
        "mG84hrxfbp06",
        "Lv7Bs8aUbp07",
        "zBkL6zw0bp07",
        "3CjaGOdvbp08",
        "Bp8vC9MZbp09",
        "OzOa9FGA6WtG",
        "YZqmoqz7bp0-",
        "-hOzddAXbp0_",
        "8Je_G2zN3VCF",
        "C91_6Swtbp1A",
        "fYLfDmHvbp1B",
        "zLZlKa99bp1C",
        "2FtmPS7Ubp1D",
        "Dqj6dc38bp1E",
        "XoLT8ewJ5V2d",
        "VbrQHwrKbp1C",
        "f9Yra0TCbp1E",
        "J49s-TEB41JQ",
        "gohwGn0tbp1L",
        "gxFmwam_bp1M"
      ],
      "name": "T1T1 MT_Project_LearnerNotebook_LowCode.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('pgds_program')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd8679fc52dd5398e4f98a567250dce312eab9afe2f425d4935b3cd22e2107a1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
